{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ffac279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from numpy import array\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "51f08343",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = pd.read_csv(r\"C:\\Users\\SANJANA\\Desktop\\RL\\DOW_JONES_INTEGRATION\\sp100_data_with_tickers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5d01beeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-03</td>\n",
       "      <td>21.201786</td>\n",
       "      <td>21.235357</td>\n",
       "      <td>20.910713</td>\n",
       "      <td>20.935356</td>\n",
       "      <td>17.951883</td>\n",
       "      <td>364280000</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-12-04</td>\n",
       "      <td>20.778570</td>\n",
       "      <td>20.778570</td>\n",
       "      <td>20.433214</td>\n",
       "      <td>20.566071</td>\n",
       "      <td>17.635214</td>\n",
       "      <td>557068400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-12-05</td>\n",
       "      <td>20.318214</td>\n",
       "      <td>20.330357</td>\n",
       "      <td>19.241785</td>\n",
       "      <td>19.242500</td>\n",
       "      <td>16.500261</td>\n",
       "      <td>1044638000</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-06</td>\n",
       "      <td>18.890715</td>\n",
       "      <td>19.761070</td>\n",
       "      <td>18.522499</td>\n",
       "      <td>19.544287</td>\n",
       "      <td>16.759045</td>\n",
       "      <td>1177212400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-07</td>\n",
       "      <td>19.764286</td>\n",
       "      <td>19.828571</td>\n",
       "      <td>18.928572</td>\n",
       "      <td>19.044643</td>\n",
       "      <td>16.330601</td>\n",
       "      <td>787040800</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250892</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>106.949997</td>\n",
       "      <td>108.739998</td>\n",
       "      <td>106.900002</td>\n",
       "      <td>108.680000</td>\n",
       "      <td>106.922302</td>\n",
       "      <td>11539400</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250893</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>109.269997</td>\n",
       "      <td>110.470001</td>\n",
       "      <td>108.830002</td>\n",
       "      <td>110.190002</td>\n",
       "      <td>108.407875</td>\n",
       "      <td>11962100</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250894</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>109.910004</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>107.900002</td>\n",
       "      <td>108.379997</td>\n",
       "      <td>106.627151</td>\n",
       "      <td>10702100</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250895</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>107.989998</td>\n",
       "      <td>109.720001</td>\n",
       "      <td>107.989998</td>\n",
       "      <td>109.199997</td>\n",
       "      <td>107.433884</td>\n",
       "      <td>10534000</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250896</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>108.610001</td>\n",
       "      <td>110.500000</td>\n",
       "      <td>108.610001</td>\n",
       "      <td>110.300003</td>\n",
       "      <td>108.516098</td>\n",
       "      <td>11799600</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250897 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date        Open        High         Low       Close  \\\n",
       "0       2012-12-03   21.201786   21.235357   20.910713   20.935356   \n",
       "1       2012-12-04   20.778570   20.778570   20.433214   20.566071   \n",
       "2       2012-12-05   20.318214   20.330357   19.241785   19.242500   \n",
       "3       2012-12-06   18.890715   19.761070   18.522499   19.544287   \n",
       "4       2012-12-07   19.764286   19.828571   18.928572   19.044643   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "250892  2022-12-23  106.949997  108.739998  106.900002  108.680000   \n",
       "250893  2022-12-27  109.269997  110.470001  108.830002  110.190002   \n",
       "250894  2022-12-28  109.910004  110.000000  107.900002  108.379997   \n",
       "250895  2022-12-29  107.989998  109.720001  107.989998  109.199997   \n",
       "250896  2022-12-30  108.610001  110.500000  108.610001  110.300003   \n",
       "\n",
       "         Adj Close      Volume Ticker  \n",
       "0        17.951883   364280000   AAPL  \n",
       "1        17.635214   557068400   AAPL  \n",
       "2        16.500261  1044638000   AAPL  \n",
       "3        16.759045  1177212400   AAPL  \n",
       "4        16.330601   787040800   AAPL  \n",
       "...            ...         ...    ...  \n",
       "250892  106.922302    11539400    XOM  \n",
       "250893  108.407875    11962100    XOM  \n",
       "250894  106.627151    10702100    XOM  \n",
       "250895  107.433884    10534000    XOM  \n",
       "250896  108.516098    11799600    XOM  \n",
       "\n",
       "[250897 rows x 8 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4ee3da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\SANJANA\\Desktop\\RL\\DOW_JONES_INTEGRATION\\sp100_data_with_tickers.csv\")\n",
    "\n",
    "df['date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "df.set_index('date', inplace=True)\n",
    "pivot_df = df.pivot(columns='Ticker', values='Close')\n",
    "pivot_df = pivot_df.fillna(value=pd.np.nan)\n",
    "pivot_df = pivot_df.bfill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "950b8b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AIG</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AMGN</th>\n",
       "      <th>AMT</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>...</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>UPS</th>\n",
       "      <th>USB</th>\n",
       "      <th>V</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-03</th>\n",
       "      <td>20.935356</td>\n",
       "      <td>35.119999</td>\n",
       "      <td>30.846342</td>\n",
       "      <td>67.830002</td>\n",
       "      <td>34.700001</td>\n",
       "      <td>33.119999</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>88.400002</td>\n",
       "      <td>74.879997</td>\n",
       "      <td>12.516500</td>\n",
       "      <td>...</td>\n",
       "      <td>53.889999</td>\n",
       "      <td>60.715000</td>\n",
       "      <td>72.269997</td>\n",
       "      <td>32.049999</td>\n",
       "      <td>37.160000</td>\n",
       "      <td>44.099998</td>\n",
       "      <td>34.279999</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>71.339996</td>\n",
       "      <td>87.610001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-04</th>\n",
       "      <td>20.566071</td>\n",
       "      <td>35.119999</td>\n",
       "      <td>30.894321</td>\n",
       "      <td>68.610001</td>\n",
       "      <td>35.299999</td>\n",
       "      <td>33.320000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>88.330002</td>\n",
       "      <td>74.830002</td>\n",
       "      <td>12.624500</td>\n",
       "      <td>...</td>\n",
       "      <td>53.540001</td>\n",
       "      <td>61.185001</td>\n",
       "      <td>73.040001</td>\n",
       "      <td>31.430000</td>\n",
       "      <td>36.897499</td>\n",
       "      <td>43.669998</td>\n",
       "      <td>34.270000</td>\n",
       "      <td>32.740002</td>\n",
       "      <td>72.120003</td>\n",
       "      <td>87.190002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-05</th>\n",
       "      <td>19.242500</td>\n",
       "      <td>35.119999</td>\n",
       "      <td>30.966291</td>\n",
       "      <td>69.599998</td>\n",
       "      <td>35.400002</td>\n",
       "      <td>33.779999</td>\n",
       "      <td>2.290000</td>\n",
       "      <td>89.010002</td>\n",
       "      <td>74.610001</td>\n",
       "      <td>12.698000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.840000</td>\n",
       "      <td>61.430000</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>31.760000</td>\n",
       "      <td>37.014999</td>\n",
       "      <td>44.099998</td>\n",
       "      <td>35.570000</td>\n",
       "      <td>32.980000</td>\n",
       "      <td>71.650002</td>\n",
       "      <td>87.730003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-06</th>\n",
       "      <td>19.544287</td>\n",
       "      <td>35.119999</td>\n",
       "      <td>30.985483</td>\n",
       "      <td>69.800003</td>\n",
       "      <td>35.139999</td>\n",
       "      <td>33.259998</td>\n",
       "      <td>2.340000</td>\n",
       "      <td>88.540001</td>\n",
       "      <td>74.980003</td>\n",
       "      <td>12.668500</td>\n",
       "      <td>...</td>\n",
       "      <td>53.650002</td>\n",
       "      <td>61.564999</td>\n",
       "      <td>72.930000</td>\n",
       "      <td>31.809999</td>\n",
       "      <td>37.117500</td>\n",
       "      <td>44.450001</td>\n",
       "      <td>35.849998</td>\n",
       "      <td>33.139999</td>\n",
       "      <td>71.589996</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-07</th>\n",
       "      <td>19.044643</td>\n",
       "      <td>35.119999</td>\n",
       "      <td>31.441294</td>\n",
       "      <td>69.480003</td>\n",
       "      <td>35.480000</td>\n",
       "      <td>34.130001</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>88.320000</td>\n",
       "      <td>75.449997</td>\n",
       "      <td>12.663500</td>\n",
       "      <td>...</td>\n",
       "      <td>53.869999</td>\n",
       "      <td>61.974998</td>\n",
       "      <td>73.169998</td>\n",
       "      <td>32.020000</td>\n",
       "      <td>37.137501</td>\n",
       "      <td>44.410000</td>\n",
       "      <td>36.099998</td>\n",
       "      <td>33.230000</td>\n",
       "      <td>72.290001</td>\n",
       "      <td>88.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>131.860001</td>\n",
       "      <td>163.100006</td>\n",
       "      <td>108.180000</td>\n",
       "      <td>266.089996</td>\n",
       "      <td>338.450012</td>\n",
       "      <td>63.160000</td>\n",
       "      <td>64.519997</td>\n",
       "      <td>263.920013</td>\n",
       "      <td>212.449997</td>\n",
       "      <td>85.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>531.309998</td>\n",
       "      <td>209.910004</td>\n",
       "      <td>177.009995</td>\n",
       "      <td>43.200001</td>\n",
       "      <td>205.830002</td>\n",
       "      <td>38.410000</td>\n",
       "      <td>38.630001</td>\n",
       "      <td>40.980000</td>\n",
       "      <td>143.770004</td>\n",
       "      <td>108.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>130.029999</td>\n",
       "      <td>162.990005</td>\n",
       "      <td>108.570000</td>\n",
       "      <td>265.309998</td>\n",
       "      <td>335.089996</td>\n",
       "      <td>63.330002</td>\n",
       "      <td>63.270000</td>\n",
       "      <td>263.390015</td>\n",
       "      <td>210.899994</td>\n",
       "      <td>83.040001</td>\n",
       "      <td>...</td>\n",
       "      <td>531.989990</td>\n",
       "      <td>210.320007</td>\n",
       "      <td>176.929993</td>\n",
       "      <td>43.650002</td>\n",
       "      <td>206.289993</td>\n",
       "      <td>39.250000</td>\n",
       "      <td>38.310001</td>\n",
       "      <td>41.040001</td>\n",
       "      <td>143.809998</td>\n",
       "      <td>110.190002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>126.040001</td>\n",
       "      <td>162.229996</td>\n",
       "      <td>107.830002</td>\n",
       "      <td>263.119995</td>\n",
       "      <td>328.329987</td>\n",
       "      <td>62.889999</td>\n",
       "      <td>62.570000</td>\n",
       "      <td>261.420013</td>\n",
       "      <td>210.100006</td>\n",
       "      <td>81.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>528.450012</td>\n",
       "      <td>206.869995</td>\n",
       "      <td>173.610001</td>\n",
       "      <td>43.349998</td>\n",
       "      <td>204.990005</td>\n",
       "      <td>38.810001</td>\n",
       "      <td>37.580002</td>\n",
       "      <td>41.119999</td>\n",
       "      <td>141.289993</td>\n",
       "      <td>108.379997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>129.610001</td>\n",
       "      <td>162.559998</td>\n",
       "      <td>110.309998</td>\n",
       "      <td>268.380005</td>\n",
       "      <td>337.579987</td>\n",
       "      <td>63.630001</td>\n",
       "      <td>64.820000</td>\n",
       "      <td>263.160004</td>\n",
       "      <td>215.740005</td>\n",
       "      <td>84.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>529.880005</td>\n",
       "      <td>209.220001</td>\n",
       "      <td>175.750000</td>\n",
       "      <td>43.570000</td>\n",
       "      <td>208.059998</td>\n",
       "      <td>39.259998</td>\n",
       "      <td>37.470001</td>\n",
       "      <td>41.330002</td>\n",
       "      <td>142.149994</td>\n",
       "      <td>109.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>129.929993</td>\n",
       "      <td>161.610001</td>\n",
       "      <td>109.790001</td>\n",
       "      <td>266.839996</td>\n",
       "      <td>336.529999</td>\n",
       "      <td>63.240002</td>\n",
       "      <td>64.769997</td>\n",
       "      <td>262.640015</td>\n",
       "      <td>211.860001</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>530.179993</td>\n",
       "      <td>207.070007</td>\n",
       "      <td>173.839996</td>\n",
       "      <td>43.610001</td>\n",
       "      <td>207.759995</td>\n",
       "      <td>39.400002</td>\n",
       "      <td>37.360001</td>\n",
       "      <td>41.290001</td>\n",
       "      <td>141.789993</td>\n",
       "      <td>110.300003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2538 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker            AAPL        ABBV         ABT         ACN        ADBE  \\\n",
       "date                                                                     \n",
       "2012-12-03   20.935356   35.119999   30.846342   67.830002   34.700001   \n",
       "2012-12-04   20.566071   35.119999   30.894321   68.610001   35.299999   \n",
       "2012-12-05   19.242500   35.119999   30.966291   69.599998   35.400002   \n",
       "2012-12-06   19.544287   35.119999   30.985483   69.800003   35.139999   \n",
       "2012-12-07   19.044643   35.119999   31.441294   69.480003   35.480000   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2022-12-23  131.860001  163.100006  108.180000  266.089996  338.450012   \n",
       "2022-12-27  130.029999  162.990005  108.570000  265.309998  335.089996   \n",
       "2022-12-28  126.040001  162.229996  107.830002  263.119995  328.329987   \n",
       "2022-12-29  129.610001  162.559998  110.309998  268.380005  337.579987   \n",
       "2022-12-30  129.929993  161.610001  109.790001  266.839996  336.529999   \n",
       "\n",
       "Ticker            AIG        AMD        AMGN         AMT       AMZN  ...  \\\n",
       "date                                                                 ...   \n",
       "2012-12-03  33.119999   2.360000   88.400002   74.879997  12.516500  ...   \n",
       "2012-12-04  33.320000   2.260000   88.330002   74.830002  12.624500  ...   \n",
       "2012-12-05  33.779999   2.290000   89.010002   74.610001  12.698000  ...   \n",
       "2012-12-06  33.259998   2.340000   88.540001   74.980003  12.668500  ...   \n",
       "2012-12-07  34.130001   2.360000   88.320000   75.449997  12.663500  ...   \n",
       "...               ...        ...         ...         ...        ...  ...   \n",
       "2022-12-23  63.160000  64.519997  263.920013  212.449997  85.250000  ...   \n",
       "2022-12-27  63.330002  63.270000  263.390015  210.899994  83.040001  ...   \n",
       "2022-12-28  62.889999  62.570000  261.420013  210.100006  81.820000  ...   \n",
       "2022-12-29  63.630001  64.820000  263.160004  215.740005  84.180000  ...   \n",
       "2022-12-30  63.240002  64.769997  262.640015  211.860001  84.000000  ...   \n",
       "\n",
       "Ticker             UNH         UNP         UPS        USB           V  \\\n",
       "date                                                                    \n",
       "2012-12-03   53.889999   60.715000   72.269997  32.049999   37.160000   \n",
       "2012-12-04   53.540001   61.185001   73.040001  31.430000   36.897499   \n",
       "2012-12-05   53.840000   61.430000   73.500000  31.760000   37.014999   \n",
       "2012-12-06   53.650002   61.564999   72.930000  31.809999   37.117500   \n",
       "2012-12-07   53.869999   61.974998   73.169998  32.020000   37.137501   \n",
       "...                ...         ...         ...        ...         ...   \n",
       "2022-12-23  531.309998  209.910004  177.009995  43.200001  205.830002   \n",
       "2022-12-27  531.989990  210.320007  176.929993  43.650002  206.289993   \n",
       "2022-12-28  528.450012  206.869995  173.610001  43.349998  204.990005   \n",
       "2022-12-29  529.880005  209.220001  175.750000  43.570000  208.059998   \n",
       "2022-12-30  530.179993  207.070007  173.839996  43.610001  207.759995   \n",
       "\n",
       "Ticker             VZ        WBA        WFC         WMT         XOM  \n",
       "date                                                                 \n",
       "2012-12-03  44.099998  34.279999  32.750000   71.339996   87.610001  \n",
       "2012-12-04  43.669998  34.270000  32.740002   72.120003   87.190002  \n",
       "2012-12-05  44.099998  35.570000  32.980000   71.650002   87.730003  \n",
       "2012-12-06  44.450001  35.849998  33.139999   71.589996   88.000000  \n",
       "2012-12-07  44.410000  36.099998  33.230000   72.290001   88.599998  \n",
       "...               ...        ...        ...         ...         ...  \n",
       "2022-12-23  38.410000  38.630001  40.980000  143.770004  108.680000  \n",
       "2022-12-27  39.250000  38.310001  41.040001  143.809998  110.190002  \n",
       "2022-12-28  38.810001  37.580002  41.119999  141.289993  108.379997  \n",
       "2022-12-29  39.259998  37.470001  41.330002  142.149994  109.199997  \n",
       "2022-12-30  39.400002  37.360001  41.290001  141.789993  110.300003  \n",
       "\n",
       "[2538 rows x 100 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "59f3e565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker\n",
      "AAPL    0\n",
      "ABBV    0\n",
      "ABT     0\n",
      "ACN     0\n",
      "ADBE    0\n",
      "       ..\n",
      "VZ      0\n",
      "WBA     0\n",
      "WFC     0\n",
      "WMT     0\n",
      "XOM     0\n",
      "Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = pivot_df.isna().sum()\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3aca06d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2538, 100)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cd5a1283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AIG</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AMGN</th>\n",
       "      <th>AMT</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>...</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>UPS</th>\n",
       "      <th>USB</th>\n",
       "      <th>V</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-03</th>\n",
       "      <td>20.935356</td>\n",
       "      <td>35.119999</td>\n",
       "      <td>30.846342</td>\n",
       "      <td>67.830002</td>\n",
       "      <td>34.700001</td>\n",
       "      <td>33.119999</td>\n",
       "      <td>2.36</td>\n",
       "      <td>88.400002</td>\n",
       "      <td>74.879997</td>\n",
       "      <td>12.5165</td>\n",
       "      <td>...</td>\n",
       "      <td>53.889999</td>\n",
       "      <td>60.715000</td>\n",
       "      <td>72.269997</td>\n",
       "      <td>32.049999</td>\n",
       "      <td>37.160000</td>\n",
       "      <td>44.099998</td>\n",
       "      <td>34.279999</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>71.339996</td>\n",
       "      <td>87.610001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-04</th>\n",
       "      <td>20.566071</td>\n",
       "      <td>35.119999</td>\n",
       "      <td>30.894321</td>\n",
       "      <td>68.610001</td>\n",
       "      <td>35.299999</td>\n",
       "      <td>33.320000</td>\n",
       "      <td>2.26</td>\n",
       "      <td>88.330002</td>\n",
       "      <td>74.830002</td>\n",
       "      <td>12.6245</td>\n",
       "      <td>...</td>\n",
       "      <td>53.540001</td>\n",
       "      <td>61.185001</td>\n",
       "      <td>73.040001</td>\n",
       "      <td>31.430000</td>\n",
       "      <td>36.897499</td>\n",
       "      <td>43.669998</td>\n",
       "      <td>34.270000</td>\n",
       "      <td>32.740002</td>\n",
       "      <td>72.120003</td>\n",
       "      <td>87.190002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-05</th>\n",
       "      <td>19.242500</td>\n",
       "      <td>35.119999</td>\n",
       "      <td>30.966291</td>\n",
       "      <td>69.599998</td>\n",
       "      <td>35.400002</td>\n",
       "      <td>33.779999</td>\n",
       "      <td>2.29</td>\n",
       "      <td>89.010002</td>\n",
       "      <td>74.610001</td>\n",
       "      <td>12.6980</td>\n",
       "      <td>...</td>\n",
       "      <td>53.840000</td>\n",
       "      <td>61.430000</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>31.760000</td>\n",
       "      <td>37.014999</td>\n",
       "      <td>44.099998</td>\n",
       "      <td>35.570000</td>\n",
       "      <td>32.980000</td>\n",
       "      <td>71.650002</td>\n",
       "      <td>87.730003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-06</th>\n",
       "      <td>19.544287</td>\n",
       "      <td>35.119999</td>\n",
       "      <td>30.985483</td>\n",
       "      <td>69.800003</td>\n",
       "      <td>35.139999</td>\n",
       "      <td>33.259998</td>\n",
       "      <td>2.34</td>\n",
       "      <td>88.540001</td>\n",
       "      <td>74.980003</td>\n",
       "      <td>12.6685</td>\n",
       "      <td>...</td>\n",
       "      <td>53.650002</td>\n",
       "      <td>61.564999</td>\n",
       "      <td>72.930000</td>\n",
       "      <td>31.809999</td>\n",
       "      <td>37.117500</td>\n",
       "      <td>44.450001</td>\n",
       "      <td>35.849998</td>\n",
       "      <td>33.139999</td>\n",
       "      <td>71.589996</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-07</th>\n",
       "      <td>19.044643</td>\n",
       "      <td>35.119999</td>\n",
       "      <td>31.441294</td>\n",
       "      <td>69.480003</td>\n",
       "      <td>35.480000</td>\n",
       "      <td>34.130001</td>\n",
       "      <td>2.36</td>\n",
       "      <td>88.320000</td>\n",
       "      <td>75.449997</td>\n",
       "      <td>12.6635</td>\n",
       "      <td>...</td>\n",
       "      <td>53.869999</td>\n",
       "      <td>61.974998</td>\n",
       "      <td>73.169998</td>\n",
       "      <td>32.020000</td>\n",
       "      <td>37.137501</td>\n",
       "      <td>44.410000</td>\n",
       "      <td>36.099998</td>\n",
       "      <td>33.230000</td>\n",
       "      <td>72.290001</td>\n",
       "      <td>88.599998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker           AAPL       ABBV        ABT        ACN       ADBE        AIG  \\\n",
       "date                                                                           \n",
       "2012-12-03  20.935356  35.119999  30.846342  67.830002  34.700001  33.119999   \n",
       "2012-12-04  20.566071  35.119999  30.894321  68.610001  35.299999  33.320000   \n",
       "2012-12-05  19.242500  35.119999  30.966291  69.599998  35.400002  33.779999   \n",
       "2012-12-06  19.544287  35.119999  30.985483  69.800003  35.139999  33.259998   \n",
       "2012-12-07  19.044643  35.119999  31.441294  69.480003  35.480000  34.130001   \n",
       "\n",
       "Ticker       AMD       AMGN        AMT     AMZN  ...        UNH        UNP  \\\n",
       "date                                             ...                         \n",
       "2012-12-03  2.36  88.400002  74.879997  12.5165  ...  53.889999  60.715000   \n",
       "2012-12-04  2.26  88.330002  74.830002  12.6245  ...  53.540001  61.185001   \n",
       "2012-12-05  2.29  89.010002  74.610001  12.6980  ...  53.840000  61.430000   \n",
       "2012-12-06  2.34  88.540001  74.980003  12.6685  ...  53.650002  61.564999   \n",
       "2012-12-07  2.36  88.320000  75.449997  12.6635  ...  53.869999  61.974998   \n",
       "\n",
       "Ticker            UPS        USB          V         VZ        WBA        WFC  \\\n",
       "date                                                                           \n",
       "2012-12-03  72.269997  32.049999  37.160000  44.099998  34.279999  32.750000   \n",
       "2012-12-04  73.040001  31.430000  36.897499  43.669998  34.270000  32.740002   \n",
       "2012-12-05  73.500000  31.760000  37.014999  44.099998  35.570000  32.980000   \n",
       "2012-12-06  72.930000  31.809999  37.117500  44.450001  35.849998  33.139999   \n",
       "2012-12-07  73.169998  32.020000  37.137501  44.410000  36.099998  33.230000   \n",
       "\n",
       "Ticker            WMT        XOM  \n",
       "date                              \n",
       "2012-12-03  71.339996  87.610001  \n",
       "2012-12-04  72.120003  87.190002  \n",
       "2012-12-05  71.650002  87.730003  \n",
       "2012-12-06  71.589996  88.000000  \n",
       "2012-12-07  72.290001  88.599998  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a880daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct_change = pivot_df.pct_change(1).astype(float)\n",
    "df_pct_change = df_pct_change.replace([np.inf, -np.inf], np.nan)\n",
    "df_pct_change = df_pct_change.fillna(method='ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "78776220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AIG</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AMGN</th>\n",
       "      <th>AMT</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>...</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>UPS</th>\n",
       "      <th>USB</th>\n",
       "      <th>V</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-04</th>\n",
       "      <td>-0.017639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.011499</td>\n",
       "      <td>0.017291</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>-0.042373</td>\n",
       "      <td>-0.000792</td>\n",
       "      <td>-0.000668</td>\n",
       "      <td>0.008629</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006495</td>\n",
       "      <td>0.007741</td>\n",
       "      <td>0.010655</td>\n",
       "      <td>-0.019345</td>\n",
       "      <td>-0.007064</td>\n",
       "      <td>-0.009751</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>0.010934</td>\n",
       "      <td>-0.004794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-05</th>\n",
       "      <td>-0.064357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.014429</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.013805</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>-0.002940</td>\n",
       "      <td>0.005822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.009847</td>\n",
       "      <td>0.037934</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>-0.006517</td>\n",
       "      <td>0.006193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-06</th>\n",
       "      <td>0.015683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>-0.007345</td>\n",
       "      <td>-0.015394</td>\n",
       "      <td>0.021834</td>\n",
       "      <td>-0.005280</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>-0.002323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003529</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>-0.007755</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>0.003078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-07</th>\n",
       "      <td>-0.025565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>-0.004585</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.026158</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>-0.002485</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>-0.000395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.009778</td>\n",
       "      <td>0.006818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker          AAPL  ABBV       ABT       ACN      ADBE       AIG       AMD  \\\n",
       "date                                                                           \n",
       "2012-12-03       NaN   NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2012-12-04 -0.017639   0.0  0.001555  0.011499  0.017291  0.006039 -0.042373   \n",
       "2012-12-05 -0.064357   0.0  0.002330  0.014429  0.002833  0.013805  0.013274   \n",
       "2012-12-06  0.015683   0.0  0.000620  0.002874 -0.007345 -0.015394  0.021834   \n",
       "2012-12-07 -0.025565   0.0  0.014710 -0.004585  0.009676  0.026158  0.008547   \n",
       "\n",
       "Ticker          AMGN       AMT      AMZN  ...       UNH       UNP       UPS  \\\n",
       "date                                      ...                                 \n",
       "2012-12-03       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "2012-12-04 -0.000792 -0.000668  0.008629  ... -0.006495  0.007741  0.010655   \n",
       "2012-12-05  0.007698 -0.002940  0.005822  ...  0.005603  0.004004  0.006298   \n",
       "2012-12-06 -0.005280  0.004959 -0.002323  ... -0.003529  0.002198 -0.007755   \n",
       "2012-12-07 -0.002485  0.006268 -0.000395  ...  0.004101  0.006660  0.003291   \n",
       "\n",
       "Ticker           USB         V        VZ       WBA       WFC       WMT  \\\n",
       "date                                                                     \n",
       "2012-12-03       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2012-12-04 -0.019345 -0.007064 -0.009751 -0.000292 -0.000305  0.010934   \n",
       "2012-12-05  0.010500  0.003185  0.009847  0.037934  0.007330 -0.006517   \n",
       "2012-12-06  0.001574  0.002769  0.007937  0.007872  0.004851 -0.000837   \n",
       "2012-12-07  0.006602  0.000539 -0.000900  0.006974  0.002716  0.009778   \n",
       "\n",
       "Ticker           XOM  \n",
       "date                  \n",
       "2012-12-03       NaN  \n",
       "2012-12-04 -0.004794  \n",
       "2012-12-05  0.006193  \n",
       "2012-12-06  0.003078  \n",
       "2012-12-07  0.006818  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pct_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "10099e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the percentage change function will make the first two rows equal to nan\n",
    "df_pct_change = df_pct_change.tail(len(df_pct_change) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9b5ed2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AIG</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AMGN</th>\n",
       "      <th>AMT</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>...</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>UPS</th>\n",
       "      <th>USB</th>\n",
       "      <th>V</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-04</th>\n",
       "      <td>-0.017639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.011499</td>\n",
       "      <td>0.017291</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>-0.042373</td>\n",
       "      <td>-0.000792</td>\n",
       "      <td>-0.000668</td>\n",
       "      <td>0.008629</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006495</td>\n",
       "      <td>0.007741</td>\n",
       "      <td>0.010655</td>\n",
       "      <td>-0.019345</td>\n",
       "      <td>-0.007064</td>\n",
       "      <td>-0.009751</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>0.010934</td>\n",
       "      <td>-0.004794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-05</th>\n",
       "      <td>-0.064357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.014429</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.013805</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>-0.002940</td>\n",
       "      <td>0.005822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.009847</td>\n",
       "      <td>0.037934</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>-0.006517</td>\n",
       "      <td>0.006193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-06</th>\n",
       "      <td>0.015683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>-0.007345</td>\n",
       "      <td>-0.015394</td>\n",
       "      <td>0.021834</td>\n",
       "      <td>-0.005280</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>-0.002323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003529</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>-0.007755</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>0.003078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-07</th>\n",
       "      <td>-0.025565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>-0.004585</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.026158</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>-0.002485</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>-0.000395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.009778</td>\n",
       "      <td>0.006818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-10</th>\n",
       "      <td>-0.006432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003052</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>-0.022561</td>\n",
       "      <td>-0.016949</td>\n",
       "      <td>0.016078</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>-0.021716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>-0.003748</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>-0.008557</td>\n",
       "      <td>0.006925</td>\n",
       "      <td>-0.005417</td>\n",
       "      <td>-0.001937</td>\n",
       "      <td>-0.002144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker          AAPL  ABBV       ABT       ACN      ADBE       AIG       AMD  \\\n",
       "date                                                                           \n",
       "2012-12-04 -0.017639   0.0  0.001555  0.011499  0.017291  0.006039 -0.042373   \n",
       "2012-12-05 -0.064357   0.0  0.002330  0.014429  0.002833  0.013805  0.013274   \n",
       "2012-12-06  0.015683   0.0  0.000620  0.002874 -0.007345 -0.015394  0.021834   \n",
       "2012-12-07 -0.025565   0.0  0.014710 -0.004585  0.009676  0.026158  0.008547   \n",
       "2012-12-10 -0.006432   0.0 -0.003052  0.000432  0.007610 -0.022561 -0.016949   \n",
       "\n",
       "Ticker          AMGN       AMT      AMZN  ...       UNH       UNP       UPS  \\\n",
       "date                                      ...                                 \n",
       "2012-12-04 -0.000792 -0.000668  0.008629  ... -0.006495  0.007741  0.010655   \n",
       "2012-12-05  0.007698 -0.002940  0.005822  ...  0.005603  0.004004  0.006298   \n",
       "2012-12-06 -0.005280  0.004959 -0.002323  ... -0.003529  0.002198 -0.007755   \n",
       "2012-12-07 -0.002485  0.006268 -0.000395  ...  0.004101  0.006660  0.003291   \n",
       "2012-12-10  0.016078 -0.004374 -0.021716  ...  0.005940  0.010327  0.006970   \n",
       "\n",
       "Ticker           USB         V        VZ       WBA       WFC       WMT  \\\n",
       "date                                                                     \n",
       "2012-12-04 -0.019345 -0.007064 -0.009751 -0.000292 -0.000305  0.010934   \n",
       "2012-12-05  0.010500  0.003185  0.009847  0.037934  0.007330 -0.006517   \n",
       "2012-12-06  0.001574  0.002769  0.007937  0.007872  0.004851 -0.000837   \n",
       "2012-12-07  0.006602  0.000539 -0.000900  0.006974  0.002716  0.009778   \n",
       "2012-12-10 -0.003748  0.000740 -0.008557  0.006925 -0.005417 -0.001937   \n",
       "\n",
       "Ticker           XOM  \n",
       "date                  \n",
       "2012-12-04 -0.004794  \n",
       "2012-12-05  0.006193  \n",
       "2012-12-06  0.003078  \n",
       "2012-12-07  0.006818  \n",
       "2012-12-10 -0.002144  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pct_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b4e2a60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2537, 100)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pct_change.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "22193003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns where there is no change over a longer time period\n",
    "df_pct_change = df_pct_change[df_pct_change.columns[((df_pct_change == 0).mean() <= 0.05)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "71702e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2537, 97)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pct_change.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c9b4bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define autoencoder\n",
    "\n",
    "\n",
    "def defineAutoencoder(num_stock, encoding_dim = 5, verbose=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function for fitting an Autoencoder\n",
    "    \"\"\"\n",
    "\n",
    "    # connect all layers\n",
    "    input = Input(shape=(num_stock,))\n",
    "\n",
    "    encoded = Dense(encoding_dim, kernel_regularizer=regularizers.l2(0.00001),name ='Encoder_Input')(input)\n",
    "\n",
    "    decoded = Dense(num_stock, kernel_regularizer=regularizers.l2(0.00001), name ='Decoder_Input')(encoded)\n",
    "    decoded = Activation(\"linear\", name='Decoder_Activation_function')(decoded)\n",
    "\n",
    "    # construct and compile AE model\n",
    "    autoencoder = Model(inputs=input, outputs=decoded)\n",
    "    adam = optimizers.Adam(lr=0.0005)\n",
    "    autoencoder.compile(optimizer=adam, loss='mean_squared_error')\n",
    "    if verbose!= 0:\n",
    "        autoencoder.summary()\n",
    "\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0e6412ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReconstructionErrorsDF(df_pct_change, reconstructed_data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function for calculating the reconstruction Errors\n",
    "    \"\"\"\n",
    "    array = []\n",
    "    stocks_ranked = []\n",
    "    num_columns = reconstructed_data.shape[1]\n",
    "    for i in range(0, num_columns):\n",
    "        diff = np.linalg.norm((df_pct_change.iloc[:, i] - reconstructed_data[:, i]))  # 2 norm difference\n",
    "        array.append(float(diff))\n",
    "\n",
    "    ranking = np.array(array).argsort()\n",
    "    r = 1\n",
    "    for stock_index in ranking:\n",
    "        stocks_ranked.append([ r\n",
    "                              ,stock_index\n",
    "                              ,df_pct_change.iloc[:, stock_index].name\n",
    "                              ,array[stock_index]\n",
    "                              ])\n",
    "        r = r + 1\n",
    "\n",
    "    columns = ['ranking','stock_index', 'stock_name' ,'recreation_error']\n",
    "    df = pd.DataFrame(stocks_ranked, columns=columns)\n",
    "    df = df.set_index('stock_name')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5a6866b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input parameters\n",
    "hidden_layers = 5\n",
    "batch_size = 500\n",
    "epochs = 500\n",
    "stock_selection_number = 20\n",
    "num_stock = df_pct_change.shape[1]\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "47756d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "df_scaler = preprocessing.MinMaxScaler()\n",
    "df_pct_change_normalised = df_scaler.fit_transform(df_pct_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f5ff4eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Define autoencoder model\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 97)]              0         \n",
      "                                                                 \n",
      " Encoder_Input (Dense)       (None, 5)                 490       \n",
      "                                                                 \n",
      " Decoder_Input (Dense)       (None, 97)                582       \n",
      "                                                                 \n",
      " Decoder_Activation_function  (None, 97)               0         \n",
      "  (Activation)                                                   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,072\n",
      "Trainable params: 1,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SANJANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# define autoencoder\n",
    "print('-' * 25 + 'Define autoencoder model')\n",
    "num_stock = len(df_pct_change.columns)\n",
    "autoencoder = defineAutoencoder(num_stock=num_stock, encoding_dim=hidden_layers, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f2ea5950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Train autoencoder model\n",
      "Epoch 1/500\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.3571\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3214\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2948\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2748\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2589\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2454\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2336\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2227\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2124\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2022\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1920\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1816\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1711\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1603\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1495\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1387\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1280\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1176\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1074\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0976\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0882\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0794\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0711\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0633\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0562\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0496\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0436\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0382\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0334\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0292\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0254\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0221\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0147\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0129\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0113\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0100\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0089\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0079\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0071\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0064\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0058\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0053\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0049\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0045\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0042\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0040\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0036\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0033\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0032\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0032\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0030\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0029\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0029\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0029\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0029\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 104/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0027\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 797us/step - loss: 0.0027\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0027\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0027\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0027\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 206/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 243/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0026\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0026\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0026\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0026\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 308/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0025\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0025\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 324/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0025\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0025\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0025\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 405/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0025\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 410/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0024\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0024\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 485/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0024\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22800998cd0>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train autoencoder\n",
    "print('-' * 25 + 'Train autoencoder model')\n",
    "autoencoder.fit(df_pct_change_normalised, df_pct_change_normalised, shuffle=False, epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4612d951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstruct = autoencoder.predict(df_pct_change_normalised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "154fcc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_real = df_scaler.inverse_transform(reconstruct)\n",
    "df_reconstruct_real = pd.DataFrame(data=reconstruct_real, columns=df_pct_change.columns)\n",
    "df_recreation_error = getReconstructionErrorsDF(df_pct_change=df_pct_change,\n",
    "                                                reconstructed_data=reconstruct_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ac2cbda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>stock_index</th>\n",
       "      <th>recreation_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>JNJ</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.442570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PG</th>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>0.493552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KO</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.496830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCD</th>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>0.499636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USB</th>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>0.502357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>93</td>\n",
       "      <td>69</td>\n",
       "      <td>1.100420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMUS</th>\n",
       "      <td>94</td>\n",
       "      <td>84</td>\n",
       "      <td>1.127238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>95</td>\n",
       "      <td>67</td>\n",
       "      <td>1.606119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>96</td>\n",
       "      <td>85</td>\n",
       "      <td>1.662548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD</th>\n",
       "      <td>97</td>\n",
       "      <td>6</td>\n",
       "      <td>1.688434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ranking  stock_index  recreation_error\n",
       "stock_name                                        \n",
       "JNJ               1           48          0.442570\n",
       "PG                2           73          0.493552\n",
       "KO                3           50          0.496830\n",
       "MCD               4           56          0.499636\n",
       "USB               5           90          0.502357\n",
       "...             ...          ...               ...\n",
       "NVDA             93           69          1.100420\n",
       "TMUS             94           84          1.127238\n",
       "NFLX             95           67          1.606119\n",
       "TSLA             96           85          1.662548\n",
       "AMD              97            6          1.688434\n",
       "\n",
       "[97 rows x 3 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recreation_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "da42a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_stocks = df_recreation_error.head(stock_selection_number).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1066f924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_selection_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5bae1cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['JNJ', 'PG', 'KO', 'MCD', 'USB', 'JPM', 'GD', 'VZ', 'MMM', 'PEP', 'CL',\n",
       "       'LIN', 'DHR', 'HON', 'LMT', 'MDT', 'V', 'RTX', 'T', 'COST'],\n",
       "      dtype='object', name='stock_name')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "782709d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['JNJ', 'PG', 'KO', 'MCD', 'USB', 'JPM', 'GD', 'VZ', 'MMM', 'PEP', 'CL',\n",
      "       'LIN', 'DHR', 'HON', 'LMT', 'MDT', 'V', 'RTX', 'T', 'COST'],\n",
      "      dtype='object', name='stock_name')\n"
     ]
    }
   ],
   "source": [
    "selected_stocks = filtered_stocks\n",
    "print(selected_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f9ddfcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-03</td>\n",
       "      <td>21.201786</td>\n",
       "      <td>21.235357</td>\n",
       "      <td>20.910713</td>\n",
       "      <td>20.935356</td>\n",
       "      <td>17.951883</td>\n",
       "      <td>364280000</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-12-04</td>\n",
       "      <td>20.778570</td>\n",
       "      <td>20.778570</td>\n",
       "      <td>20.433214</td>\n",
       "      <td>20.566071</td>\n",
       "      <td>17.635214</td>\n",
       "      <td>557068400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-12-05</td>\n",
       "      <td>20.318214</td>\n",
       "      <td>20.330357</td>\n",
       "      <td>19.241785</td>\n",
       "      <td>19.242500</td>\n",
       "      <td>16.500261</td>\n",
       "      <td>1044638000</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-06</td>\n",
       "      <td>18.890715</td>\n",
       "      <td>19.761070</td>\n",
       "      <td>18.522499</td>\n",
       "      <td>19.544287</td>\n",
       "      <td>16.759045</td>\n",
       "      <td>1177212400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-07</td>\n",
       "      <td>19.764286</td>\n",
       "      <td>19.828571</td>\n",
       "      <td>18.928572</td>\n",
       "      <td>19.044643</td>\n",
       "      <td>16.330601</td>\n",
       "      <td>787040800</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2012-12-03  21.201786  21.235357  20.910713  20.935356  17.951883   \n",
       "1  2012-12-04  20.778570  20.778570  20.433214  20.566071  17.635214   \n",
       "2  2012-12-05  20.318214  20.330357  19.241785  19.242500  16.500261   \n",
       "3  2012-12-06  18.890715  19.761070  18.522499  19.544287  16.759045   \n",
       "4  2012-12-07  19.764286  19.828571  18.928572  19.044643  16.330601   \n",
       "\n",
       "       Volume Ticker  \n",
       "0   364280000   AAPL  \n",
       "1   557068400   AAPL  \n",
       "2  1044638000   AAPL  \n",
       "3  1177212400   AAPL  \n",
       "4   787040800   AAPL  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0adc81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = initial_df.drop('Adj Close', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3fe3ddd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'ABBV', 'ABT', 'ACN', 'ADBE', 'AIG', 'AMD', 'AMGN', 'AMT',\n",
       "       'AMZN', 'AVGO', 'AXP', 'BA', 'BAC', 'BK', 'BKNG', 'BLK', 'BMY',\n",
       "       'C', 'CAT', 'CHTR', 'CL', 'CMCSA', 'COF', 'COP', 'COST', 'CRM',\n",
       "       'CSCO', 'CVS', 'CVX', 'DHR', 'DIS', 'DOW', 'DUK', 'EMR', 'EXC',\n",
       "       'F', 'FDX', 'GD', 'GE', 'GILD', 'GM', 'GOOG', 'GOOGL', 'GS', 'HD',\n",
       "       'HON', 'IBM', 'INTC', 'JNJ', 'JPM', 'KHC', 'KO', 'LIN', 'LLY',\n",
       "       'LMT', 'LOW', 'MA', 'MCD', 'MDLZ', 'MDT', 'MET', 'META', 'MMM',\n",
       "       'MO', 'MRK', 'MS', 'MSFT', 'NEE', 'NFLX', 'NKE', 'NVDA', 'ORCL',\n",
       "       'PEP', 'PFE', 'PG', 'PM', 'PYPL', 'QCOM', 'RTX', 'SBUX', 'SCHW',\n",
       "       'SO', 'SPG', 'T', 'TGT', 'TMO', 'TMUS', 'TSLA', 'TXN', 'UNH',\n",
       "       'UNP', 'UPS', 'USB', 'V', 'VZ', 'WBA', 'WFC', 'WMT', 'XOM'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_df['Ticker'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9d49bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = initial_df[initial_df['Ticker'].isin(selected_stocks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f7e38e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CL', 'COST', 'DHR', 'GD', 'HON', 'JNJ', 'JPM', 'KO', 'LIN', 'LMT',\n",
       "       'MCD', 'MDT', 'MMM', 'PEP', 'PG', 'RTX', 'T', 'USB', 'V', 'VZ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6cc72dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ta\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f432eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Function for adding technical indicators\n",
    "\n",
    "def add_features(data, feature_list, short_names):\n",
    "\n",
    "    data_col_names = list(data.columns)\n",
    "    filter_names = data_col_names + feature_list\n",
    "    col_rename = data_col_names +  short_names\n",
    "    \n",
    "    # Add technical indicators using the ta Library\n",
    "    data = add_all_ta_features(data, open=\"Open\", high=\"High\", \n",
    "    low=\"Low\", close=\"Close\", volume=\"Volume\") \n",
    "    \n",
    "    # Filter the Indicators with the required features\n",
    "    data = data[filter_names]\n",
    "    data.columns = col_rename # rename the columns to use shortened indicator names\n",
    "    data = data.dropna()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# List of Features to add\n",
    "feature_list= ['volatility_atr','volatility_bbw','volume_obv','volume_cmf',\n",
    "               'trend_macd', 'trend_adx', 'trend_sma_fast', \n",
    "               'trend_ema_fast', 'trend_cci', 'momentum_rsi']\n",
    "\n",
    "# Short names of the features\n",
    "short_names = ['atr', 'bbw','obv','cmf','macd', 'adx', 'sma', 'ema', 'cci', 'rsi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "aa5a55e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SANJANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ta\\trend.py:780: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "C:\\Users\\SANJANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ta\\trend.py:785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n"
     ]
    }
   ],
   "source": [
    "# Add Indicators to our dataset\n",
    "data_with_features = data.copy()\n",
    "\n",
    "data_with_features = add_features(data_with_features, feature_list, short_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b47df14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>atr</th>\n",
       "      <th>bbw</th>\n",
       "      <th>obv</th>\n",
       "      <th>cmf</th>\n",
       "      <th>macd</th>\n",
       "      <th>adx</th>\n",
       "      <th>sma</th>\n",
       "      <th>ema</th>\n",
       "      <th>cci</th>\n",
       "      <th>rsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53303</th>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>53.174999</td>\n",
       "      <td>53.320000</td>\n",
       "      <td>52.945000</td>\n",
       "      <td>53.064999</td>\n",
       "      <td>1967800</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.606628</td>\n",
       "      <td>3.809607</td>\n",
       "      <td>-10729600</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>-0.134796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.837917</td>\n",
       "      <td>53.058077</td>\n",
       "      <td>16.567053</td>\n",
       "      <td>48.360834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53304</th>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>53.150002</td>\n",
       "      <td>53.695000</td>\n",
       "      <td>53.025002</td>\n",
       "      <td>53.695000</td>\n",
       "      <td>2521600</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.612965</td>\n",
       "      <td>3.657817</td>\n",
       "      <td>-8208000</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>-0.074002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.933333</td>\n",
       "      <td>53.156065</td>\n",
       "      <td>85.758151</td>\n",
       "      <td>54.995763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53305</th>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>53.779999</td>\n",
       "      <td>53.959999</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>53.544998</td>\n",
       "      <td>2032000</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.598668</td>\n",
       "      <td>3.678000</td>\n",
       "      <td>-10240000</td>\n",
       "      <td>0.023291</td>\n",
       "      <td>-0.037495</td>\n",
       "      <td>24.425343</td>\n",
       "      <td>53.018333</td>\n",
       "      <td>53.215901</td>\n",
       "      <td>120.113237</td>\n",
       "      <td>53.241689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53306</th>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>53.654999</td>\n",
       "      <td>54.060001</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>53.965000</td>\n",
       "      <td>1464400</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.594802</td>\n",
       "      <td>4.004830</td>\n",
       "      <td>-8775600</td>\n",
       "      <td>0.083019</td>\n",
       "      <td>0.025040</td>\n",
       "      <td>23.674760</td>\n",
       "      <td>53.152500</td>\n",
       "      <td>53.331147</td>\n",
       "      <td>137.797634</td>\n",
       "      <td>57.344092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53307</th>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>53.650002</td>\n",
       "      <td>53.955002</td>\n",
       "      <td>53.404999</td>\n",
       "      <td>53.869999</td>\n",
       "      <td>2236000</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.591322</td>\n",
       "      <td>4.217783</td>\n",
       "      <td>-11011600</td>\n",
       "      <td>0.162404</td>\n",
       "      <td>0.066171</td>\n",
       "      <td>22.768322</td>\n",
       "      <td>53.255417</td>\n",
       "      <td>53.414047</td>\n",
       "      <td>108.474006</td>\n",
       "      <td>56.144187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240740</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>38.310001</td>\n",
       "      <td>38.540001</td>\n",
       "      <td>37.919998</td>\n",
       "      <td>38.410000</td>\n",
       "      <td>16918300</td>\n",
       "      <td>VZ</td>\n",
       "      <td>0.789779</td>\n",
       "      <td>6.305874</td>\n",
       "      <td>11949677290</td>\n",
       "      <td>0.095259</td>\n",
       "      <td>-0.033100</td>\n",
       "      <td>10.992571</td>\n",
       "      <td>37.597500</td>\n",
       "      <td>37.747024</td>\n",
       "      <td>78.205062</td>\n",
       "      <td>56.449715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240741</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>38.490002</td>\n",
       "      <td>39.400002</td>\n",
       "      <td>38.320000</td>\n",
       "      <td>39.250000</td>\n",
       "      <td>25315900</td>\n",
       "      <td>VZ</td>\n",
       "      <td>0.818801</td>\n",
       "      <td>7.141455</td>\n",
       "      <td>11974993190</td>\n",
       "      <td>0.161281</td>\n",
       "      <td>0.089248</td>\n",
       "      <td>12.037531</td>\n",
       "      <td>37.776667</td>\n",
       "      <td>37.978251</td>\n",
       "      <td>159.709540</td>\n",
       "      <td>62.900383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240742</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>39.660000</td>\n",
       "      <td>38.590000</td>\n",
       "      <td>38.810001</td>\n",
       "      <td>21793200</td>\n",
       "      <td>VZ</td>\n",
       "      <td>0.843921</td>\n",
       "      <td>7.424203</td>\n",
       "      <td>11953199990</td>\n",
       "      <td>0.112142</td>\n",
       "      <td>0.148987</td>\n",
       "      <td>13.249353</td>\n",
       "      <td>37.894167</td>\n",
       "      <td>38.106213</td>\n",
       "      <td>146.369938</td>\n",
       "      <td>58.050036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240743</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>38.900002</td>\n",
       "      <td>39.529999</td>\n",
       "      <td>38.810001</td>\n",
       "      <td>39.259998</td>\n",
       "      <td>17347000</td>\n",
       "      <td>VZ</td>\n",
       "      <td>0.831529</td>\n",
       "      <td>7.695248</td>\n",
       "      <td>11970546990</td>\n",
       "      <td>0.082521</td>\n",
       "      <td>0.229991</td>\n",
       "      <td>14.374616</td>\n",
       "      <td>38.003333</td>\n",
       "      <td>38.283718</td>\n",
       "      <td>158.040912</td>\n",
       "      <td>61.333953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240744</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>39.310001</td>\n",
       "      <td>39.689999</td>\n",
       "      <td>39.070000</td>\n",
       "      <td>39.400002</td>\n",
       "      <td>44007200</td>\n",
       "      <td>VZ</td>\n",
       "      <td>0.810376</td>\n",
       "      <td>8.448232</td>\n",
       "      <td>12014554190</td>\n",
       "      <td>0.098244</td>\n",
       "      <td>0.302003</td>\n",
       "      <td>15.578860</td>\n",
       "      <td>38.131667</td>\n",
       "      <td>38.455454</td>\n",
       "      <td>159.989685</td>\n",
       "      <td>62.322186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50735 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date       Open       High        Low      Close    Volume  \\\n",
       "53303   2013-01-09  53.174999  53.320000  52.945000  53.064999   1967800   \n",
       "53304   2013-01-10  53.150002  53.695000  53.025002  53.695000   2521600   \n",
       "53305   2013-01-11  53.779999  53.959999  53.490002  53.544998   2032000   \n",
       "53306   2013-01-14  53.654999  54.060001  53.500000  53.965000   1464400   \n",
       "53307   2013-01-15  53.650002  53.955002  53.404999  53.869999   2236000   \n",
       "...            ...        ...        ...        ...        ...       ...   \n",
       "240740  2022-12-23  38.310001  38.540001  37.919998  38.410000  16918300   \n",
       "240741  2022-12-27  38.490002  39.400002  38.320000  39.250000  25315900   \n",
       "240742  2022-12-28  39.189999  39.660000  38.590000  38.810001  21793200   \n",
       "240743  2022-12-29  38.900002  39.529999  38.810001  39.259998  17347000   \n",
       "240744  2022-12-30  39.310001  39.689999  39.070000  39.400002  44007200   \n",
       "\n",
       "       Ticker       atr       bbw          obv       cmf      macd        adx  \\\n",
       "53303      CL  0.606628  3.809607    -10729600  0.002008 -0.134796   0.000000   \n",
       "53304      CL  0.612965  3.657817     -8208000  0.022100 -0.074002   0.000000   \n",
       "53305      CL  0.598668  3.678000    -10240000  0.023291 -0.037495  24.425343   \n",
       "53306      CL  0.594802  4.004830     -8775600  0.083019  0.025040  23.674760   \n",
       "53307      CL  0.591322  4.217783    -11011600  0.162404  0.066171  22.768322   \n",
       "...       ...       ...       ...          ...       ...       ...        ...   \n",
       "240740     VZ  0.789779  6.305874  11949677290  0.095259 -0.033100  10.992571   \n",
       "240741     VZ  0.818801  7.141455  11974993190  0.161281  0.089248  12.037531   \n",
       "240742     VZ  0.843921  7.424203  11953199990  0.112142  0.148987  13.249353   \n",
       "240743     VZ  0.831529  7.695248  11970546990  0.082521  0.229991  14.374616   \n",
       "240744     VZ  0.810376  8.448232  12014554190  0.098244  0.302003  15.578860   \n",
       "\n",
       "              sma        ema         cci        rsi  \n",
       "53303   52.837917  53.058077   16.567053  48.360834  \n",
       "53304   52.933333  53.156065   85.758151  54.995763  \n",
       "53305   53.018333  53.215901  120.113237  53.241689  \n",
       "53306   53.152500  53.331147  137.797634  57.344092  \n",
       "53307   53.255417  53.414047  108.474006  56.144187  \n",
       "...           ...        ...         ...        ...  \n",
       "240740  37.597500  37.747024   78.205062  56.449715  \n",
       "240741  37.776667  37.978251  159.709540  62.900383  \n",
       "240742  37.894167  38.106213  146.369938  58.050036  \n",
       "240743  38.003333  38.283718  158.040912  61.333953  \n",
       "240744  38.131667  38.455454  159.989685  62.322186  \n",
       "\n",
       "[50735 rows x 17 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a7330576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>atr</th>\n",
       "      <th>bbw</th>\n",
       "      <th>obv</th>\n",
       "      <th>cmf</th>\n",
       "      <th>macd</th>\n",
       "      <th>adx</th>\n",
       "      <th>sma</th>\n",
       "      <th>ema</th>\n",
       "      <th>cci</th>\n",
       "      <th>rsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53303</th>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>53.174999</td>\n",
       "      <td>53.320000</td>\n",
       "      <td>52.945000</td>\n",
       "      <td>53.064999</td>\n",
       "      <td>1967800</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.606628</td>\n",
       "      <td>3.809607</td>\n",
       "      <td>-10729600</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>-0.134796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.837917</td>\n",
       "      <td>53.058077</td>\n",
       "      <td>16.567053</td>\n",
       "      <td>48.360834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53304</th>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>53.150002</td>\n",
       "      <td>53.695000</td>\n",
       "      <td>53.025002</td>\n",
       "      <td>53.695000</td>\n",
       "      <td>2521600</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.612965</td>\n",
       "      <td>3.657817</td>\n",
       "      <td>-8208000</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>-0.074002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.933333</td>\n",
       "      <td>53.156065</td>\n",
       "      <td>85.758151</td>\n",
       "      <td>54.995763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53305</th>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>53.779999</td>\n",
       "      <td>53.959999</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>53.544998</td>\n",
       "      <td>2032000</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.598668</td>\n",
       "      <td>3.678000</td>\n",
       "      <td>-10240000</td>\n",
       "      <td>0.023291</td>\n",
       "      <td>-0.037495</td>\n",
       "      <td>24.425343</td>\n",
       "      <td>53.018333</td>\n",
       "      <td>53.215901</td>\n",
       "      <td>120.113237</td>\n",
       "      <td>53.241689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53306</th>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>53.654999</td>\n",
       "      <td>54.060001</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>53.965000</td>\n",
       "      <td>1464400</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.594802</td>\n",
       "      <td>4.004830</td>\n",
       "      <td>-8775600</td>\n",
       "      <td>0.083019</td>\n",
       "      <td>0.025040</td>\n",
       "      <td>23.674760</td>\n",
       "      <td>53.152500</td>\n",
       "      <td>53.331147</td>\n",
       "      <td>137.797634</td>\n",
       "      <td>57.344092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53307</th>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>53.650002</td>\n",
       "      <td>53.955002</td>\n",
       "      <td>53.404999</td>\n",
       "      <td>53.869999</td>\n",
       "      <td>2236000</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.591322</td>\n",
       "      <td>4.217783</td>\n",
       "      <td>-11011600</td>\n",
       "      <td>0.162404</td>\n",
       "      <td>0.066171</td>\n",
       "      <td>22.768322</td>\n",
       "      <td>53.255417</td>\n",
       "      <td>53.414047</td>\n",
       "      <td>108.474006</td>\n",
       "      <td>56.144187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date       Open       High        Low      Close   Volume Ticker  \\\n",
       "53303  2013-01-09  53.174999  53.320000  52.945000  53.064999  1967800     CL   \n",
       "53304  2013-01-10  53.150002  53.695000  53.025002  53.695000  2521600     CL   \n",
       "53305  2013-01-11  53.779999  53.959999  53.490002  53.544998  2032000     CL   \n",
       "53306  2013-01-14  53.654999  54.060001  53.500000  53.965000  1464400     CL   \n",
       "53307  2013-01-15  53.650002  53.955002  53.404999  53.869999  2236000     CL   \n",
       "\n",
       "            atr       bbw       obv       cmf      macd        adx        sma  \\\n",
       "53303  0.606628  3.809607 -10729600  0.002008 -0.134796   0.000000  52.837917   \n",
       "53304  0.612965  3.657817  -8208000  0.022100 -0.074002   0.000000  52.933333   \n",
       "53305  0.598668  3.678000 -10240000  0.023291 -0.037495  24.425343  53.018333   \n",
       "53306  0.594802  4.004830  -8775600  0.083019  0.025040  23.674760  53.152500   \n",
       "53307  0.591322  4.217783 -11011600  0.162404  0.066171  22.768322  53.255417   \n",
       "\n",
       "             ema         cci        rsi  \n",
       "53303  53.058077   16.567053  48.360834  \n",
       "53304  53.156065   85.758151  54.995763  \n",
       "53305  53.215901  120.113237  53.241689  \n",
       "53306  53.331147  137.797634  57.344092  \n",
       "53307  53.414047  108.474006  56.144187  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "35ffb1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_features = data_with_features.rename(columns={'Date': 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "21d868ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>atr</th>\n",
       "      <th>bbw</th>\n",
       "      <th>obv</th>\n",
       "      <th>cmf</th>\n",
       "      <th>macd</th>\n",
       "      <th>adx</th>\n",
       "      <th>sma</th>\n",
       "      <th>ema</th>\n",
       "      <th>cci</th>\n",
       "      <th>rsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53303</th>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>53.174999</td>\n",
       "      <td>53.320000</td>\n",
       "      <td>52.945000</td>\n",
       "      <td>53.064999</td>\n",
       "      <td>1967800</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.606628</td>\n",
       "      <td>3.809607</td>\n",
       "      <td>-10729600</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>-0.134796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.837917</td>\n",
       "      <td>53.058077</td>\n",
       "      <td>16.567053</td>\n",
       "      <td>48.360834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53304</th>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>53.150002</td>\n",
       "      <td>53.695000</td>\n",
       "      <td>53.025002</td>\n",
       "      <td>53.695000</td>\n",
       "      <td>2521600</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.612965</td>\n",
       "      <td>3.657817</td>\n",
       "      <td>-8208000</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>-0.074002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.933333</td>\n",
       "      <td>53.156065</td>\n",
       "      <td>85.758151</td>\n",
       "      <td>54.995763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53305</th>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>53.779999</td>\n",
       "      <td>53.959999</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>53.544998</td>\n",
       "      <td>2032000</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.598668</td>\n",
       "      <td>3.678000</td>\n",
       "      <td>-10240000</td>\n",
       "      <td>0.023291</td>\n",
       "      <td>-0.037495</td>\n",
       "      <td>24.425343</td>\n",
       "      <td>53.018333</td>\n",
       "      <td>53.215901</td>\n",
       "      <td>120.113237</td>\n",
       "      <td>53.241689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53306</th>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>53.654999</td>\n",
       "      <td>54.060001</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>53.965000</td>\n",
       "      <td>1464400</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.594802</td>\n",
       "      <td>4.004830</td>\n",
       "      <td>-8775600</td>\n",
       "      <td>0.083019</td>\n",
       "      <td>0.025040</td>\n",
       "      <td>23.674760</td>\n",
       "      <td>53.152500</td>\n",
       "      <td>53.331147</td>\n",
       "      <td>137.797634</td>\n",
       "      <td>57.344092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53307</th>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>53.650002</td>\n",
       "      <td>53.955002</td>\n",
       "      <td>53.404999</td>\n",
       "      <td>53.869999</td>\n",
       "      <td>2236000</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.591322</td>\n",
       "      <td>4.217783</td>\n",
       "      <td>-11011600</td>\n",
       "      <td>0.162404</td>\n",
       "      <td>0.066171</td>\n",
       "      <td>22.768322</td>\n",
       "      <td>53.255417</td>\n",
       "      <td>53.414047</td>\n",
       "      <td>108.474006</td>\n",
       "      <td>56.144187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date       Open       High        Low      Close   Volume Ticker  \\\n",
       "53303  2013-01-09  53.174999  53.320000  52.945000  53.064999  1967800     CL   \n",
       "53304  2013-01-10  53.150002  53.695000  53.025002  53.695000  2521600     CL   \n",
       "53305  2013-01-11  53.779999  53.959999  53.490002  53.544998  2032000     CL   \n",
       "53306  2013-01-14  53.654999  54.060001  53.500000  53.965000  1464400     CL   \n",
       "53307  2013-01-15  53.650002  53.955002  53.404999  53.869999  2236000     CL   \n",
       "\n",
       "            atr       bbw       obv       cmf      macd        adx        sma  \\\n",
       "53303  0.606628  3.809607 -10729600  0.002008 -0.134796   0.000000  52.837917   \n",
       "53304  0.612965  3.657817  -8208000  0.022100 -0.074002   0.000000  52.933333   \n",
       "53305  0.598668  3.678000 -10240000  0.023291 -0.037495  24.425343  53.018333   \n",
       "53306  0.594802  4.004830  -8775600  0.083019  0.025040  23.674760  53.152500   \n",
       "53307  0.591322  4.217783 -11011600  0.162404  0.066171  22.768322  53.255417   \n",
       "\n",
       "             ema         cci        rsi  \n",
       "53303  53.058077   16.567053  48.360834  \n",
       "53304  53.156065   85.758151  54.995763  \n",
       "53305  53.215901  120.113237  53.241689  \n",
       "53306  53.331147  137.797634  57.344092  \n",
       "53307  53.414047  108.474006  56.144187  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2ac2d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding covariance matrix\n",
    "\n",
    "\n",
    "def add_cov_matrix(df):\n",
    "    \"\"\"\n",
    "    Function to add Coveriance Matrices as part of the defined states\n",
    "    \"\"\"\n",
    "    # Sort the data and index by date and tic\n",
    "    df=df.sort_values(['date','Ticker'],ignore_index=True) \n",
    "    df.index = df.date.factorize()[0]\n",
    "    \n",
    "    cov_list = [] # create empty list for storing coveriance matrices at each time step\n",
    "    \n",
    "    # look back for constructing the coveriance matrix is one year\n",
    "    lookback=252\n",
    "    for i in range(lookback,len(df.index.unique())):\n",
    "        data_lookback = df.loc[i-lookback:i,:]\n",
    "        price_lookback=data_lookback.pivot_table(index = 'date',columns = 'Ticker', values = 'Close')\n",
    "        return_lookback = price_lookback.pct_change().dropna()\n",
    "        covs = return_lookback.cov().values \n",
    "        covs = covs#/covs.max()\n",
    "        cov_list.append(covs)\n",
    "        \n",
    "    df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list})\n",
    "    df = df.merge(df_cov, on='date')\n",
    "    df = df.sort_values(['date','Ticker']).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3da877b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Covariance Matrices to our dataset\n",
    "data_with_features_covs = data_with_features.copy()\n",
    "data_with_features_covs = add_cov_matrix(data_with_features_covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ab569c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>atr</th>\n",
       "      <th>bbw</th>\n",
       "      <th>obv</th>\n",
       "      <th>cmf</th>\n",
       "      <th>macd</th>\n",
       "      <th>adx</th>\n",
       "      <th>sma</th>\n",
       "      <th>ema</th>\n",
       "      <th>cci</th>\n",
       "      <th>rsi</th>\n",
       "      <th>cov_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>65.010002</td>\n",
       "      <td>65.430000</td>\n",
       "      <td>64.879997</td>\n",
       "      <td>65.370003</td>\n",
       "      <td>2183700</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.736201</td>\n",
       "      <td>2.917910</td>\n",
       "      <td>59133500</td>\n",
       "      <td>0.140533</td>\n",
       "      <td>0.589751</td>\n",
       "      <td>26.368171</td>\n",
       "      <td>65.665834</td>\n",
       "      <td>65.550861</td>\n",
       "      <td>-36.130018</td>\n",
       "      <td>54.933937</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>123.720001</td>\n",
       "      <td>123.970001</td>\n",
       "      <td>122.970001</td>\n",
       "      <td>123.820000</td>\n",
       "      <td>1767900</td>\n",
       "      <td>COST</td>\n",
       "      <td>1.433317</td>\n",
       "      <td>4.010875</td>\n",
       "      <td>385073300</td>\n",
       "      <td>0.175502</td>\n",
       "      <td>1.509197</td>\n",
       "      <td>29.628245</td>\n",
       "      <td>124.313333</td>\n",
       "      <td>124.062547</td>\n",
       "      <td>-2.234842</td>\n",
       "      <td>57.565631</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>56.315392</td>\n",
       "      <td>56.444275</td>\n",
       "      <td>55.754360</td>\n",
       "      <td>55.928734</td>\n",
       "      <td>3117061</td>\n",
       "      <td>DHR</td>\n",
       "      <td>0.673827</td>\n",
       "      <td>4.568752</td>\n",
       "      <td>629198375</td>\n",
       "      <td>-0.035569</td>\n",
       "      <td>0.580076</td>\n",
       "      <td>30.145718</td>\n",
       "      <td>56.503033</td>\n",
       "      <td>56.389011</td>\n",
       "      <td>-27.073061</td>\n",
       "      <td>51.823937</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>91.089996</td>\n",
       "      <td>91.360001</td>\n",
       "      <td>90.019997</td>\n",
       "      <td>90.339996</td>\n",
       "      <td>1198600</td>\n",
       "      <td>GD</td>\n",
       "      <td>1.073160</td>\n",
       "      <td>8.936027</td>\n",
       "      <td>1332459783</td>\n",
       "      <td>0.174849</td>\n",
       "      <td>1.114092</td>\n",
       "      <td>24.278320</td>\n",
       "      <td>90.815000</td>\n",
       "      <td>90.598526</td>\n",
       "      <td>44.496106</td>\n",
       "      <td>55.851273</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>82.638069</td>\n",
       "      <td>83.009888</td>\n",
       "      <td>2430852</td>\n",
       "      <td>HON</td>\n",
       "      <td>0.994786</td>\n",
       "      <td>4.271538</td>\n",
       "      <td>1557103883</td>\n",
       "      <td>-0.040978</td>\n",
       "      <td>0.525893</td>\n",
       "      <td>14.602989</td>\n",
       "      <td>84.121355</td>\n",
       "      <td>83.903915</td>\n",
       "      <td>-42.299743</td>\n",
       "      <td>47.762318</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45715</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>100.279999</td>\n",
       "      <td>101.010002</td>\n",
       "      <td>99.779999</td>\n",
       "      <td>100.919998</td>\n",
       "      <td>2984100</td>\n",
       "      <td>RTX</td>\n",
       "      <td>1.710921</td>\n",
       "      <td>3.791303</td>\n",
       "      <td>8388578676</td>\n",
       "      <td>0.063938</td>\n",
       "      <td>1.010825</td>\n",
       "      <td>14.130540</td>\n",
       "      <td>99.176667</td>\n",
       "      <td>99.443249</td>\n",
       "      <td>116.001722</td>\n",
       "      <td>61.402890</td>\n",
       "      <td>[[0.0001622733871503801, 0.0001196456385651904...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45716</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>18.480000</td>\n",
       "      <td>18.219999</td>\n",
       "      <td>18.410000</td>\n",
       "      <td>26204200</td>\n",
       "      <td>T</td>\n",
       "      <td>0.346544</td>\n",
       "      <td>9.359277</td>\n",
       "      <td>10466197590</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>-0.079796</td>\n",
       "      <td>21.834460</td>\n",
       "      <td>18.338333</td>\n",
       "      <td>18.437117</td>\n",
       "      <td>-44.059396</td>\n",
       "      <td>47.847232</td>\n",
       "      <td>[[0.0001622733871503801, 0.0001196456385651904...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45717</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>43.400002</td>\n",
       "      <td>43.799999</td>\n",
       "      <td>43.279999</td>\n",
       "      <td>43.610001</td>\n",
       "      <td>5737900</td>\n",
       "      <td>USB</td>\n",
       "      <td>0.841648</td>\n",
       "      <td>7.495823</td>\n",
       "      <td>11224326390</td>\n",
       "      <td>0.053584</td>\n",
       "      <td>-0.043884</td>\n",
       "      <td>11.191549</td>\n",
       "      <td>42.925000</td>\n",
       "      <td>43.252141</td>\n",
       "      <td>34.514776</td>\n",
       "      <td>52.703524</td>\n",
       "      <td>[[0.0001622733871503801, 0.0001196456385651904...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45718</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>206.309998</td>\n",
       "      <td>208.039993</td>\n",
       "      <td>205.699997</td>\n",
       "      <td>207.759995</td>\n",
       "      <td>4159400</td>\n",
       "      <td>V</td>\n",
       "      <td>3.791076</td>\n",
       "      <td>6.862015</td>\n",
       "      <td>12457940590</td>\n",
       "      <td>-0.087997</td>\n",
       "      <td>-0.201309</td>\n",
       "      <td>9.991681</td>\n",
       "      <td>206.925001</td>\n",
       "      <td>207.348775</td>\n",
       "      <td>-38.306813</td>\n",
       "      <td>50.522009</td>\n",
       "      <td>[[0.0001622733871503801, 0.0001196456385651904...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45719</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>39.310001</td>\n",
       "      <td>39.689999</td>\n",
       "      <td>39.070000</td>\n",
       "      <td>39.400002</td>\n",
       "      <td>44007200</td>\n",
       "      <td>VZ</td>\n",
       "      <td>0.810376</td>\n",
       "      <td>8.448232</td>\n",
       "      <td>12014554190</td>\n",
       "      <td>0.098244</td>\n",
       "      <td>0.302003</td>\n",
       "      <td>15.578860</td>\n",
       "      <td>38.131667</td>\n",
       "      <td>38.455454</td>\n",
       "      <td>159.989685</td>\n",
       "      <td>62.322186</td>\n",
       "      <td>[[0.0001622733871503801, 0.0001196456385651904...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45720 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date        Open        High         Low       Close    Volume  \\\n",
       "0      2013-12-03   65.010002   65.430000   64.879997   65.370003   2183700   \n",
       "1      2013-12-03  123.720001  123.970001  122.970001  123.820000   1767900   \n",
       "2      2013-12-03   56.315392   56.444275   55.754360   55.928734   3117061   \n",
       "3      2013-12-03   91.089996   91.360001   90.019997   90.339996   1198600   \n",
       "4      2013-12-03   83.848846   83.848846   82.638069   83.009888   2430852   \n",
       "...           ...         ...         ...         ...         ...       ...   \n",
       "45715  2022-12-30  100.279999  101.010002   99.779999  100.919998   2984100   \n",
       "45716  2022-12-30   18.420000   18.480000   18.219999   18.410000  26204200   \n",
       "45717  2022-12-30   43.400002   43.799999   43.279999   43.610001   5737900   \n",
       "45718  2022-12-30  206.309998  208.039993  205.699997  207.759995   4159400   \n",
       "45719  2022-12-30   39.310001   39.689999   39.070000   39.400002  44007200   \n",
       "\n",
       "      Ticker       atr       bbw          obv       cmf      macd        adx  \\\n",
       "0         CL  0.736201  2.917910     59133500  0.140533  0.589751  26.368171   \n",
       "1       COST  1.433317  4.010875    385073300  0.175502  1.509197  29.628245   \n",
       "2        DHR  0.673827  4.568752    629198375 -0.035569  0.580076  30.145718   \n",
       "3         GD  1.073160  8.936027   1332459783  0.174849  1.114092  24.278320   \n",
       "4        HON  0.994786  4.271538   1557103883 -0.040978  0.525893  14.602989   \n",
       "...      ...       ...       ...          ...       ...       ...        ...   \n",
       "45715    RTX  1.710921  3.791303   8388578676  0.063938  1.010825  14.130540   \n",
       "45716      T  0.346544  9.359277  10466197590  0.145833 -0.079796  21.834460   \n",
       "45717    USB  0.841648  7.495823  11224326390  0.053584 -0.043884  11.191549   \n",
       "45718      V  3.791076  6.862015  12457940590 -0.087997 -0.201309   9.991681   \n",
       "45719     VZ  0.810376  8.448232  12014554190  0.098244  0.302003  15.578860   \n",
       "\n",
       "              sma         ema         cci        rsi  \\\n",
       "0       65.665834   65.550861  -36.130018  54.933937   \n",
       "1      124.313333  124.062547   -2.234842  57.565631   \n",
       "2       56.503033   56.389011  -27.073061  51.823937   \n",
       "3       90.815000   90.598526   44.496106  55.851273   \n",
       "4       84.121355   83.903915  -42.299743  47.762318   \n",
       "...           ...         ...         ...        ...   \n",
       "45715   99.176667   99.443249  116.001722  61.402890   \n",
       "45716   18.338333   18.437117  -44.059396  47.847232   \n",
       "45717   42.925000   43.252141   34.514776  52.703524   \n",
       "45718  206.925001  207.348775  -38.306813  50.522009   \n",
       "45719   38.131667   38.455454  159.989685  62.322186   \n",
       "\n",
       "                                                cov_list  \n",
       "0      [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "1      [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "2      [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "3      [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "4      [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "...                                                  ...  \n",
       "45715  [[0.0001622733871503801, 0.0001196456385651904...  \n",
       "45716  [[0.0001622733871503801, 0.0001196456385651904...  \n",
       "45717  [[0.0001622733871503801, 0.0001196456385651904...  \n",
       "45718  [[0.0001622733871503801, 0.0001196456385651904...  \n",
       "45719  [[0.0001622733871503801, 0.0001196456385651904...  \n",
       "\n",
       "[45720 rows x 18 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_features_covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "79184c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lstm autoencoder recreate sequence\n",
    "from numpy import array\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "08460d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>atr</th>\n",
       "      <th>bbw</th>\n",
       "      <th>obv</th>\n",
       "      <th>cmf</th>\n",
       "      <th>macd</th>\n",
       "      <th>adx</th>\n",
       "      <th>sma</th>\n",
       "      <th>ema</th>\n",
       "      <th>cci</th>\n",
       "      <th>rsi</th>\n",
       "      <th>cov_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>65.010002</td>\n",
       "      <td>65.430000</td>\n",
       "      <td>64.879997</td>\n",
       "      <td>65.370003</td>\n",
       "      <td>2183700</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.736201</td>\n",
       "      <td>2.917910</td>\n",
       "      <td>59133500</td>\n",
       "      <td>0.140533</td>\n",
       "      <td>0.589751</td>\n",
       "      <td>26.368171</td>\n",
       "      <td>65.665834</td>\n",
       "      <td>65.550861</td>\n",
       "      <td>-36.130018</td>\n",
       "      <td>54.933937</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>123.720001</td>\n",
       "      <td>123.970001</td>\n",
       "      <td>122.970001</td>\n",
       "      <td>123.820000</td>\n",
       "      <td>1767900</td>\n",
       "      <td>COST</td>\n",
       "      <td>1.433317</td>\n",
       "      <td>4.010875</td>\n",
       "      <td>385073300</td>\n",
       "      <td>0.175502</td>\n",
       "      <td>1.509197</td>\n",
       "      <td>29.628245</td>\n",
       "      <td>124.313333</td>\n",
       "      <td>124.062547</td>\n",
       "      <td>-2.234842</td>\n",
       "      <td>57.565631</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>56.315392</td>\n",
       "      <td>56.444275</td>\n",
       "      <td>55.754360</td>\n",
       "      <td>55.928734</td>\n",
       "      <td>3117061</td>\n",
       "      <td>DHR</td>\n",
       "      <td>0.673827</td>\n",
       "      <td>4.568752</td>\n",
       "      <td>629198375</td>\n",
       "      <td>-0.035569</td>\n",
       "      <td>0.580076</td>\n",
       "      <td>30.145718</td>\n",
       "      <td>56.503033</td>\n",
       "      <td>56.389011</td>\n",
       "      <td>-27.073061</td>\n",
       "      <td>51.823937</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>91.089996</td>\n",
       "      <td>91.360001</td>\n",
       "      <td>90.019997</td>\n",
       "      <td>90.339996</td>\n",
       "      <td>1198600</td>\n",
       "      <td>GD</td>\n",
       "      <td>1.073160</td>\n",
       "      <td>8.936027</td>\n",
       "      <td>1332459783</td>\n",
       "      <td>0.174849</td>\n",
       "      <td>1.114092</td>\n",
       "      <td>24.278320</td>\n",
       "      <td>90.815000</td>\n",
       "      <td>90.598526</td>\n",
       "      <td>44.496106</td>\n",
       "      <td>55.851273</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>82.638069</td>\n",
       "      <td>83.009888</td>\n",
       "      <td>2430852</td>\n",
       "      <td>HON</td>\n",
       "      <td>0.994786</td>\n",
       "      <td>4.271538</td>\n",
       "      <td>1557103883</td>\n",
       "      <td>-0.040978</td>\n",
       "      <td>0.525893</td>\n",
       "      <td>14.602989</td>\n",
       "      <td>84.121355</td>\n",
       "      <td>83.903915</td>\n",
       "      <td>-42.299743</td>\n",
       "      <td>47.762318</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        Open        High         Low       Close   Volume Ticker  \\\n",
       "0  2013-12-03   65.010002   65.430000   64.879997   65.370003  2183700     CL   \n",
       "1  2013-12-03  123.720001  123.970001  122.970001  123.820000  1767900   COST   \n",
       "2  2013-12-03   56.315392   56.444275   55.754360   55.928734  3117061    DHR   \n",
       "3  2013-12-03   91.089996   91.360001   90.019997   90.339996  1198600     GD   \n",
       "4  2013-12-03   83.848846   83.848846   82.638069   83.009888  2430852    HON   \n",
       "\n",
       "        atr       bbw         obv       cmf      macd        adx         sma  \\\n",
       "0  0.736201  2.917910    59133500  0.140533  0.589751  26.368171   65.665834   \n",
       "1  1.433317  4.010875   385073300  0.175502  1.509197  29.628245  124.313333   \n",
       "2  0.673827  4.568752   629198375 -0.035569  0.580076  30.145718   56.503033   \n",
       "3  1.073160  8.936027  1332459783  0.174849  1.114092  24.278320   90.815000   \n",
       "4  0.994786  4.271538  1557103883 -0.040978  0.525893  14.602989   84.121355   \n",
       "\n",
       "          ema        cci        rsi  \\\n",
       "0   65.550861 -36.130018  54.933937   \n",
       "1  124.062547  -2.234842  57.565631   \n",
       "2   56.389011 -27.073061  51.823937   \n",
       "3   90.598526  44.496106  55.851273   \n",
       "4   83.903915 -42.299743  47.762318   \n",
       "\n",
       "                                            cov_list  \n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "1  [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "2  [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "3  [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "4  [[9.88188682115059e-05, 4.637338976698862e-05,...  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_features_covs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f851acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all the features\n",
    "features_list = list(data_with_features_covs.columns)[7:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5dbbb438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atr', 'bbw', 'obv', 'cmf', 'macd', 'adx', 'sma', 'ema', 'cci', 'rsi']\n"
     ]
    }
   ],
   "source": [
    "print(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e5dc8508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atr</th>\n",
       "      <th>bbw</th>\n",
       "      <th>obv</th>\n",
       "      <th>cmf</th>\n",
       "      <th>macd</th>\n",
       "      <th>adx</th>\n",
       "      <th>sma</th>\n",
       "      <th>ema</th>\n",
       "      <th>cci</th>\n",
       "      <th>rsi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-03</th>\n",
       "      <td>0.736201</td>\n",
       "      <td>2.917910</td>\n",
       "      <td>59133500</td>\n",
       "      <td>0.140533</td>\n",
       "      <td>0.589751</td>\n",
       "      <td>26.368171</td>\n",
       "      <td>65.665834</td>\n",
       "      <td>65.550861</td>\n",
       "      <td>-36.130018</td>\n",
       "      <td>54.933937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-03</th>\n",
       "      <td>1.433317</td>\n",
       "      <td>4.010875</td>\n",
       "      <td>385073300</td>\n",
       "      <td>0.175502</td>\n",
       "      <td>1.509197</td>\n",
       "      <td>29.628245</td>\n",
       "      <td>124.313333</td>\n",
       "      <td>124.062547</td>\n",
       "      <td>-2.234842</td>\n",
       "      <td>57.565631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-03</th>\n",
       "      <td>0.673827</td>\n",
       "      <td>4.568752</td>\n",
       "      <td>629198375</td>\n",
       "      <td>-0.035569</td>\n",
       "      <td>0.580076</td>\n",
       "      <td>30.145718</td>\n",
       "      <td>56.503033</td>\n",
       "      <td>56.389011</td>\n",
       "      <td>-27.073061</td>\n",
       "      <td>51.823937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-03</th>\n",
       "      <td>1.073160</td>\n",
       "      <td>8.936027</td>\n",
       "      <td>1332459783</td>\n",
       "      <td>0.174849</td>\n",
       "      <td>1.114092</td>\n",
       "      <td>24.278320</td>\n",
       "      <td>90.815000</td>\n",
       "      <td>90.598526</td>\n",
       "      <td>44.496106</td>\n",
       "      <td>55.851273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-03</th>\n",
       "      <td>0.994786</td>\n",
       "      <td>4.271538</td>\n",
       "      <td>1557103883</td>\n",
       "      <td>-0.040978</td>\n",
       "      <td>0.525893</td>\n",
       "      <td>14.602989</td>\n",
       "      <td>84.121355</td>\n",
       "      <td>83.903915</td>\n",
       "      <td>-42.299743</td>\n",
       "      <td>47.762318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 atr       bbw         obv       cmf      macd        adx  \\\n",
       "date                                                                        \n",
       "2013-12-03  0.736201  2.917910    59133500  0.140533  0.589751  26.368171   \n",
       "2013-12-03  1.433317  4.010875   385073300  0.175502  1.509197  29.628245   \n",
       "2013-12-03  0.673827  4.568752   629198375 -0.035569  0.580076  30.145718   \n",
       "2013-12-03  1.073160  8.936027  1332459783  0.174849  1.114092  24.278320   \n",
       "2013-12-03  0.994786  4.271538  1557103883 -0.040978  0.525893  14.602989   \n",
       "\n",
       "                   sma         ema        cci        rsi  \n",
       "date                                                      \n",
       "2013-12-03   65.665834   65.550861 -36.130018  54.933937  \n",
       "2013-12-03  124.313333  124.062547  -2.234842  57.565631  \n",
       "2013-12-03   56.503033   56.389011 -27.073061  51.823937  \n",
       "2013-12-03   90.815000   90.598526  44.496106  55.851273  \n",
       "2013-12-03   84.121355   83.903915 -42.299743  47.762318  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct a data frame of features\n",
    "features_df = data_with_features_covs[features_list]\n",
    "features_df.index = data_with_features_covs['date']\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3aaf5105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45720, 18)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_features_covs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7d35915f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45720, 10)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a76e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d3a35854",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.array(features_df)\n",
    "\n",
    "features_scaler = preprocessing.MinMaxScaler()\n",
    "features_normalised = features_scaler.fit_transform(features_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3edc5b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the features array\n",
    "features_normalised = features_normalised.reshape(-1,20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b36c3d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2286, 20, 10)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_normalised.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "28fcd1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, activation='relu', input_shape=(20,10)))\n",
    "model.add(RepeatVector(20))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(10)))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6d06bb59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 4s 17ms/step - loss: 0.0725\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0166\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0111\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0103\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0098\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0091\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0087\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0083\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0078\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0074\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0071\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0068\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0067\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0066\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0065\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0065\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0064\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0064\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0063\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0063\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0062\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0062\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0061\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0061\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0060\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0059\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0058\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0058\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0057\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0057\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0056\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0056\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0056\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0056\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0055\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0055\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0055\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0055\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0055\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0054\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0054\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0054\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0054\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0054\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0054\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0054\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0054\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0054\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0053\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0053\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0053\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0053\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0053\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0053\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0053\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0053\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0053\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0053\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0053\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0052\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0052\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0052\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0052\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0052\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0052\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0052\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0052\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0052\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0052\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0052\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0052\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0051\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0051\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0051\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0051\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0051\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 2s 32ms/step - loss: 0.0051\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0051\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0051\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0051\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0051\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0051\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0051\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0051\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0051\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0051\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0050\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0050\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0050\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.0050\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.0050\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0050\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0050\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0050\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0050\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0050\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0050\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0050\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0050\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x228174092d0>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(features_normalised, features_normalised, epochs=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "65bfa4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_shapes=True, to_file='./results/reconstruct_lstm_autoencoder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bf638e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 4)                 240       \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 20, 4)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20, 100)           42000     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 20, 10)           1010      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,250\n",
      "Trainable params: 43,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c9ed39a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect the encoder LSTM as the output layer\n",
    "model_feature = Model(inputs=model.inputs, outputs=model.layers[1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "61805adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_input (InputLayer)     [(None, 20, 10)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 4)                 240       \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 20, 4)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 240\n",
      "Trainable params: 240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_feature.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5e996fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'features_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e0579011",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1e7c49ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 3ms/step\n",
      "(2286, 20, 4)\n"
     ]
    }
   ],
   "source": [
    "yhat = model_feature.predict(features_normalised)\n",
    "print(yhat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1700e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_features = yhat.reshape(-1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0a30c364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45720, 4)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2a84a34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45720, 18)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_features_covs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a4fbb82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>atr</th>\n",
       "      <th>bbw</th>\n",
       "      <th>obv</th>\n",
       "      <th>cmf</th>\n",
       "      <th>macd</th>\n",
       "      <th>adx</th>\n",
       "      <th>sma</th>\n",
       "      <th>ema</th>\n",
       "      <th>cci</th>\n",
       "      <th>rsi</th>\n",
       "      <th>cov_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>65.010002</td>\n",
       "      <td>65.430000</td>\n",
       "      <td>64.879997</td>\n",
       "      <td>65.370003</td>\n",
       "      <td>2183700</td>\n",
       "      <td>CL</td>\n",
       "      <td>0.736201</td>\n",
       "      <td>2.917910</td>\n",
       "      <td>59133500</td>\n",
       "      <td>0.140533</td>\n",
       "      <td>0.589751</td>\n",
       "      <td>26.368171</td>\n",
       "      <td>65.665834</td>\n",
       "      <td>65.550861</td>\n",
       "      <td>-36.130018</td>\n",
       "      <td>54.933937</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>123.720001</td>\n",
       "      <td>123.970001</td>\n",
       "      <td>122.970001</td>\n",
       "      <td>123.820000</td>\n",
       "      <td>1767900</td>\n",
       "      <td>COST</td>\n",
       "      <td>1.433317</td>\n",
       "      <td>4.010875</td>\n",
       "      <td>385073300</td>\n",
       "      <td>0.175502</td>\n",
       "      <td>1.509197</td>\n",
       "      <td>29.628245</td>\n",
       "      <td>124.313333</td>\n",
       "      <td>124.062547</td>\n",
       "      <td>-2.234842</td>\n",
       "      <td>57.565631</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>56.315392</td>\n",
       "      <td>56.444275</td>\n",
       "      <td>55.754360</td>\n",
       "      <td>55.928734</td>\n",
       "      <td>3117061</td>\n",
       "      <td>DHR</td>\n",
       "      <td>0.673827</td>\n",
       "      <td>4.568752</td>\n",
       "      <td>629198375</td>\n",
       "      <td>-0.035569</td>\n",
       "      <td>0.580076</td>\n",
       "      <td>30.145718</td>\n",
       "      <td>56.503033</td>\n",
       "      <td>56.389011</td>\n",
       "      <td>-27.073061</td>\n",
       "      <td>51.823937</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>91.089996</td>\n",
       "      <td>91.360001</td>\n",
       "      <td>90.019997</td>\n",
       "      <td>90.339996</td>\n",
       "      <td>1198600</td>\n",
       "      <td>GD</td>\n",
       "      <td>1.073160</td>\n",
       "      <td>8.936027</td>\n",
       "      <td>1332459783</td>\n",
       "      <td>0.174849</td>\n",
       "      <td>1.114092</td>\n",
       "      <td>24.278320</td>\n",
       "      <td>90.815000</td>\n",
       "      <td>90.598526</td>\n",
       "      <td>44.496106</td>\n",
       "      <td>55.851273</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>82.638069</td>\n",
       "      <td>83.009888</td>\n",
       "      <td>2430852</td>\n",
       "      <td>HON</td>\n",
       "      <td>0.994786</td>\n",
       "      <td>4.271538</td>\n",
       "      <td>1557103883</td>\n",
       "      <td>-0.040978</td>\n",
       "      <td>0.525893</td>\n",
       "      <td>14.602989</td>\n",
       "      <td>84.121355</td>\n",
       "      <td>83.903915</td>\n",
       "      <td>-42.299743</td>\n",
       "      <td>47.762318</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        Open        High         Low       Close   Volume Ticker  \\\n",
       "0  2013-12-03   65.010002   65.430000   64.879997   65.370003  2183700     CL   \n",
       "1  2013-12-03  123.720001  123.970001  122.970001  123.820000  1767900   COST   \n",
       "2  2013-12-03   56.315392   56.444275   55.754360   55.928734  3117061    DHR   \n",
       "3  2013-12-03   91.089996   91.360001   90.019997   90.339996  1198600     GD   \n",
       "4  2013-12-03   83.848846   83.848846   82.638069   83.009888  2430852    HON   \n",
       "\n",
       "        atr       bbw         obv       cmf      macd        adx         sma  \\\n",
       "0  0.736201  2.917910    59133500  0.140533  0.589751  26.368171   65.665834   \n",
       "1  1.433317  4.010875   385073300  0.175502  1.509197  29.628245  124.313333   \n",
       "2  0.673827  4.568752   629198375 -0.035569  0.580076  30.145718   56.503033   \n",
       "3  1.073160  8.936027  1332459783  0.174849  1.114092  24.278320   90.815000   \n",
       "4  0.994786  4.271538  1557103883 -0.040978  0.525893  14.602989   84.121355   \n",
       "\n",
       "          ema        cci        rsi  \\\n",
       "0   65.550861 -36.130018  54.933937   \n",
       "1  124.062547  -2.234842  57.565631   \n",
       "2   56.389011 -27.073061  51.823937   \n",
       "3   90.598526  44.496106  55.851273   \n",
       "4   83.903915 -42.299743  47.762318   \n",
       "\n",
       "                                            cov_list  \n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "1  [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "2  [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "3  [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "4  [[9.88188682115059e-05, 4.637338976698862e-05,...  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = data_with_features_covs.copy()\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7f913289",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(features_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "eba4a6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>cov_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>65.010002</td>\n",
       "      <td>65.430000</td>\n",
       "      <td>64.879997</td>\n",
       "      <td>65.370003</td>\n",
       "      <td>2183700</td>\n",
       "      <td>CL</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>123.720001</td>\n",
       "      <td>123.970001</td>\n",
       "      <td>122.970001</td>\n",
       "      <td>123.820000</td>\n",
       "      <td>1767900</td>\n",
       "      <td>COST</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>56.315392</td>\n",
       "      <td>56.444275</td>\n",
       "      <td>55.754360</td>\n",
       "      <td>55.928734</td>\n",
       "      <td>3117061</td>\n",
       "      <td>DHR</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>91.089996</td>\n",
       "      <td>91.360001</td>\n",
       "      <td>90.019997</td>\n",
       "      <td>90.339996</td>\n",
       "      <td>1198600</td>\n",
       "      <td>GD</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>82.638069</td>\n",
       "      <td>83.009888</td>\n",
       "      <td>2430852</td>\n",
       "      <td>HON</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        Open        High         Low       Close   Volume Ticker  \\\n",
       "0  2013-12-03   65.010002   65.430000   64.879997   65.370003  2183700     CL   \n",
       "1  2013-12-03  123.720001  123.970001  122.970001  123.820000  1767900   COST   \n",
       "2  2013-12-03   56.315392   56.444275   55.754360   55.928734  3117061    DHR   \n",
       "3  2013-12-03   91.089996   91.360001   90.019997   90.339996  1198600     GD   \n",
       "4  2013-12-03   83.848846   83.848846   82.638069   83.009888  2430852    HON   \n",
       "\n",
       "                                            cov_list  \n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "1  [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "2  [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "3  [[9.88188682115059e-05, 4.637338976698862e-05,...  \n",
       "4  [[9.88188682115059e-05, 4.637338976698862e-05,...  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "313b15c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_reduced_df = pd.DataFrame(reduced_features, columns=['f01','f02','f03','f04'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8d4b7f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f01       f02       f03       f04\n",
       "0  0.968878  1.040823  1.991801  1.938116\n",
       "1  0.968878  1.040823  1.991801  1.938116\n",
       "2  0.968878  1.040823  1.991801  1.938116\n",
       "3  0.968878  1.040823  1.991801  1.938116\n",
       "4  0.968878  1.040823  1.991801  1.938116"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a2f7a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_reduced_df = features_reduced_df.drop( 'f03',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f111756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['f01','f02', 'f03','f04']] = features_reduced_df[['f01','f02', 'f03','f04']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "dcbeff07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>65.010002</td>\n",
       "      <td>65.430000</td>\n",
       "      <td>64.879997</td>\n",
       "      <td>65.370003</td>\n",
       "      <td>2183700</td>\n",
       "      <td>CL</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>123.720001</td>\n",
       "      <td>123.970001</td>\n",
       "      <td>122.970001</td>\n",
       "      <td>123.820000</td>\n",
       "      <td>1767900</td>\n",
       "      <td>COST</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>56.315392</td>\n",
       "      <td>56.444275</td>\n",
       "      <td>55.754360</td>\n",
       "      <td>55.928734</td>\n",
       "      <td>3117061</td>\n",
       "      <td>DHR</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>91.089996</td>\n",
       "      <td>91.360001</td>\n",
       "      <td>90.019997</td>\n",
       "      <td>90.339996</td>\n",
       "      <td>1198600</td>\n",
       "      <td>GD</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>82.638069</td>\n",
       "      <td>83.009888</td>\n",
       "      <td>2430852</td>\n",
       "      <td>HON</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        Open        High         Low       Close   Volume Ticker  \\\n",
       "0  2013-12-03   65.010002   65.430000   64.879997   65.370003  2183700     CL   \n",
       "1  2013-12-03  123.720001  123.970001  122.970001  123.820000  1767900   COST   \n",
       "2  2013-12-03   56.315392   56.444275   55.754360   55.928734  3117061    DHR   \n",
       "3  2013-12-03   91.089996   91.360001   90.019997   90.339996  1198600     GD   \n",
       "4  2013-12-03   83.848846   83.848846   82.638069   83.009888  2430852    HON   \n",
       "\n",
       "                                            cov_list       f01       f02  \\\n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "1  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "2  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "3  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "4  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "\n",
       "        f03       f04  \n",
       "0  1.991801  1.938116  \n",
       "1  1.991801  1.938116  \n",
       "2  1.991801  1.938116  \n",
       "3  1.991801  1.938116  \n",
       "4  1.991801  1.938116  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "05560e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45720, 12)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8a5ca4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-03</th>\n",
       "      <td>2012-12-03</td>\n",
       "      <td>21.201786</td>\n",
       "      <td>21.235357</td>\n",
       "      <td>20.910713</td>\n",
       "      <td>20.935356</td>\n",
       "      <td>17.951883</td>\n",
       "      <td>364280000</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-04</th>\n",
       "      <td>2012-12-04</td>\n",
       "      <td>20.778570</td>\n",
       "      <td>20.778570</td>\n",
       "      <td>20.433214</td>\n",
       "      <td>20.566071</td>\n",
       "      <td>17.635214</td>\n",
       "      <td>557068400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-05</th>\n",
       "      <td>2012-12-05</td>\n",
       "      <td>20.318214</td>\n",
       "      <td>20.330357</td>\n",
       "      <td>19.241785</td>\n",
       "      <td>19.242500</td>\n",
       "      <td>16.500261</td>\n",
       "      <td>1044638000</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-06</th>\n",
       "      <td>2012-12-06</td>\n",
       "      <td>18.890715</td>\n",
       "      <td>19.761070</td>\n",
       "      <td>18.522499</td>\n",
       "      <td>19.544287</td>\n",
       "      <td>16.759045</td>\n",
       "      <td>1177212400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-07</th>\n",
       "      <td>2012-12-07</td>\n",
       "      <td>19.764286</td>\n",
       "      <td>19.828571</td>\n",
       "      <td>18.928572</td>\n",
       "      <td>19.044643</td>\n",
       "      <td>16.330601</td>\n",
       "      <td>787040800</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date       Open       High        Low      Close  Adj Close  \\\n",
       "date                                                                            \n",
       "2012-12-03  2012-12-03  21.201786  21.235357  20.910713  20.935356  17.951883   \n",
       "2012-12-04  2012-12-04  20.778570  20.778570  20.433214  20.566071  17.635214   \n",
       "2012-12-05  2012-12-05  20.318214  20.330357  19.241785  19.242500  16.500261   \n",
       "2012-12-06  2012-12-06  18.890715  19.761070  18.522499  19.544287  16.759045   \n",
       "2012-12-07  2012-12-07  19.764286  19.828571  18.928572  19.044643  16.330601   \n",
       "\n",
       "                Volume Ticker  \n",
       "date                           \n",
       "2012-12-03   364280000   AAPL  \n",
       "2012-12-04   557068400   AAPL  \n",
       "2012-12-05  1044638000   AAPL  \n",
       "2012-12-06  1177212400   AAPL  \n",
       "2012-12-07   787040800   AAPL  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bed00097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = final_df.reset_index().set_index(['Ticker', 'date']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e088370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_close = pd.DataFrame()\n",
    "\n",
    "for ticker in filtered_stocks:\n",
    "    series = df_prices.xs(ticker).Close\n",
    "    df_close[ticker] = series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e0f358d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JNJ</th>\n",
       "      <th>PG</th>\n",
       "      <th>KO</th>\n",
       "      <th>MCD</th>\n",
       "      <th>USB</th>\n",
       "      <th>JPM</th>\n",
       "      <th>GD</th>\n",
       "      <th>VZ</th>\n",
       "      <th>MMM</th>\n",
       "      <th>PEP</th>\n",
       "      <th>CL</th>\n",
       "      <th>LIN</th>\n",
       "      <th>DHR</th>\n",
       "      <th>HON</th>\n",
       "      <th>LMT</th>\n",
       "      <th>MDT</th>\n",
       "      <th>V</th>\n",
       "      <th>RTX</th>\n",
       "      <th>T</th>\n",
       "      <th>COST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-03</th>\n",
       "      <td>93.970001</td>\n",
       "      <td>83.830002</td>\n",
       "      <td>40.349998</td>\n",
       "      <td>96.379997</td>\n",
       "      <td>38.520000</td>\n",
       "      <td>56.860001</td>\n",
       "      <td>90.339996</td>\n",
       "      <td>49.599998</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>83.800003</td>\n",
       "      <td>65.370003</td>\n",
       "      <td>124.239998</td>\n",
       "      <td>55.928734</td>\n",
       "      <td>83.009888</td>\n",
       "      <td>138.770004</td>\n",
       "      <td>57.639999</td>\n",
       "      <td>50.437500</td>\n",
       "      <td>69.030838</td>\n",
       "      <td>26.238670</td>\n",
       "      <td>123.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-04</th>\n",
       "      <td>93.629997</td>\n",
       "      <td>83.349998</td>\n",
       "      <td>40.369999</td>\n",
       "      <td>95.709999</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>57.189999</td>\n",
       "      <td>89.480003</td>\n",
       "      <td>49.369999</td>\n",
       "      <td>126.459999</td>\n",
       "      <td>82.650002</td>\n",
       "      <td>65.040001</td>\n",
       "      <td>123.620003</td>\n",
       "      <td>55.845337</td>\n",
       "      <td>82.781075</td>\n",
       "      <td>136.229996</td>\n",
       "      <td>56.930000</td>\n",
       "      <td>50.685001</td>\n",
       "      <td>68.558846</td>\n",
       "      <td>26.132931</td>\n",
       "      <td>122.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-05</th>\n",
       "      <td>92.970001</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>39.830002</td>\n",
       "      <td>95.430000</td>\n",
       "      <td>38.610001</td>\n",
       "      <td>55.820000</td>\n",
       "      <td>89.230003</td>\n",
       "      <td>48.910000</td>\n",
       "      <td>126.830002</td>\n",
       "      <td>81.900002</td>\n",
       "      <td>64.540001</td>\n",
       "      <td>122.489998</td>\n",
       "      <td>55.830173</td>\n",
       "      <td>82.809677</td>\n",
       "      <td>136.660004</td>\n",
       "      <td>56.910000</td>\n",
       "      <td>50.427502</td>\n",
       "      <td>68.628067</td>\n",
       "      <td>25.868580</td>\n",
       "      <td>120.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-06</th>\n",
       "      <td>94.440002</td>\n",
       "      <td>84.519997</td>\n",
       "      <td>40.459999</td>\n",
       "      <td>96.800003</td>\n",
       "      <td>39.660000</td>\n",
       "      <td>56.060001</td>\n",
       "      <td>90.790001</td>\n",
       "      <td>49.480000</td>\n",
       "      <td>128.610001</td>\n",
       "      <td>83.150002</td>\n",
       "      <td>65.660004</td>\n",
       "      <td>125.459999</td>\n",
       "      <td>56.952236</td>\n",
       "      <td>84.201599</td>\n",
       "      <td>138.190002</td>\n",
       "      <td>58.139999</td>\n",
       "      <td>50.467499</td>\n",
       "      <td>69.930771</td>\n",
       "      <td>26.080059</td>\n",
       "      <td>122.059998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-09</th>\n",
       "      <td>94.440002</td>\n",
       "      <td>84.779999</td>\n",
       "      <td>40.400002</td>\n",
       "      <td>95.720001</td>\n",
       "      <td>39.740002</td>\n",
       "      <td>56.509998</td>\n",
       "      <td>90.529999</td>\n",
       "      <td>49.570000</td>\n",
       "      <td>128.570007</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>65.690002</td>\n",
       "      <td>125.410004</td>\n",
       "      <td>57.149357</td>\n",
       "      <td>83.772583</td>\n",
       "      <td>138.929993</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>50.397499</td>\n",
       "      <td>69.968536</td>\n",
       "      <td>26.200907</td>\n",
       "      <td>121.660004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  JNJ         PG         KO        MCD        USB        JPM  \\\n",
       "date                                                                           \n",
       "2013-12-03  93.970001  83.830002  40.349998  96.379997  38.520000  56.860001   \n",
       "2013-12-04  93.629997  83.349998  40.369999  95.709999  39.000000  57.189999   \n",
       "2013-12-05  92.970001  82.690002  39.830002  95.430000  38.610001  55.820000   \n",
       "2013-12-06  94.440002  84.519997  40.459999  96.800003  39.660000  56.060001   \n",
       "2013-12-09  94.440002  84.779999  40.400002  95.720001  39.740002  56.509998   \n",
       "\n",
       "                   GD         VZ         MMM        PEP         CL  \\\n",
       "date                                                                 \n",
       "2013-12-03  90.339996  49.599998  126.599998  83.800003  65.370003   \n",
       "2013-12-04  89.480003  49.369999  126.459999  82.650002  65.040001   \n",
       "2013-12-05  89.230003  48.910000  126.830002  81.900002  64.540001   \n",
       "2013-12-06  90.790001  49.480000  128.610001  83.150002  65.660004   \n",
       "2013-12-09  90.529999  49.570000  128.570007  82.690002  65.690002   \n",
       "\n",
       "                   LIN        DHR        HON         LMT        MDT  \\\n",
       "date                                                                  \n",
       "2013-12-03  124.239998  55.928734  83.009888  138.770004  57.639999   \n",
       "2013-12-04  123.620003  55.845337  82.781075  136.229996  56.930000   \n",
       "2013-12-05  122.489998  55.830173  82.809677  136.660004  56.910000   \n",
       "2013-12-06  125.459999  56.952236  84.201599  138.190002  58.139999   \n",
       "2013-12-09  125.410004  57.149357  83.772583  138.929993  57.869999   \n",
       "\n",
       "                    V        RTX          T        COST  \n",
       "date                                                     \n",
       "2013-12-03  50.437500  69.030838  26.238670  123.820000  \n",
       "2013-12-04  50.685001  68.558846  26.132931  122.970001  \n",
       "2013-12-05  50.427502  68.628067  25.868580  120.949997  \n",
       "2013-12-06  50.467499  69.930771  26.080059  122.059998  \n",
       "2013-12-09  50.397499  69.968536  26.200907  121.660004  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_close.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "da49c485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2286, 20)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_close.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "810afe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_close' (DataFrame)\n",
      "Stored 'features_reduced_df' (DataFrame)\n",
      "Stored 'final_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store df_close\n",
    "%store features_reduced_df\n",
    "%store final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7495fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_close\n",
    "%store -r final_df\n",
    "%store -r features_reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3554a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_close = df_close.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "289ba9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and end dates for the train and test data\n",
    "\n",
    "train_pct = 0.8 # percentage of train data\n",
    "date_list = list(final_df.date.unique()) # List of dates in the data\n",
    "\n",
    "date_list_len = len(date_list) # len of the date list\n",
    "train_data_len = int(train_pct * date_list_len) # length of the train data\n",
    "\n",
    "train_start_date = date_list[0]\n",
    "train_end_date = date_list[train_data_len]\n",
    "\n",
    "test_start_date = date_list[train_data_len+1]\n",
    "test_end_date = date_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b952d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:  from  2013-12-03  to  2021-03-10\n"
     ]
    }
   ],
   "source": [
    "print('Training Data: ', 'from ', train_start_date, ' to ', train_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e751be10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data:  from  2021-03-11  to  2022-12-30\n"
     ]
    }
   ],
   "source": [
    "print('Testing Data: ', 'from ', test_start_date, ' to ', test_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7cc0de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ta\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "196ec003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AAPL', 'ABBV', 'ABT', 'ACN', 'ADBE', 'AIG', 'AMD', 'AMGN', 'AMT',\n",
      "       'AMZN', 'AVGO', 'AXP', 'BA', 'BAC', 'BK', 'BKNG', 'BLK', 'BMY', 'C',\n",
      "       'CAT', 'CHTR', 'CL', 'CMCSA', 'COF', 'COP', 'COST', 'CRM', 'CSCO',\n",
      "       'CVS', 'CVX', 'DHR', 'DIS', 'DOW', 'DUK', 'EMR', 'EXC', 'F', 'FDX',\n",
      "       'GD', 'GE', 'GILD', 'GM', 'GOOG', 'GOOGL', 'GS', 'HD', 'HON', 'IBM',\n",
      "       'INTC', 'JNJ', 'JPM', 'KHC', 'KO', 'LIN', 'LLY', 'LMT', 'LOW', 'MA',\n",
      "       'MCD', 'MDLZ', 'MDT', 'MET', 'META', 'MMM', 'MO', 'MRK', 'MS', 'MSFT',\n",
      "       'NEE', 'NFLX', 'NKE', 'NVDA', 'ORCL', 'PEP', 'PFE', 'PG', 'PM', 'PYPL',\n",
      "       'QCOM', 'RTX', 'SBUX', 'SCHW', 'SO', 'SPG', 'T', 'TGT', 'TMO', 'TMUS',\n",
      "       'TSLA', 'TXN', 'UNH', 'UNP', 'UPS', 'USB', 'V', 'VZ', 'WBA', 'WFC',\n",
      "       'WMT', 'XOM'],\n",
      "      dtype='object', name='Ticker')\n"
     ]
    }
   ],
   "source": [
    "print(pivot_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4aa94bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.rename(columns={'Ticker': 'tic'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "28ae086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the whole dataset\n",
    "train_data = data_split(final_df, train_start_date, train_end_date)\n",
    "test_data = data_split(final_df, test_start_date, test_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "696b2e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Close Prices dataset\n",
    "prices_train_data = df_close[df_close['date']<=train_end_date]\n",
    "prices_test_data = df_close[df_close['date']>=test_start_date]\n",
    "\n",
    "# split the Close Prices of all stocks\n",
    "prices_full_train = df_close[df_close['date']<=train_end_date]\n",
    "prices_full_test = df_close[df_close['date']>=test_start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "67cdfdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_train = prices_train_data.copy()\n",
    "prices_test = prices_test_data.copy()\n",
    "\n",
    "train_df = train_data.copy()\n",
    "test_df = test_data.copy()\n",
    "\n",
    "prices_full_train_df = prices_full_train.copy()\n",
    "prices_full_test_df = prices_full_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "45903b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>65.010002</td>\n",
       "      <td>65.430000</td>\n",
       "      <td>64.879997</td>\n",
       "      <td>65.370003</td>\n",
       "      <td>2183700</td>\n",
       "      <td>CL</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>123.720001</td>\n",
       "      <td>123.970001</td>\n",
       "      <td>122.970001</td>\n",
       "      <td>123.820000</td>\n",
       "      <td>1767900</td>\n",
       "      <td>COST</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>56.315392</td>\n",
       "      <td>56.444275</td>\n",
       "      <td>55.754360</td>\n",
       "      <td>55.928734</td>\n",
       "      <td>3117061</td>\n",
       "      <td>DHR</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>91.089996</td>\n",
       "      <td>91.360001</td>\n",
       "      <td>90.019997</td>\n",
       "      <td>90.339996</td>\n",
       "      <td>1198600</td>\n",
       "      <td>GD</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>82.638069</td>\n",
       "      <td>83.009888</td>\n",
       "      <td>2430852</td>\n",
       "      <td>HON</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>76.040001</td>\n",
       "      <td>76.699997</td>\n",
       "      <td>74.750000</td>\n",
       "      <td>74.830002</td>\n",
       "      <td>6558300</td>\n",
       "      <td>RTX</td>\n",
       "      <td>[[0.00033739648202381155, 0.000211218829005817...</td>\n",
       "      <td>2.705900</td>\n",
       "      <td>1.114965</td>\n",
       "      <td>3.517446</td>\n",
       "      <td>0.767194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>22.583082</td>\n",
       "      <td>22.764351</td>\n",
       "      <td>22.364048</td>\n",
       "      <td>22.386707</td>\n",
       "      <td>63488580</td>\n",
       "      <td>T</td>\n",
       "      <td>[[0.00033739648202381155, 0.000211218829005817...</td>\n",
       "      <td>2.705900</td>\n",
       "      <td>1.114965</td>\n",
       "      <td>3.517446</td>\n",
       "      <td>0.767194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>52.869999</td>\n",
       "      <td>53.840000</td>\n",
       "      <td>52.470001</td>\n",
       "      <td>52.900002</td>\n",
       "      <td>8899100</td>\n",
       "      <td>USB</td>\n",
       "      <td>[[0.00033739648202381155, 0.000211218829005817...</td>\n",
       "      <td>2.705900</td>\n",
       "      <td>1.114965</td>\n",
       "      <td>3.517446</td>\n",
       "      <td>0.767194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>222.059998</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>220.190002</td>\n",
       "      <td>220.360001</td>\n",
       "      <td>9228600</td>\n",
       "      <td>V</td>\n",
       "      <td>[[0.00033739648202381155, 0.000211218829005817...</td>\n",
       "      <td>2.705900</td>\n",
       "      <td>1.114965</td>\n",
       "      <td>3.517446</td>\n",
       "      <td>0.767194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>56.900002</td>\n",
       "      <td>57.099998</td>\n",
       "      <td>56.169998</td>\n",
       "      <td>56.200001</td>\n",
       "      <td>20956400</td>\n",
       "      <td>VZ</td>\n",
       "      <td>[[0.00033739648202381155, 0.000211218829005817...</td>\n",
       "      <td>2.705900</td>\n",
       "      <td>1.114965</td>\n",
       "      <td>3.517446</td>\n",
       "      <td>0.767194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36560 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        Open        High         Low       Close    Volume  \\\n",
       "0     2013-12-03   65.010002   65.430000   64.879997   65.370003   2183700   \n",
       "0     2013-12-03  123.720001  123.970001  122.970001  123.820000   1767900   \n",
       "0     2013-12-03   56.315392   56.444275   55.754360   55.928734   3117061   \n",
       "0     2013-12-03   91.089996   91.360001   90.019997   90.339996   1198600   \n",
       "0     2013-12-03   83.848846   83.848846   82.638069   83.009888   2430852   \n",
       "...          ...         ...         ...         ...         ...       ...   \n",
       "1827  2021-03-09   76.040001   76.699997   74.750000   74.830002   6558300   \n",
       "1827  2021-03-09   22.583082   22.764351   22.364048   22.386707  63488580   \n",
       "1827  2021-03-09   52.869999   53.840000   52.470001   52.900002   8899100   \n",
       "1827  2021-03-09  222.059998  225.000000  220.190002  220.360001   9228600   \n",
       "1827  2021-03-09   56.900002   57.099998   56.169998   56.200001  20956400   \n",
       "\n",
       "       tic                                           cov_list       f01  \\\n",
       "0       CL  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878   \n",
       "0     COST  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878   \n",
       "0      DHR  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878   \n",
       "0       GD  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878   \n",
       "0      HON  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878   \n",
       "...    ...                                                ...       ...   \n",
       "1827   RTX  [[0.00033739648202381155, 0.000211218829005817...  2.705900   \n",
       "1827     T  [[0.00033739648202381155, 0.000211218829005817...  2.705900   \n",
       "1827   USB  [[0.00033739648202381155, 0.000211218829005817...  2.705900   \n",
       "1827     V  [[0.00033739648202381155, 0.000211218829005817...  2.705900   \n",
       "1827    VZ  [[0.00033739648202381155, 0.000211218829005817...  2.705900   \n",
       "\n",
       "           f02       f03       f04  \n",
       "0     1.040823  1.991801  1.938116  \n",
       "0     1.040823  1.991801  1.938116  \n",
       "0     1.040823  1.991801  1.938116  \n",
       "0     1.040823  1.991801  1.938116  \n",
       "0     1.040823  1.991801  1.938116  \n",
       "...        ...       ...       ...  \n",
       "1827  1.114965  3.517446  0.767194  \n",
       "1827  1.114965  3.517446  0.767194  \n",
       "1827  1.114965  3.517446  0.767194  \n",
       "1827  1.114965  3.517446  0.767194  \n",
       "1827  1.114965  3.517446  0.767194  \n",
       "\n",
       "[36560 rows x 12 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "45bad57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "from IPython.display import display, HTML\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ebcc2b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ec8379b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt import objective_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8ec68d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtest import BackTestStats, BaselineStats, BackTestPlot, backtest_strat, baseline_strat\n",
    "from backtest import backtest_strat, baseline_strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b798c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import env_portfolio\n",
    "from env_portfolio import StockPortfolioEnv\n",
    "\n",
    "import models\n",
    "from models import DRLAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1a0ef46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>PG</th>\n",
       "      <th>KO</th>\n",
       "      <th>MCD</th>\n",
       "      <th>USB</th>\n",
       "      <th>JPM</th>\n",
       "      <th>GD</th>\n",
       "      <th>VZ</th>\n",
       "      <th>MMM</th>\n",
       "      <th>...</th>\n",
       "      <th>CL</th>\n",
       "      <th>LIN</th>\n",
       "      <th>DHR</th>\n",
       "      <th>HON</th>\n",
       "      <th>LMT</th>\n",
       "      <th>MDT</th>\n",
       "      <th>V</th>\n",
       "      <th>RTX</th>\n",
       "      <th>T</th>\n",
       "      <th>COST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>93.970001</td>\n",
       "      <td>83.830002</td>\n",
       "      <td>40.349998</td>\n",
       "      <td>96.379997</td>\n",
       "      <td>38.520000</td>\n",
       "      <td>56.860001</td>\n",
       "      <td>90.339996</td>\n",
       "      <td>49.599998</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>...</td>\n",
       "      <td>65.370003</td>\n",
       "      <td>124.239998</td>\n",
       "      <td>55.928734</td>\n",
       "      <td>83.009888</td>\n",
       "      <td>138.770004</td>\n",
       "      <td>57.639999</td>\n",
       "      <td>50.437500</td>\n",
       "      <td>69.030838</td>\n",
       "      <td>26.238670</td>\n",
       "      <td>123.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>93.629997</td>\n",
       "      <td>83.349998</td>\n",
       "      <td>40.369999</td>\n",
       "      <td>95.709999</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>57.189999</td>\n",
       "      <td>89.480003</td>\n",
       "      <td>49.369999</td>\n",
       "      <td>126.459999</td>\n",
       "      <td>...</td>\n",
       "      <td>65.040001</td>\n",
       "      <td>123.620003</td>\n",
       "      <td>55.845337</td>\n",
       "      <td>82.781075</td>\n",
       "      <td>136.229996</td>\n",
       "      <td>56.930000</td>\n",
       "      <td>50.685001</td>\n",
       "      <td>68.558846</td>\n",
       "      <td>26.132931</td>\n",
       "      <td>122.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>92.970001</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>39.830002</td>\n",
       "      <td>95.430000</td>\n",
       "      <td>38.610001</td>\n",
       "      <td>55.820000</td>\n",
       "      <td>89.230003</td>\n",
       "      <td>48.910000</td>\n",
       "      <td>126.830002</td>\n",
       "      <td>...</td>\n",
       "      <td>64.540001</td>\n",
       "      <td>122.489998</td>\n",
       "      <td>55.830173</td>\n",
       "      <td>82.809677</td>\n",
       "      <td>136.660004</td>\n",
       "      <td>56.910000</td>\n",
       "      <td>50.427502</td>\n",
       "      <td>68.628067</td>\n",
       "      <td>25.868580</td>\n",
       "      <td>120.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-06</td>\n",
       "      <td>94.440002</td>\n",
       "      <td>84.519997</td>\n",
       "      <td>40.459999</td>\n",
       "      <td>96.800003</td>\n",
       "      <td>39.660000</td>\n",
       "      <td>56.060001</td>\n",
       "      <td>90.790001</td>\n",
       "      <td>49.480000</td>\n",
       "      <td>128.610001</td>\n",
       "      <td>...</td>\n",
       "      <td>65.660004</td>\n",
       "      <td>125.459999</td>\n",
       "      <td>56.952236</td>\n",
       "      <td>84.201599</td>\n",
       "      <td>138.190002</td>\n",
       "      <td>58.139999</td>\n",
       "      <td>50.467499</td>\n",
       "      <td>69.930771</td>\n",
       "      <td>26.080059</td>\n",
       "      <td>122.059998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-09</td>\n",
       "      <td>94.440002</td>\n",
       "      <td>84.779999</td>\n",
       "      <td>40.400002</td>\n",
       "      <td>95.720001</td>\n",
       "      <td>39.740002</td>\n",
       "      <td>56.509998</td>\n",
       "      <td>90.529999</td>\n",
       "      <td>49.570000</td>\n",
       "      <td>128.570007</td>\n",
       "      <td>...</td>\n",
       "      <td>65.690002</td>\n",
       "      <td>125.410004</td>\n",
       "      <td>57.149357</td>\n",
       "      <td>83.772583</td>\n",
       "      <td>138.929993</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>50.397499</td>\n",
       "      <td>69.968536</td>\n",
       "      <td>26.200907</td>\n",
       "      <td>121.660004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        JNJ         PG         KO        MCD        USB  \\\n",
       "0  2013-12-03  93.970001  83.830002  40.349998  96.379997  38.520000   \n",
       "1  2013-12-04  93.629997  83.349998  40.369999  95.709999  39.000000   \n",
       "2  2013-12-05  92.970001  82.690002  39.830002  95.430000  38.610001   \n",
       "3  2013-12-06  94.440002  84.519997  40.459999  96.800003  39.660000   \n",
       "4  2013-12-09  94.440002  84.779999  40.400002  95.720001  39.740002   \n",
       "\n",
       "         JPM         GD         VZ         MMM  ...         CL         LIN  \\\n",
       "0  56.860001  90.339996  49.599998  126.599998  ...  65.370003  124.239998   \n",
       "1  57.189999  89.480003  49.369999  126.459999  ...  65.040001  123.620003   \n",
       "2  55.820000  89.230003  48.910000  126.830002  ...  64.540001  122.489998   \n",
       "3  56.060001  90.790001  49.480000  128.610001  ...  65.660004  125.459999   \n",
       "4  56.509998  90.529999  49.570000  128.570007  ...  65.690002  125.410004   \n",
       "\n",
       "         DHR        HON         LMT        MDT          V        RTX  \\\n",
       "0  55.928734  83.009888  138.770004  57.639999  50.437500  69.030838   \n",
       "1  55.845337  82.781075  136.229996  56.930000  50.685001  68.558846   \n",
       "2  55.830173  82.809677  136.660004  56.910000  50.427502  68.628067   \n",
       "3  56.952236  84.201599  138.190002  58.139999  50.467499  69.930771   \n",
       "4  57.149357  83.772583  138.929993  57.869999  50.397499  69.968536   \n",
       "\n",
       "           T        COST  \n",
       "0  26.238670  123.820000  \n",
       "1  26.132931  122.970001  \n",
       "2  25.868580  120.949997  \n",
       "3  26.080059  122.059998  \n",
       "4  26.200907  121.660004  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_full_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a6565a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "85d1496f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>PG</th>\n",
       "      <th>KO</th>\n",
       "      <th>MCD</th>\n",
       "      <th>USB</th>\n",
       "      <th>JPM</th>\n",
       "      <th>GD</th>\n",
       "      <th>VZ</th>\n",
       "      <th>MMM</th>\n",
       "      <th>...</th>\n",
       "      <th>CL</th>\n",
       "      <th>LIN</th>\n",
       "      <th>DHR</th>\n",
       "      <th>HON</th>\n",
       "      <th>LMT</th>\n",
       "      <th>MDT</th>\n",
       "      <th>V</th>\n",
       "      <th>RTX</th>\n",
       "      <th>T</th>\n",
       "      <th>COST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>93.970001</td>\n",
       "      <td>83.830002</td>\n",
       "      <td>40.349998</td>\n",
       "      <td>96.379997</td>\n",
       "      <td>38.520000</td>\n",
       "      <td>56.860001</td>\n",
       "      <td>90.339996</td>\n",
       "      <td>49.599998</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>...</td>\n",
       "      <td>65.370003</td>\n",
       "      <td>124.239998</td>\n",
       "      <td>55.928734</td>\n",
       "      <td>83.009888</td>\n",
       "      <td>138.770004</td>\n",
       "      <td>57.639999</td>\n",
       "      <td>50.437500</td>\n",
       "      <td>69.030838</td>\n",
       "      <td>26.238670</td>\n",
       "      <td>123.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>93.629997</td>\n",
       "      <td>83.349998</td>\n",
       "      <td>40.369999</td>\n",
       "      <td>95.709999</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>57.189999</td>\n",
       "      <td>89.480003</td>\n",
       "      <td>49.369999</td>\n",
       "      <td>126.459999</td>\n",
       "      <td>...</td>\n",
       "      <td>65.040001</td>\n",
       "      <td>123.620003</td>\n",
       "      <td>55.845337</td>\n",
       "      <td>82.781075</td>\n",
       "      <td>136.229996</td>\n",
       "      <td>56.930000</td>\n",
       "      <td>50.685001</td>\n",
       "      <td>68.558846</td>\n",
       "      <td>26.132931</td>\n",
       "      <td>122.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>92.970001</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>39.830002</td>\n",
       "      <td>95.430000</td>\n",
       "      <td>38.610001</td>\n",
       "      <td>55.820000</td>\n",
       "      <td>89.230003</td>\n",
       "      <td>48.910000</td>\n",
       "      <td>126.830002</td>\n",
       "      <td>...</td>\n",
       "      <td>64.540001</td>\n",
       "      <td>122.489998</td>\n",
       "      <td>55.830173</td>\n",
       "      <td>82.809677</td>\n",
       "      <td>136.660004</td>\n",
       "      <td>56.910000</td>\n",
       "      <td>50.427502</td>\n",
       "      <td>68.628067</td>\n",
       "      <td>25.868580</td>\n",
       "      <td>120.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-06</td>\n",
       "      <td>94.440002</td>\n",
       "      <td>84.519997</td>\n",
       "      <td>40.459999</td>\n",
       "      <td>96.800003</td>\n",
       "      <td>39.660000</td>\n",
       "      <td>56.060001</td>\n",
       "      <td>90.790001</td>\n",
       "      <td>49.480000</td>\n",
       "      <td>128.610001</td>\n",
       "      <td>...</td>\n",
       "      <td>65.660004</td>\n",
       "      <td>125.459999</td>\n",
       "      <td>56.952236</td>\n",
       "      <td>84.201599</td>\n",
       "      <td>138.190002</td>\n",
       "      <td>58.139999</td>\n",
       "      <td>50.467499</td>\n",
       "      <td>69.930771</td>\n",
       "      <td>26.080059</td>\n",
       "      <td>122.059998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-09</td>\n",
       "      <td>94.440002</td>\n",
       "      <td>84.779999</td>\n",
       "      <td>40.400002</td>\n",
       "      <td>95.720001</td>\n",
       "      <td>39.740002</td>\n",
       "      <td>56.509998</td>\n",
       "      <td>90.529999</td>\n",
       "      <td>49.570000</td>\n",
       "      <td>128.570007</td>\n",
       "      <td>...</td>\n",
       "      <td>65.690002</td>\n",
       "      <td>125.410004</td>\n",
       "      <td>57.149357</td>\n",
       "      <td>83.772583</td>\n",
       "      <td>138.929993</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>50.397499</td>\n",
       "      <td>69.968536</td>\n",
       "      <td>26.200907</td>\n",
       "      <td>121.660004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>153.070007</td>\n",
       "      <td>122.150002</td>\n",
       "      <td>49.939999</td>\n",
       "      <td>204.839996</td>\n",
       "      <td>51.020000</td>\n",
       "      <td>150.559998</td>\n",
       "      <td>165.770004</td>\n",
       "      <td>54.799999</td>\n",
       "      <td>177.630005</td>\n",
       "      <td>...</td>\n",
       "      <td>74.440002</td>\n",
       "      <td>245.419998</td>\n",
       "      <td>214.410004</td>\n",
       "      <td>202.940002</td>\n",
       "      <td>338.250000</td>\n",
       "      <td>115.269997</td>\n",
       "      <td>211.500000</td>\n",
       "      <td>74.419998</td>\n",
       "      <td>21.842899</td>\n",
       "      <td>319.040009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>156.100006</td>\n",
       "      <td>125.980003</td>\n",
       "      <td>50.790001</td>\n",
       "      <td>207.369995</td>\n",
       "      <td>52.470001</td>\n",
       "      <td>150.910004</td>\n",
       "      <td>170.520004</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>180.800003</td>\n",
       "      <td>...</td>\n",
       "      <td>76.059998</td>\n",
       "      <td>247.639999</td>\n",
       "      <td>218.350006</td>\n",
       "      <td>206.580002</td>\n",
       "      <td>340.429993</td>\n",
       "      <td>118.260002</td>\n",
       "      <td>215.410004</td>\n",
       "      <td>75.180000</td>\n",
       "      <td>22.371601</td>\n",
       "      <td>317.320007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>157.399994</td>\n",
       "      <td>127.309998</td>\n",
       "      <td>51.639999</td>\n",
       "      <td>209.110001</td>\n",
       "      <td>54.049999</td>\n",
       "      <td>152.910004</td>\n",
       "      <td>172.690002</td>\n",
       "      <td>56.790001</td>\n",
       "      <td>183.770004</td>\n",
       "      <td>...</td>\n",
       "      <td>76.449997</td>\n",
       "      <td>253.679993</td>\n",
       "      <td>212.380005</td>\n",
       "      <td>207.699997</td>\n",
       "      <td>341.450012</td>\n",
       "      <td>116.669998</td>\n",
       "      <td>220.270004</td>\n",
       "      <td>75.610001</td>\n",
       "      <td>22.651056</td>\n",
       "      <td>311.420013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>157.699997</td>\n",
       "      <td>126.180000</td>\n",
       "      <td>50.860001</td>\n",
       "      <td>208.550003</td>\n",
       "      <td>52.900002</td>\n",
       "      <td>151.830002</td>\n",
       "      <td>168.740005</td>\n",
       "      <td>56.200001</td>\n",
       "      <td>181.179993</td>\n",
       "      <td>...</td>\n",
       "      <td>74.940002</td>\n",
       "      <td>262.339996</td>\n",
       "      <td>216.339996</td>\n",
       "      <td>207.610001</td>\n",
       "      <td>337.500000</td>\n",
       "      <td>117.050003</td>\n",
       "      <td>220.360001</td>\n",
       "      <td>74.830002</td>\n",
       "      <td>22.386707</td>\n",
       "      <td>318.779999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>159.149994</td>\n",
       "      <td>127.339996</td>\n",
       "      <td>51.439999</td>\n",
       "      <td>213.309998</td>\n",
       "      <td>53.779999</td>\n",
       "      <td>155.130005</td>\n",
       "      <td>172.419998</td>\n",
       "      <td>57.080002</td>\n",
       "      <td>184.509995</td>\n",
       "      <td>...</td>\n",
       "      <td>75.800003</td>\n",
       "      <td>265.640015</td>\n",
       "      <td>212.929993</td>\n",
       "      <td>212.910004</td>\n",
       "      <td>340.839996</td>\n",
       "      <td>118.660004</td>\n",
       "      <td>223.169998</td>\n",
       "      <td>76.559998</td>\n",
       "      <td>22.651056</td>\n",
       "      <td>323.829987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1829 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date         JNJ          PG         KO         MCD        USB  \\\n",
       "0     2013-12-03   93.970001   83.830002  40.349998   96.379997  38.520000   \n",
       "1     2013-12-04   93.629997   83.349998  40.369999   95.709999  39.000000   \n",
       "2     2013-12-05   92.970001   82.690002  39.830002   95.430000  38.610001   \n",
       "3     2013-12-06   94.440002   84.519997  40.459999   96.800003  39.660000   \n",
       "4     2013-12-09   94.440002   84.779999  40.400002   95.720001  39.740002   \n",
       "...          ...         ...         ...        ...         ...        ...   \n",
       "1824  2021-03-04  153.070007  122.150002  49.939999  204.839996  51.020000   \n",
       "1825  2021-03-05  156.100006  125.980003  50.790001  207.369995  52.470001   \n",
       "1826  2021-03-08  157.399994  127.309998  51.639999  209.110001  54.049999   \n",
       "1827  2021-03-09  157.699997  126.180000  50.860001  208.550003  52.900002   \n",
       "1828  2021-03-10  159.149994  127.339996  51.439999  213.309998  53.779999   \n",
       "\n",
       "             JPM          GD         VZ         MMM  ...         CL  \\\n",
       "0      56.860001   90.339996  49.599998  126.599998  ...  65.370003   \n",
       "1      57.189999   89.480003  49.369999  126.459999  ...  65.040001   \n",
       "2      55.820000   89.230003  48.910000  126.830002  ...  64.540001   \n",
       "3      56.060001   90.790001  49.480000  128.610001  ...  65.660004   \n",
       "4      56.509998   90.529999  49.570000  128.570007  ...  65.690002   \n",
       "...          ...         ...        ...         ...  ...        ...   \n",
       "1824  150.559998  165.770004  54.799999  177.630005  ...  74.440002   \n",
       "1825  150.910004  170.520004  56.000000  180.800003  ...  76.059998   \n",
       "1826  152.910004  172.690002  56.790001  183.770004  ...  76.449997   \n",
       "1827  151.830002  168.740005  56.200001  181.179993  ...  74.940002   \n",
       "1828  155.130005  172.419998  57.080002  184.509995  ...  75.800003   \n",
       "\n",
       "             LIN         DHR         HON         LMT         MDT           V  \\\n",
       "0     124.239998   55.928734   83.009888  138.770004   57.639999   50.437500   \n",
       "1     123.620003   55.845337   82.781075  136.229996   56.930000   50.685001   \n",
       "2     122.489998   55.830173   82.809677  136.660004   56.910000   50.427502   \n",
       "3     125.459999   56.952236   84.201599  138.190002   58.139999   50.467499   \n",
       "4     125.410004   57.149357   83.772583  138.929993   57.869999   50.397499   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1824  245.419998  214.410004  202.940002  338.250000  115.269997  211.500000   \n",
       "1825  247.639999  218.350006  206.580002  340.429993  118.260002  215.410004   \n",
       "1826  253.679993  212.380005  207.699997  341.450012  116.669998  220.270004   \n",
       "1827  262.339996  216.339996  207.610001  337.500000  117.050003  220.360001   \n",
       "1828  265.640015  212.929993  212.910004  340.839996  118.660004  223.169998   \n",
       "\n",
       "            RTX          T        COST  \n",
       "0     69.030838  26.238670  123.820000  \n",
       "1     68.558846  26.132931  122.970001  \n",
       "2     68.628067  25.868580  120.949997  \n",
       "3     69.930771  26.080059  122.059998  \n",
       "4     69.968536  26.200907  121.660004  \n",
       "...         ...        ...         ...  \n",
       "1824  74.419998  21.842899  319.040009  \n",
       "1825  75.180000  22.371601  317.320007  \n",
       "1826  75.610001  22.651056  311.420013  \n",
       "1827  74.830002  22.386707  318.779999  \n",
       "1828  76.559998  22.651056  323.829987  \n",
       "\n",
       "[1829 rows x 21 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(prices_full_train_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b9eef157",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "03c0fe9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JNJ</th>\n",
       "      <th>PG</th>\n",
       "      <th>KO</th>\n",
       "      <th>MCD</th>\n",
       "      <th>USB</th>\n",
       "      <th>JPM</th>\n",
       "      <th>GD</th>\n",
       "      <th>VZ</th>\n",
       "      <th>MMM</th>\n",
       "      <th>PEP</th>\n",
       "      <th>CL</th>\n",
       "      <th>LIN</th>\n",
       "      <th>DHR</th>\n",
       "      <th>HON</th>\n",
       "      <th>LMT</th>\n",
       "      <th>MDT</th>\n",
       "      <th>V</th>\n",
       "      <th>RTX</th>\n",
       "      <th>T</th>\n",
       "      <th>COST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-03</th>\n",
       "      <td>93.970001</td>\n",
       "      <td>83.830002</td>\n",
       "      <td>40.349998</td>\n",
       "      <td>96.379997</td>\n",
       "      <td>38.520000</td>\n",
       "      <td>56.860001</td>\n",
       "      <td>90.339996</td>\n",
       "      <td>49.599998</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>83.800003</td>\n",
       "      <td>65.370003</td>\n",
       "      <td>124.239998</td>\n",
       "      <td>55.928734</td>\n",
       "      <td>83.009888</td>\n",
       "      <td>138.770004</td>\n",
       "      <td>57.639999</td>\n",
       "      <td>50.437500</td>\n",
       "      <td>69.030838</td>\n",
       "      <td>26.238670</td>\n",
       "      <td>123.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-04</th>\n",
       "      <td>93.629997</td>\n",
       "      <td>83.349998</td>\n",
       "      <td>40.369999</td>\n",
       "      <td>95.709999</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>57.189999</td>\n",
       "      <td>89.480003</td>\n",
       "      <td>49.369999</td>\n",
       "      <td>126.459999</td>\n",
       "      <td>82.650002</td>\n",
       "      <td>65.040001</td>\n",
       "      <td>123.620003</td>\n",
       "      <td>55.845337</td>\n",
       "      <td>82.781075</td>\n",
       "      <td>136.229996</td>\n",
       "      <td>56.930000</td>\n",
       "      <td>50.685001</td>\n",
       "      <td>68.558846</td>\n",
       "      <td>26.132931</td>\n",
       "      <td>122.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-05</th>\n",
       "      <td>92.970001</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>39.830002</td>\n",
       "      <td>95.430000</td>\n",
       "      <td>38.610001</td>\n",
       "      <td>55.820000</td>\n",
       "      <td>89.230003</td>\n",
       "      <td>48.910000</td>\n",
       "      <td>126.830002</td>\n",
       "      <td>81.900002</td>\n",
       "      <td>64.540001</td>\n",
       "      <td>122.489998</td>\n",
       "      <td>55.830173</td>\n",
       "      <td>82.809677</td>\n",
       "      <td>136.660004</td>\n",
       "      <td>56.910000</td>\n",
       "      <td>50.427502</td>\n",
       "      <td>68.628067</td>\n",
       "      <td>25.868580</td>\n",
       "      <td>120.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-06</th>\n",
       "      <td>94.440002</td>\n",
       "      <td>84.519997</td>\n",
       "      <td>40.459999</td>\n",
       "      <td>96.800003</td>\n",
       "      <td>39.660000</td>\n",
       "      <td>56.060001</td>\n",
       "      <td>90.790001</td>\n",
       "      <td>49.480000</td>\n",
       "      <td>128.610001</td>\n",
       "      <td>83.150002</td>\n",
       "      <td>65.660004</td>\n",
       "      <td>125.459999</td>\n",
       "      <td>56.952236</td>\n",
       "      <td>84.201599</td>\n",
       "      <td>138.190002</td>\n",
       "      <td>58.139999</td>\n",
       "      <td>50.467499</td>\n",
       "      <td>69.930771</td>\n",
       "      <td>26.080059</td>\n",
       "      <td>122.059998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-09</th>\n",
       "      <td>94.440002</td>\n",
       "      <td>84.779999</td>\n",
       "      <td>40.400002</td>\n",
       "      <td>95.720001</td>\n",
       "      <td>39.740002</td>\n",
       "      <td>56.509998</td>\n",
       "      <td>90.529999</td>\n",
       "      <td>49.570000</td>\n",
       "      <td>128.570007</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>65.690002</td>\n",
       "      <td>125.410004</td>\n",
       "      <td>57.149357</td>\n",
       "      <td>83.772583</td>\n",
       "      <td>138.929993</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>50.397499</td>\n",
       "      <td>69.968536</td>\n",
       "      <td>26.200907</td>\n",
       "      <td>121.660004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  JNJ         PG         KO        MCD        USB        JPM  \\\n",
       "date                                                                           \n",
       "2013-12-03  93.970001  83.830002  40.349998  96.379997  38.520000  56.860001   \n",
       "2013-12-04  93.629997  83.349998  40.369999  95.709999  39.000000  57.189999   \n",
       "2013-12-05  92.970001  82.690002  39.830002  95.430000  38.610001  55.820000   \n",
       "2013-12-06  94.440002  84.519997  40.459999  96.800003  39.660000  56.060001   \n",
       "2013-12-09  94.440002  84.779999  40.400002  95.720001  39.740002  56.509998   \n",
       "\n",
       "                   GD         VZ         MMM        PEP         CL  \\\n",
       "date                                                                 \n",
       "2013-12-03  90.339996  49.599998  126.599998  83.800003  65.370003   \n",
       "2013-12-04  89.480003  49.369999  126.459999  82.650002  65.040001   \n",
       "2013-12-05  89.230003  48.910000  126.830002  81.900002  64.540001   \n",
       "2013-12-06  90.790001  49.480000  128.610001  83.150002  65.660004   \n",
       "2013-12-09  90.529999  49.570000  128.570007  82.690002  65.690002   \n",
       "\n",
       "                   LIN        DHR        HON         LMT        MDT  \\\n",
       "date                                                                  \n",
       "2013-12-03  124.239998  55.928734  83.009888  138.770004  57.639999   \n",
       "2013-12-04  123.620003  55.845337  82.781075  136.229996  56.930000   \n",
       "2013-12-05  122.489998  55.830173  82.809677  136.660004  56.910000   \n",
       "2013-12-06  125.459999  56.952236  84.201599  138.190002  58.139999   \n",
       "2013-12-09  125.410004  57.149357  83.772583  138.929993  57.869999   \n",
       "\n",
       "                    V        RTX          T        COST  \n",
       "date                                                     \n",
       "2013-12-03  50.437500  69.030838  26.238670  123.820000  \n",
       "2013-12-04  50.685001  68.558846  26.132931  122.970001  \n",
       "2013-12-05  50.427502  68.628067  25.868580  120.949997  \n",
       "2013-12-06  50.467499  69.930771  26.080059  122.059998  \n",
       "2013-12-09  50.397499  69.968536  26.200907  121.660004  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# df = df.drop('level_0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1dfd8cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3517ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "1bf0f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Function for Displaying the Cleaned Weights\n",
    "def show_clean_p(port_df):\n",
    "    p1_show_1 = (port_df.transpose()[0]).map(lambda x: \"{:.3%}\".format(x)).to_frame().transpose()\n",
    "    return display(HTML(p1_show_1.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "9b7dd6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3fa5fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = list(df.columns) # Get List of all ticker symbols\n",
    "n_assets = len(ticker_list) # Number of assets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "cb2daf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Daily Draw Down\n",
    "\n",
    "ticker_symb = ['VZ']\n",
    "prices = df[ticker_symb]\n",
    "window = 250\n",
    "\n",
    "def get_daily_max_drawdown(prices, window):\n",
    "    max_rolling = prices.rolling(min_periods=1, window=window).max()\n",
    "    daily_drawdown = (prices / max_rolling) - 1\n",
    "    max_daily_drawdown = daily_drawdown.rolling(min_periods=1, window=window).min()\n",
    "    return daily_drawdown,max_daily_drawdown\n",
    "\n",
    "max_rolling = prices.rolling(min_periods=1, window=window).max()\n",
    "\n",
    "daily_drawdown, max_daily_drawdown = get_daily_max_drawdown(prices, window)\n",
    "daily_drawdown.name = \"{} daily drawdown\".format(ticker_symb) \n",
    "#daily_drawdown = pd.DataFrame(daily_drawdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f5775545",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "789e5f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "daily_drawdown.plot(ax=ax);\n",
    "ax.set_title(\"Daily Drawdown\", fontsize=14)\n",
    "plt.legend(loc=\"best\");\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('results/daily_drawdown.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1dbd4c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the average daily return to calculate portfolio return\n",
    "\n",
    "returns = df.pct_change() # get the assets daily returns\n",
    "mean_daily_returns = returns.mean().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "4a56997d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JNJ</th>\n",
       "      <th>PG</th>\n",
       "      <th>KO</th>\n",
       "      <th>MCD</th>\n",
       "      <th>USB</th>\n",
       "      <th>JPM</th>\n",
       "      <th>GD</th>\n",
       "      <th>VZ</th>\n",
       "      <th>MMM</th>\n",
       "      <th>PEP</th>\n",
       "      <th>CL</th>\n",
       "      <th>LIN</th>\n",
       "      <th>DHR</th>\n",
       "      <th>HON</th>\n",
       "      <th>LMT</th>\n",
       "      <th>MDT</th>\n",
       "      <th>V</th>\n",
       "      <th>RTX</th>\n",
       "      <th>T</th>\n",
       "      <th>COST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-03</th>\n",
       "      <td>93.970001</td>\n",
       "      <td>83.830002</td>\n",
       "      <td>40.349998</td>\n",
       "      <td>96.379997</td>\n",
       "      <td>38.520000</td>\n",
       "      <td>56.860001</td>\n",
       "      <td>90.339996</td>\n",
       "      <td>49.599998</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>83.800003</td>\n",
       "      <td>65.370003</td>\n",
       "      <td>124.239998</td>\n",
       "      <td>55.928734</td>\n",
       "      <td>83.009888</td>\n",
       "      <td>138.770004</td>\n",
       "      <td>57.639999</td>\n",
       "      <td>50.437500</td>\n",
       "      <td>69.030838</td>\n",
       "      <td>26.238670</td>\n",
       "      <td>123.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-04</th>\n",
       "      <td>93.629997</td>\n",
       "      <td>83.349998</td>\n",
       "      <td>40.369999</td>\n",
       "      <td>95.709999</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>57.189999</td>\n",
       "      <td>89.480003</td>\n",
       "      <td>49.369999</td>\n",
       "      <td>126.459999</td>\n",
       "      <td>82.650002</td>\n",
       "      <td>65.040001</td>\n",
       "      <td>123.620003</td>\n",
       "      <td>55.845337</td>\n",
       "      <td>82.781075</td>\n",
       "      <td>136.229996</td>\n",
       "      <td>56.930000</td>\n",
       "      <td>50.685001</td>\n",
       "      <td>68.558846</td>\n",
       "      <td>26.132931</td>\n",
       "      <td>122.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-05</th>\n",
       "      <td>92.970001</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>39.830002</td>\n",
       "      <td>95.430000</td>\n",
       "      <td>38.610001</td>\n",
       "      <td>55.820000</td>\n",
       "      <td>89.230003</td>\n",
       "      <td>48.910000</td>\n",
       "      <td>126.830002</td>\n",
       "      <td>81.900002</td>\n",
       "      <td>64.540001</td>\n",
       "      <td>122.489998</td>\n",
       "      <td>55.830173</td>\n",
       "      <td>82.809677</td>\n",
       "      <td>136.660004</td>\n",
       "      <td>56.910000</td>\n",
       "      <td>50.427502</td>\n",
       "      <td>68.628067</td>\n",
       "      <td>25.868580</td>\n",
       "      <td>120.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-06</th>\n",
       "      <td>94.440002</td>\n",
       "      <td>84.519997</td>\n",
       "      <td>40.459999</td>\n",
       "      <td>96.800003</td>\n",
       "      <td>39.660000</td>\n",
       "      <td>56.060001</td>\n",
       "      <td>90.790001</td>\n",
       "      <td>49.480000</td>\n",
       "      <td>128.610001</td>\n",
       "      <td>83.150002</td>\n",
       "      <td>65.660004</td>\n",
       "      <td>125.459999</td>\n",
       "      <td>56.952236</td>\n",
       "      <td>84.201599</td>\n",
       "      <td>138.190002</td>\n",
       "      <td>58.139999</td>\n",
       "      <td>50.467499</td>\n",
       "      <td>69.930771</td>\n",
       "      <td>26.080059</td>\n",
       "      <td>122.059998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-09</th>\n",
       "      <td>94.440002</td>\n",
       "      <td>84.779999</td>\n",
       "      <td>40.400002</td>\n",
       "      <td>95.720001</td>\n",
       "      <td>39.740002</td>\n",
       "      <td>56.509998</td>\n",
       "      <td>90.529999</td>\n",
       "      <td>49.570000</td>\n",
       "      <td>128.570007</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>65.690002</td>\n",
       "      <td>125.410004</td>\n",
       "      <td>57.149357</td>\n",
       "      <td>83.772583</td>\n",
       "      <td>138.929993</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>50.397499</td>\n",
       "      <td>69.968536</td>\n",
       "      <td>26.200907</td>\n",
       "      <td>121.660004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-04</th>\n",
       "      <td>153.070007</td>\n",
       "      <td>122.150002</td>\n",
       "      <td>49.939999</td>\n",
       "      <td>204.839996</td>\n",
       "      <td>51.020000</td>\n",
       "      <td>150.559998</td>\n",
       "      <td>165.770004</td>\n",
       "      <td>54.799999</td>\n",
       "      <td>177.630005</td>\n",
       "      <td>128.830002</td>\n",
       "      <td>74.440002</td>\n",
       "      <td>245.419998</td>\n",
       "      <td>214.410004</td>\n",
       "      <td>202.940002</td>\n",
       "      <td>338.250000</td>\n",
       "      <td>115.269997</td>\n",
       "      <td>211.500000</td>\n",
       "      <td>74.419998</td>\n",
       "      <td>21.842899</td>\n",
       "      <td>319.040009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-05</th>\n",
       "      <td>156.100006</td>\n",
       "      <td>125.980003</td>\n",
       "      <td>50.790001</td>\n",
       "      <td>207.369995</td>\n",
       "      <td>52.470001</td>\n",
       "      <td>150.910004</td>\n",
       "      <td>170.520004</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>180.800003</td>\n",
       "      <td>133.029999</td>\n",
       "      <td>76.059998</td>\n",
       "      <td>247.639999</td>\n",
       "      <td>218.350006</td>\n",
       "      <td>206.580002</td>\n",
       "      <td>340.429993</td>\n",
       "      <td>118.260002</td>\n",
       "      <td>215.410004</td>\n",
       "      <td>75.180000</td>\n",
       "      <td>22.371601</td>\n",
       "      <td>317.320007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-08</th>\n",
       "      <td>157.399994</td>\n",
       "      <td>127.309998</td>\n",
       "      <td>51.639999</td>\n",
       "      <td>209.110001</td>\n",
       "      <td>54.049999</td>\n",
       "      <td>152.910004</td>\n",
       "      <td>172.690002</td>\n",
       "      <td>56.790001</td>\n",
       "      <td>183.770004</td>\n",
       "      <td>132.130005</td>\n",
       "      <td>76.449997</td>\n",
       "      <td>253.679993</td>\n",
       "      <td>212.380005</td>\n",
       "      <td>207.699997</td>\n",
       "      <td>341.450012</td>\n",
       "      <td>116.669998</td>\n",
       "      <td>220.270004</td>\n",
       "      <td>75.610001</td>\n",
       "      <td>22.651056</td>\n",
       "      <td>311.420013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-09</th>\n",
       "      <td>157.699997</td>\n",
       "      <td>126.180000</td>\n",
       "      <td>50.860001</td>\n",
       "      <td>208.550003</td>\n",
       "      <td>52.900002</td>\n",
       "      <td>151.830002</td>\n",
       "      <td>168.740005</td>\n",
       "      <td>56.200001</td>\n",
       "      <td>181.179993</td>\n",
       "      <td>132.250000</td>\n",
       "      <td>74.940002</td>\n",
       "      <td>262.339996</td>\n",
       "      <td>216.339996</td>\n",
       "      <td>207.610001</td>\n",
       "      <td>337.500000</td>\n",
       "      <td>117.050003</td>\n",
       "      <td>220.360001</td>\n",
       "      <td>74.830002</td>\n",
       "      <td>22.386707</td>\n",
       "      <td>318.779999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-10</th>\n",
       "      <td>159.149994</td>\n",
       "      <td>127.339996</td>\n",
       "      <td>51.439999</td>\n",
       "      <td>213.309998</td>\n",
       "      <td>53.779999</td>\n",
       "      <td>155.130005</td>\n",
       "      <td>172.419998</td>\n",
       "      <td>57.080002</td>\n",
       "      <td>184.509995</td>\n",
       "      <td>133.580002</td>\n",
       "      <td>75.800003</td>\n",
       "      <td>265.640015</td>\n",
       "      <td>212.929993</td>\n",
       "      <td>212.910004</td>\n",
       "      <td>340.839996</td>\n",
       "      <td>118.660004</td>\n",
       "      <td>223.169998</td>\n",
       "      <td>76.559998</td>\n",
       "      <td>22.651056</td>\n",
       "      <td>323.829987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1829 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   JNJ          PG         KO         MCD        USB  \\\n",
       "date                                                                   \n",
       "2013-12-03   93.970001   83.830002  40.349998   96.379997  38.520000   \n",
       "2013-12-04   93.629997   83.349998  40.369999   95.709999  39.000000   \n",
       "2013-12-05   92.970001   82.690002  39.830002   95.430000  38.610001   \n",
       "2013-12-06   94.440002   84.519997  40.459999   96.800003  39.660000   \n",
       "2013-12-09   94.440002   84.779999  40.400002   95.720001  39.740002   \n",
       "...                ...         ...        ...         ...        ...   \n",
       "2021-03-04  153.070007  122.150002  49.939999  204.839996  51.020000   \n",
       "2021-03-05  156.100006  125.980003  50.790001  207.369995  52.470001   \n",
       "2021-03-08  157.399994  127.309998  51.639999  209.110001  54.049999   \n",
       "2021-03-09  157.699997  126.180000  50.860001  208.550003  52.900002   \n",
       "2021-03-10  159.149994  127.339996  51.439999  213.309998  53.779999   \n",
       "\n",
       "                   JPM          GD         VZ         MMM         PEP  \\\n",
       "date                                                                    \n",
       "2013-12-03   56.860001   90.339996  49.599998  126.599998   83.800003   \n",
       "2013-12-04   57.189999   89.480003  49.369999  126.459999   82.650002   \n",
       "2013-12-05   55.820000   89.230003  48.910000  126.830002   81.900002   \n",
       "2013-12-06   56.060001   90.790001  49.480000  128.610001   83.150002   \n",
       "2013-12-09   56.509998   90.529999  49.570000  128.570007   82.690002   \n",
       "...                ...         ...        ...         ...         ...   \n",
       "2021-03-04  150.559998  165.770004  54.799999  177.630005  128.830002   \n",
       "2021-03-05  150.910004  170.520004  56.000000  180.800003  133.029999   \n",
       "2021-03-08  152.910004  172.690002  56.790001  183.770004  132.130005   \n",
       "2021-03-09  151.830002  168.740005  56.200001  181.179993  132.250000   \n",
       "2021-03-10  155.130005  172.419998  57.080002  184.509995  133.580002   \n",
       "\n",
       "                   CL         LIN         DHR         HON         LMT  \\\n",
       "date                                                                    \n",
       "2013-12-03  65.370003  124.239998   55.928734   83.009888  138.770004   \n",
       "2013-12-04  65.040001  123.620003   55.845337   82.781075  136.229996   \n",
       "2013-12-05  64.540001  122.489998   55.830173   82.809677  136.660004   \n",
       "2013-12-06  65.660004  125.459999   56.952236   84.201599  138.190002   \n",
       "2013-12-09  65.690002  125.410004   57.149357   83.772583  138.929993   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "2021-03-04  74.440002  245.419998  214.410004  202.940002  338.250000   \n",
       "2021-03-05  76.059998  247.639999  218.350006  206.580002  340.429993   \n",
       "2021-03-08  76.449997  253.679993  212.380005  207.699997  341.450012   \n",
       "2021-03-09  74.940002  262.339996  216.339996  207.610001  337.500000   \n",
       "2021-03-10  75.800003  265.640015  212.929993  212.910004  340.839996   \n",
       "\n",
       "                   MDT           V        RTX          T        COST  \n",
       "date                                                                  \n",
       "2013-12-03   57.639999   50.437500  69.030838  26.238670  123.820000  \n",
       "2013-12-04   56.930000   50.685001  68.558846  26.132931  122.970001  \n",
       "2013-12-05   56.910000   50.427502  68.628067  25.868580  120.949997  \n",
       "2013-12-06   58.139999   50.467499  69.930771  26.080059  122.059998  \n",
       "2013-12-09   57.869999   50.397499  69.968536  26.200907  121.660004  \n",
       "...                ...         ...        ...        ...         ...  \n",
       "2021-03-04  115.269997  211.500000  74.419998  21.842899  319.040009  \n",
       "2021-03-05  118.260002  215.410004  75.180000  22.371601  317.320007  \n",
       "2021-03-08  116.669998  220.270004  75.610001  22.651056  311.420013  \n",
       "2021-03-09  117.050003  220.360001  74.830002  22.386707  318.779999  \n",
       "2021-03-10  118.660004  223.169998  76.559998  22.651056  323.829987  \n",
       "\n",
       "[1829 rows x 20 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0e30cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annualized Return, Variance and Standard Deviation\n",
    "\n",
    "def get_annualized_return(prices, weigths):\n",
    "    months = (pd.to_datetime(df.index)[-1] - pd.to_datetime(df.index)[0]) / np.timedelta64(1, 'M')\n",
    "    months = np.floor(months)\n",
    "    total_return = (prices.iloc[-1].dot(weigths) - prices.iloc[0].dot(weigths)) / prices.iloc[0].dot(weigths)\n",
    "    annualized_return = ((1 + total_return) ** (12 / months)) - 1\n",
    "    return annualized_return\n",
    "\n",
    "def get_portfolio_variance(returns, weigths):\n",
    "    covariance_returns = returns.cov() * 250\n",
    "    return np.dot(weigths.T, np.dot(covariance_returns, weigths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d53293c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharpe ratio\n",
    "rfr = 0.04 #Risk free rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "99e61fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "706d26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import env_portfolio\n",
    "from env_portfolio import StockPortfolioEnv\n",
    "\n",
    "import models\n",
    "from models import DRLAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b9196158",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from backtest import BackTestStats, BaselineStats, BackTestPlot, backtest_strat, baseline_strat\n",
    "from backtest import backtest_strat, baseline_strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "62adef5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 20, State Space: 20\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train_df.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "00028ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_initial = [1/stock_dimension]*stock_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d8cab849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>65.010002</td>\n",
       "      <td>65.430000</td>\n",
       "      <td>64.879997</td>\n",
       "      <td>65.370003</td>\n",
       "      <td>2183700</td>\n",
       "      <td>CL</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>123.720001</td>\n",
       "      <td>123.970001</td>\n",
       "      <td>122.970001</td>\n",
       "      <td>123.820000</td>\n",
       "      <td>1767900</td>\n",
       "      <td>COST</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>56.315392</td>\n",
       "      <td>56.444275</td>\n",
       "      <td>55.754360</td>\n",
       "      <td>55.928734</td>\n",
       "      <td>3117061</td>\n",
       "      <td>DHR</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>91.089996</td>\n",
       "      <td>91.360001</td>\n",
       "      <td>90.019997</td>\n",
       "      <td>90.339996</td>\n",
       "      <td>1198600</td>\n",
       "      <td>GD</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>82.638069</td>\n",
       "      <td>83.009888</td>\n",
       "      <td>2430852</td>\n",
       "      <td>HON</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        Open        High         Low       Close   Volume   tic  \\\n",
       "0  2013-12-03   65.010002   65.430000   64.879997   65.370003  2183700    CL   \n",
       "0  2013-12-03  123.720001  123.970001  122.970001  123.820000  1767900  COST   \n",
       "0  2013-12-03   56.315392   56.444275   55.754360   55.928734  3117061   DHR   \n",
       "0  2013-12-03   91.089996   91.360001   90.019997   90.339996  1198600    GD   \n",
       "0  2013-12-03   83.848846   83.848846   82.638069   83.009888  2430852   HON   \n",
       "\n",
       "                                            cov_list       f01       f02  \\\n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "\n",
       "        f03       f04  \n",
       "0  1.991801  1.938116  \n",
       "0  1.991801  1.938116  \n",
       "0  1.991801  1.938116  \n",
       "0  1.991801  1.938116  \n",
       "0  1.991801  1.938116  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "21ef9a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36560, 12)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "6025e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.rename(columns={'Close': 'close'})\n",
    "train_df = train_df.rename(columns={'Open': 'open'})\n",
    "train_df = train_df.rename(columns={'High': 'high'})\n",
    "train_df = train_df.rename(columns={'Low': 'low'})\n",
    "train_df = train_df.rename(columns={'Volume': 'volume'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "9a40d738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>65.010002</td>\n",
       "      <td>65.430000</td>\n",
       "      <td>64.879997</td>\n",
       "      <td>65.370003</td>\n",
       "      <td>2183700</td>\n",
       "      <td>CL</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>123.720001</td>\n",
       "      <td>123.970001</td>\n",
       "      <td>122.970001</td>\n",
       "      <td>123.820000</td>\n",
       "      <td>1767900</td>\n",
       "      <td>COST</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>56.315392</td>\n",
       "      <td>56.444275</td>\n",
       "      <td>55.754360</td>\n",
       "      <td>55.928734</td>\n",
       "      <td>3117061</td>\n",
       "      <td>DHR</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>91.089996</td>\n",
       "      <td>91.360001</td>\n",
       "      <td>90.019997</td>\n",
       "      <td>90.339996</td>\n",
       "      <td>1198600</td>\n",
       "      <td>GD</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>83.848846</td>\n",
       "      <td>82.638069</td>\n",
       "      <td>83.009888</td>\n",
       "      <td>2430852</td>\n",
       "      <td>HON</td>\n",
       "      <td>[[9.88188682115059e-05, 4.637338976698862e-05,...</td>\n",
       "      <td>0.968878</td>\n",
       "      <td>1.040823</td>\n",
       "      <td>1.991801</td>\n",
       "      <td>1.938116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close   volume   tic  \\\n",
       "0  2013-12-03   65.010002   65.430000   64.879997   65.370003  2183700    CL   \n",
       "0  2013-12-03  123.720001  123.970001  122.970001  123.820000  1767900  COST   \n",
       "0  2013-12-03   56.315392   56.444275   55.754360   55.928734  3117061   DHR   \n",
       "0  2013-12-03   91.089996   91.360001   90.019997   90.339996  1198600    GD   \n",
       "0  2013-12-03   83.848846   83.848846   82.638069   83.009888  2430852   HON   \n",
       "\n",
       "                                            cov_list       f01       f02  \\\n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "0  [[9.88188682115059e-05, 4.637338976698862e-05,...  0.968878  1.040823   \n",
       "\n",
       "        f03       f04  \n",
       "0  1.991801  1.938116  \n",
       "0  1.991801  1.938116  \n",
       "0  1.991801  1.938116  \n",
       "0  1.991801  1.938116  \n",
       "0  1.991801  1.938116  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8e4f3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_indicator_list = ['f01','f02','f03','f04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9da5f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 500, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": tech_indicator_list, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 0,\n",
    "    'initial_weights': [1/stock_dimension]*stock_dimension\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ec64e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_train_gym = StockPortfolioEnv(df = train_df, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "90d6989c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SANJANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b460cb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "250e6859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/a2c\\a2c_16\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 9.25e+07  |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 1.48e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 1.18e+08  |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 2.43e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.4e+08  |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 3.22e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1985706.0745088018\n",
      "Sharpe:  0.6681548443659734\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 9.61e+07 |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 1.18e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 1.07e+08 |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 1.81e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 1.26e+08 |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 2.46e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 128      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 1.43e+08 |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 3.23e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1966673.4772005985\n",
      "Sharpe:  0.6640409189458466\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 9.71e+07  |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 1.43e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 1.16e+08 |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 2.15e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 1.3e+08   |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 3.07e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2230052.0858664415\n",
      "Sharpe:  0.7744215795781343\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 7.87e+07 |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 1.04e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 126      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 8.99e+07 |\n",
      "|    std                | 0.995    |\n",
      "|    value_loss         | 1.52e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 1.29e+08 |\n",
      "|    std                | 0.994    |\n",
      "|    value_loss         | 2.68e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 1.63e+08 |\n",
      "|    std                | 0.994    |\n",
      "|    value_loss         | 3.93e+13 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2087013.646114219\n",
      "Sharpe:  0.7219374524359692\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 9.26e+07 |\n",
      "|    std                | 0.994    |\n",
      "|    value_loss         | 1.27e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 129      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 1.11e+08 |\n",
      "|    std                | 0.993    |\n",
      "|    value_loss         | 1.97e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 130      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 1.27e+08 |\n",
      "|    std                | 0.993    |\n",
      "|    value_loss         | 2.66e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 1.81e+08 |\n",
      "|    std                | 0.993    |\n",
      "|    value_loss         | 3.81e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2072393.5237451503\n",
      "Sharpe:  0.7158672198423025\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 1.06e+08 |\n",
      "|    std                | 0.993    |\n",
      "|    value_loss         | 1.41e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 131      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 1.11e+08 |\n",
      "|    std                | 0.992    |\n",
      "|    value_loss         | 2.04e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 132      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 1.24e+08 |\n",
      "|    std                | 0.991    |\n",
      "|    value_loss         | 2.98e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1984906.7706966996\n",
      "Sharpe:  0.6717360273424073\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 132       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 9.02e+07  |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 1.11e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 9.29e+07 |\n",
      "|    std                | 0.991    |\n",
      "|    value_loss         | 1.47e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 133      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 1.33e+08 |\n",
      "|    std                | 0.991    |\n",
      "|    value_loss         | 2.67e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 1.57e+08 |\n",
      "|    std                | 0.99     |\n",
      "|    value_loss         | 3.48e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1960141.5511358092\n",
      "Sharpe:  0.662113875519049\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 9.02e+07 |\n",
      "|    std                | 0.99     |\n",
      "|    value_loss         | 1.31e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 134       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 1.03e+08  |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 1.73e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 1.33e+08 |\n",
      "|    std                | 0.988    |\n",
      "|    value_loss         | 2.58e+13 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 135       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 1.52e+08  |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 4.09e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2016732.5216725233\n",
      "Sharpe:  0.684157900601023\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 1.1e+08  |\n",
      "|    std                | 0.988    |\n",
      "|    value_loss         | 1.44e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 135       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 114       |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | 1.17e+08  |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 2.24e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 1.43e+08 |\n",
      "|    std                | 0.986    |\n",
      "|    value_loss         | 3.05e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2010296.3419907016\n",
      "Sharpe:  0.6797819650803764\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 135       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 8.76e+07  |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 1e+13     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 9.22e+07 |\n",
      "|    std                | 0.985    |\n",
      "|    value_loss         | 1.42e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 136       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 1.43e+08  |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 2.72e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 1.57e+08 |\n",
      "|    std                | 0.983    |\n",
      "|    value_loss         | 3.44e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1885211.8102184478\n",
      "Sharpe:  0.6264431909367763\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 9.33e+07 |\n",
      "|    std                | 0.983    |\n",
      "|    value_loss         | 1.29e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 1.15e+08 |\n",
      "|    std                | 0.983    |\n",
      "|    value_loss         | 1.91e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 1.31e+08 |\n",
      "|    std                | 0.982    |\n",
      "|    value_loss         | 2.94e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 145       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 1.69e+08  |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 4.05e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2131816.008964318\n",
      "Sharpe:  0.7358829136579589\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 9.79e+07  |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 1.47e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 1.06e+08 |\n",
      "|    std                | 0.982    |\n",
      "|    value_loss         | 2.29e+13 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 1.46e+08 |\n",
      "|    std                | 0.982    |\n",
      "|    value_loss         | 2.99e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1903085.3348566769\n",
      "Sharpe:  0.6386540207762275\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 8.3e+07  |\n",
      "|    std                | 0.982    |\n",
      "|    value_loss         | 1.11e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 1.11e+08  |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 1.54e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 1.16e+08 |\n",
      "|    std                | 0.981    |\n",
      "|    value_loss         | 2.63e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 1.66e+08 |\n",
      "|    std                | 0.981    |\n",
      "|    value_loss         | 4.06e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1919159.138727104\n",
      "Sharpe:  0.6437342135126618\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 9.02e+07 |\n",
      "|    std                | 0.981    |\n",
      "|    value_loss         | 1.31e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 1.05e+08 |\n",
      "|    std                | 0.98     |\n",
      "|    value_loss         | 1.72e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 1.3e+08  |\n",
      "|    std                | 0.98     |\n",
      "|    value_loss         | 2.66e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 183       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 1.62e+08  |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 4.46e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2129132.364939704\n",
      "Sharpe:  0.7345773994634626\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 9.52e+07  |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 1.4e+13   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 1.35e+08 |\n",
      "|    std                | 0.978    |\n",
      "|    value_loss         | 2.18e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 1.41e+08 |\n",
      "|    std                | 0.976    |\n",
      "|    value_loss         | 3.09e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2010866.4742235392\n",
      "Sharpe:  0.684824295582867\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 1.04e+08 |\n",
      "|    std                | 0.976    |\n",
      "|    value_loss         | 1.15e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 9.93e+07 |\n",
      "|    std                | 0.975    |\n",
      "|    value_loss         | 1.67e+13 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 1.34e+08 |\n",
      "|    std                | 0.975    |\n",
      "|    value_loss         | 2.79e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 1.39e+08 |\n",
      "|    std                | 0.974    |\n",
      "|    value_loss         | 3.29e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1990581.5735420564\n",
      "Sharpe:  0.6729076305025802\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 9.16e+07 |\n",
      "|    std                | 0.973    |\n",
      "|    value_loss         | 1.41e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 1.01e+08 |\n",
      "|    std                | 0.973    |\n",
      "|    value_loss         | 1.84e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 1.35e+08 |\n",
      "|    std                | 0.974    |\n",
      "|    value_loss         | 2.65e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 139       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 222       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | 1.5e+08   |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 4.06e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2029899.7927648344\n",
      "Sharpe:  0.6875232277952251\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 1.09e+08  |\n",
      "|    std                | 0.972     |\n",
      "|    value_loss         | 1.47e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 1.17e+08 |\n",
      "|    std                | 0.971    |\n",
      "|    value_loss         | 2.23e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 1.37e+08 |\n",
      "|    std                | 0.971    |\n",
      "|    value_loss         | 3.19e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1877137.4801075086\n",
      "Sharpe:  0.6237930636673477\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 238       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 8.61e+07  |\n",
      "|    std                | 0.971     |\n",
      "|    value_loss         | 1.13e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 1.01e+08 |\n",
      "|    std                | 0.971    |\n",
      "|    value_loss         | 1.64e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | 1.18e+08  |\n",
      "|    std                | 0.97      |\n",
      "|    value_loss         | 2.57e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 248       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 1.37e+08  |\n",
      "|    std                | 0.97      |\n",
      "|    value_loss         | 2.63e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1964610.7979921545\n",
      "Sharpe:  0.662441897997365\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 252      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 8.36e+07 |\n",
      "|    std                | 0.969    |\n",
      "|    value_loss         | 1.36e+13 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 255       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 1.12e+08  |\n",
      "|    std                | 0.969     |\n",
      "|    value_loss         | 1.88e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 1.24e+08 |\n",
      "|    std                | 0.969    |\n",
      "|    value_loss         | 2.73e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 1.63e+08 |\n",
      "|    std                | 0.968    |\n",
      "|    value_loss         | 4.63e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2087085.0132822588\n",
      "Sharpe:  0.7115484961375589\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 8.7e+07  |\n",
      "|    std                | 0.968    |\n",
      "|    value_loss         | 1.27e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 271       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 1.21e+08  |\n",
      "|    std                | 0.968     |\n",
      "|    value_loss         | 2.19e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 1.27e+08 |\n",
      "|    std                | 0.968    |\n",
      "|    value_loss         | 3.15e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1936004.7834973568\n",
      "Sharpe:  0.644828229720626\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 9.34e+07 |\n",
      "|    std                | 0.968    |\n",
      "|    value_loss         | 1.18e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 9.45e+07 |\n",
      "|    std                | 0.967    |\n",
      "|    value_loss         | 1.68e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 1.19e+08 |\n",
      "|    std                | 0.967    |\n",
      "|    value_loss         | 2.35e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 288       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 1.35e+08  |\n",
      "|    std                | 0.967     |\n",
      "|    value_loss         | 2.73e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1943952.802822156\n",
      "Sharpe:  0.6486643920834789\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 292      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 9.12e+07 |\n",
      "|    std                | 0.967    |\n",
      "|    value_loss         | 1.4e+13  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 1.16e+08 |\n",
      "|    std                | 0.968    |\n",
      "|    value_loss         | 1.87e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 299       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 1.21e+08  |\n",
      "|    std                | 0.968     |\n",
      "|    value_loss         | 2.07e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 1.57e+08 |\n",
      "|    std                | 0.967    |\n",
      "|    value_loss         | 3.66e+13 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1822706.4922882218\n",
      "Sharpe:  0.5941134427098488\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 306       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 1.01e+08  |\n",
      "|    std                | 0.967     |\n",
      "|    value_loss         | 1.35e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 1.21e+08 |\n",
      "|    std                | 0.967    |\n",
      "|    value_loss         | 2.28e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 313       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 1.48e+08  |\n",
      "|    std                | 0.966     |\n",
      "|    value_loss         | 3.51e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1970279.461625475\n",
      "Sharpe:  0.6599906720905224\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 317      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 8.91e+07 |\n",
      "|    std                | 0.966    |\n",
      "|    value_loss         | 1.21e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 321      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 1.01e+08 |\n",
      "|    std                | 0.966    |\n",
      "|    value_loss         | 1.69e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 326      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 1.26e+08 |\n",
      "|    std                | 0.966    |\n",
      "|    value_loss         | 2.47e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 329      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 1.3e+08  |\n",
      "|    std                | 0.965    |\n",
      "|    value_loss         | 2.68e+13 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1928108.5222087689\n",
      "Sharpe:  0.6444958436291457\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 333       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 9.03e+07  |\n",
      "|    std                | 0.964     |\n",
      "|    value_loss         | 1.38e+13  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 336      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 1.05e+08 |\n",
      "|    std                | 0.963    |\n",
      "|    value_loss         | 1.85e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 339      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 1.29e+08 |\n",
      "|    std                | 0.963    |\n",
      "|    value_loss         | 2.5e+13  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 343       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 1.63e+08  |\n",
      "|    std                | 0.962     |\n",
      "|    value_loss         | 4.43e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2029627.141766275\n",
      "Sharpe:  0.6904726211641108\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 347      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 9.96e+07 |\n",
      "|    std                | 0.962    |\n",
      "|    value_loss         | 1.46e+13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 138      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 351      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 1.28e+08 |\n",
      "|    std                | 0.961    |\n",
      "|    value_loss         | 2.44e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 138       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 354       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 1.39e+08  |\n",
      "|    std                | 0.961     |\n",
      "|    value_loss         | 3.34e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1983053.8257903492\n",
      "Sharpe:  0.670230733571736\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 8.63e+07 |\n",
      "|    std                | 0.96     |\n",
      "|    value_loss         | 1.18e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 362       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 9.5e+07   |\n",
      "|    std                | 0.959     |\n",
      "|    value_loss         | 1.67e+13  |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e111373c",
   "metadata": {},
   "source": [
    "# ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "12de3709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.005,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e28ce21b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/ppo\\ppo_5\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2002461.616346536\n",
      "Sharpe:  0.6826500134897019\n",
      "=================================\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 198  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 10   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2079165.8552976106\n",
      "Sharpe:  0.7099290200577231\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 179       |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 22        |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.83e+14  |\n",
      "|    n_updates            | 10        |\n",
      "|    policy_gradient_loss | -2.87e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.69e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2070072.6495108923\n",
      "Sharpe:  0.706467924866239\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 175       |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 6144      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.95e+14  |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -4.56e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.99e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2029872.4167627848\n",
      "Sharpe:  0.6885284564639672\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 174       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 46        |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.81e+14  |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -3.09e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.92e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2091734.4815315965\n",
      "Sharpe:  0.7116765132693843\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 170       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 60        |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.89e+14  |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -3.27e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.81e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2019908.0636199613\n",
      "Sharpe:  0.682995265217757\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 164       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.14e+14  |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -3.77e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.02e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1943813.943803167\n",
      "Sharpe:  0.6555161293701008\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 160       |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 89        |\n",
      "|    total_timesteps      | 14336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.02e+14  |\n",
      "|    n_updates            | 60        |\n",
      "|    policy_gradient_loss | -4.33e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.03e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2053448.1202133724\n",
      "Sharpe:  0.6999714026120233\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 158       |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 103       |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.93e+14  |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -4.11e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.02e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2058771.2767657866\n",
      "Sharpe:  0.7074652868422069\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2056473.571865322\n",
      "Sharpe:  0.7027009202315546\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 156       |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 117       |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.24e+14  |\n",
      "|    n_updates            | 80        |\n",
      "|    policy_gradient_loss | -7.37e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.24e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1897779.6317370613\n",
      "Sharpe:  0.6336489285967272\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 155       |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 132       |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.09e+14  |\n",
      "|    n_updates            | 90        |\n",
      "|    policy_gradient_loss | -4.15e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.96e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2133542.7377938824\n",
      "Sharpe:  0.7360283737987693\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 155       |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 145       |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.5e+14   |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -2.23e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.31e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1961360.180365343\n",
      "Sharpe:  0.6603012010642338\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 156       |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 157       |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.11e+14  |\n",
      "|    n_updates            | 110       |\n",
      "|    policy_gradient_loss | -3.63e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.06e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2055127.9332709957\n",
      "Sharpe:  0.7055974148764099\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 157       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 169       |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.91e+14  |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -4.31e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.62e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2179577.60870962\n",
      "Sharpe:  0.7542755005219824\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 157       |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 181       |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3e+14     |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | -3.19e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.08e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2006731.756214271\n",
      "Sharpe:  0.6773277599562044\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 157       |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 194       |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.16e+14  |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | -5.13e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.35e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2182206.9812959316\n",
      "Sharpe:  0.7488225962092132\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 156       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 209       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.19e+14  |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -3.58e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.24e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2059309.6397124554\n",
      "Sharpe:  0.7034192845026864\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1978833.1675574137\n",
      "Sharpe:  0.6713315761312838\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 153      |\n",
      "|    iterations           | 17       |\n",
      "|    time_elapsed         | 226      |\n",
      "|    total_timesteps      | 34816    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -28.4    |\n",
      "|    explained_variance   | 1.79e-07 |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 3.24e+14 |\n",
      "|    n_updates            | 160      |\n",
      "|    policy_gradient_loss | -3.3e-07 |\n",
      "|    std                  | 1        |\n",
      "|    value_loss           | 6.68e+14 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2067330.2053739452\n",
      "Sharpe:  0.7116767879675858\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 241       |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3e+14     |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | -5.69e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.97e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1909619.2463451037\n",
      "Sharpe:  0.6336012232401425\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 257       |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.9e+14   |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -6.81e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.71e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2001139.8565936838\n",
      "Sharpe:  0.6760907538629156\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 270       |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.78e+14  |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -5.76e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.39e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1942866.2872435208\n",
      "Sharpe:  0.6522602390856083\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 282       |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.82e+14  |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -2.4e-07  |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.72e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2209497.565919309\n",
      "Sharpe:  0.7622006929312657\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 295       |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.85e+14  |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -3.61e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.52e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2000275.6940251223\n",
      "Sharpe:  0.6786986874826455\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 153       |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 307       |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.17e+14  |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | -2.84e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.44e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2039411.4084460044\n",
      "Sharpe:  0.6888510295932491\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 153       |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 320       |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.98e+14  |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -5.12e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.21e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2122867.339958444\n",
      "Sharpe:  0.7293071041072517\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2080158.2329112503\n",
      "Sharpe:  0.7116657481868591\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 153       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 333       |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.2e+14   |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -5.26e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.53e+14  |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88711775",
   "metadata": {},
   "source": [
    "# ddpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f4967069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
    "\n",
    "\n",
    "model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f0891929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/ddpg\\ddpg_6\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2020994.168595884\n",
      "Sharpe:  0.6886100512656552\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045614.1071479346\n",
      "Sharpe:  0.6902808409370745\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045614.1071479346\n",
      "Sharpe:  0.6902808409370745\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045614.1071479346\n",
      "Sharpe:  0.6902808409370745\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 21        |\n",
      "|    time_elapsed    | 343       |\n",
      "|    total_timesteps | 7312      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -3.15e+07 |\n",
      "|    critic_loss     | 1.44e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 5484      |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045614.1071479346\n",
      "Sharpe:  0.6902808409370745\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045614.1071479346\n",
      "Sharpe:  0.6902808409370745\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045614.1071479346\n",
      "Sharpe:  0.6902808409370745\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045614.1071479346\n",
      "Sharpe:  0.6902808409370745\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 18        |\n",
      "|    time_elapsed    | 808       |\n",
      "|    total_timesteps | 14624     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -6.61e+07 |\n",
      "|    critic_loss     | 6.15e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 12796     |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045614.1071479346\n",
      "Sharpe:  0.6902808409370745\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045614.1071479346\n",
      "Sharpe:  0.6902808409370745\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045614.1071479346\n",
      "Sharpe:  0.6902808409370745\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045614.1071479346\n",
      "Sharpe:  0.6902808409370745\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 16        |\n",
      "|    time_elapsed    | 1292      |\n",
      "|    total_timesteps | 21936     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -8.96e+07 |\n",
      "|    critic_loss     | 1.09e+13  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 20108     |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045614.1071479346\n",
      "Sharpe:  0.6902808409370745\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045614.1071479346\n",
      "Sharpe:  0.6902808409370745\n",
      "=================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_ddpg \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_ddpg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mddpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\RL\\DOW_JONES_INTEGRATION\\models.py:117\u001b[0m, in \u001b[0;36mDRLAgent.train_model\u001b[1;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, tb_log_name, total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m):\n\u001b[1;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\ddpg\\ddpg.py:123\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDDPG,\n\u001b[0;32m    116\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDDPG:\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\td3\\td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[0;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:331\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 331\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\td3\\td3.py:188\u001b[0m, in \u001b[0;36mTD3.train\u001b[1;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# Optimize the critics\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 188\u001b[0m \u001b[43mcritic_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Delayed policy updates\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ba6b1",
   "metadata": {},
   "source": [
    "# dqn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c184a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class Model():\n",
    "    '''\n",
    "    Deep Q-learning model (DQN) that uses a neural network to approximate the Q-function.\n",
    "    This is the same as the single_feature_model.py, but this model takes in multiple features.\n",
    "    The number of features is defined by the num_features parameter.\n",
    "    '''\n",
    "    def __init__(self, state_size, num_features, action_space=3, model_name=\"model\"):\n",
    "        self.num_features = num_features\n",
    "        self.state_size = state_size\n",
    "        self.action_space = action_space # Action space of 3 - Buy, Sell and Hold\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "\n",
    "        # Replay memory is a queue of the last 2000 transactions\n",
    "        # This is used to train the model\n",
    "        self.memory = deque(maxlen=2000) \n",
    "        self.inventory = []\n",
    "\n",
    "        self.gamma = 0.95 # Maximize reward over long-term\n",
    "        self.epsilon = 1.0 # 1.0 means model will explore the environment randomly during training\n",
    "        self.epsilon_final = 0.01 # Decrease epsilon over time to take less random actions\n",
    "        self.epsilon_decay = 0.995 # Decay rate of epsilon\n",
    "\n",
    "    def model_builder(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\", input_shape=(None, self.state_size, self.num_features)))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dense(self.action_space, activation=\"linear\")) # We use linear activation cuz it's a regression task w/ no set range\n",
    "        model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5))\n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def trade(self, state, is_eval=False):\n",
    "        '''\n",
    "        The model generates a random floating point number between 0 and 1. \n",
    "        If the number is less than epsilon, the model will explore the environment randomly.\n",
    "        If the number is greater than epsilon, the model will exploit the environment by choosing the best action.\n",
    "        '''\n",
    "        if random.random() <= self.epsilon and not is_eval:\n",
    "            return random.randrange(self.action_space)\n",
    "        state = state.reshape(-1, 1, self.state_size, self.num_features) # Reshape the state to have shape (batch_size, state_size, num_features)\n",
    "        # state = np.expand_dims(state, axis=0) # Add a dimension to the state to have shape (batch_size, 1, state_size, num_features)\n",
    "        actions = self.model.predict(state, verbose=0)\n",
    "        return np.argmax(actions, axis=-1)[0][0][0] # For some reason, the model outputs a 3D array, so we need to squeeze it to get the action\n",
    "    \n",
    "    def batch_train(self, batch_size):\n",
    "        batch = random.sample(self.memory, batch_size) # (state, action, reward, next_state, done)\n",
    "        states = np.array([transition[0] for transition in batch])\n",
    "        actions = np.array([transition[1] for transition in batch])\n",
    "        rewards = np.array([transition[2] for transition in batch])\n",
    "        next_states = np.array([transition[3] for transition in batch])\n",
    "        dones = np.array([transition[4] for transition in batch])\n",
    "\n",
    "        targets = self.model.predict(states, verbose=0)\n",
    "        targets_next = self.model.predict(next_states, verbose=0)\n",
    "\n",
    "        # print(states.shape, actions.shape, rewards.shape, next_states.shape, dones.shape, targets.shape, targets_next.shape)\n",
    "        # (32, 1, 10, 6) (32,) (32,) (32, 1, 10, 6) (32,) (32, 1, 10, 3) (32, 1, 10, 3) -> Shapes of the arrays for multi_feature model\n",
    "        # (32, 1, 10)    (32,) (32,) (32, 1, 10)    (32,) (32, 3)        (32, 1, 3) -> Shapes of the arrays for single_feature model\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            if dones[i]:\n",
    "                # Add reward to the last dimension\n",
    "                targets[i, :, :, actions[i]] = rewards[i]\n",
    "            else:\n",
    "                targets[i, :, :, actions[i]] = rewards[i] + self.gamma * np.amax(targets_next[i], axis=-1)\n",
    "        \n",
    "        self.model.fit(states, targets, epochs=1, verbose=0)\n",
    "\n",
    "        if self.epsilon > self.epsilon_final:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ad74c117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: data-extractor in c:\\users\\sanjana\\anaconda3\\lib\\site-packages (0.10.2)\n",
      "Requirement already satisfied: typing-extensions==3.7.4.3 in c:\\users\\sanjana\\anaconda3\\lib\\site-packages (from data-extractor) (3.7.4.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install data-extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "0311b807",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'label_buy_sell_hold' from 'data_extractor' (C:\\Users\\SANJANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\data_extractor\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[281], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m expit\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_extractor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m label_buy_sell_hold\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmulti_feature_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m     11\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_CPP_MIN_LOG_LEVEL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'label_buy_sell_hold' from 'data_extractor' (C:\\Users\\SANJANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\data_extractor\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from datetime import *\n",
    "from scipy.special import expit\n",
    "from tqdm import tqdm\n",
    "from data_extractor import label_buy_sell_hold\n",
    "from multi_feature_model import Model\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "def format_price(n):\n",
    "    '''\n",
    "    Formats a number into a string with 2 decimal places.\n",
    "    '''\n",
    "    # Convert n from numpy array to float\n",
    "    n = float(n)\n",
    "    \n",
    "    if n < 0:\n",
    "        return \"-${0:2f}\".format(abs(n))\n",
    "    else:\n",
    "        return \"${0:2f}\".format(abs(n))\n",
    "\n",
    "\n",
    "def state_creator(data, timestep, window_size):\n",
    "    '''\n",
    "    Changes input data to be differences in stock prices,\n",
    "    which represent price changes over time. \n",
    "    This will allow model to predict buy/sell/hold rather than the price itself.\n",
    "    '''\n",
    "    starting_id = timestep - window_size + 1\n",
    "    if starting_id >= 0:\n",
    "        windowed_data = data[starting_id:timestep + 1]\n",
    "    else:\n",
    "        windowed_data = -starting_id * [data[0]] + list(data[0: timestep + 1])\n",
    "    \n",
    "    state = []\n",
    "    for i in range(window_size - 1):\n",
    "        # expit is logistic sigmoid function, and avoids overflow errors associated w/ large diffs in stock price\n",
    "        # https://i.stack.imgur.com/WY61Z.png\n",
    "        state.append(expit(windowed_data[i + 1] - windowed_data[i]))\n",
    "    return np.array([state])\n",
    "\n",
    "\n",
    "def train_model(data, model, window_size, episodes, batch_size=32, name=\"model_multifeature\"):\n",
    "    for episode in range(1, episodes + 1): # For printing purposes\n",
    "        print(\"Episode: {}/{}\".format(episode, episodes))\n",
    "        state = state_creator(data, 0, window_size + 1)\n",
    "        total_profit = 0\n",
    "        model.inventory = []\n",
    "\n",
    "        for t in tqdm(range(len(data))):\n",
    "            # print(\"Timestep: {}/{}\".format(t, len(data)))\n",
    "            action = model.trade(state)\n",
    "            \n",
    "            # If action is not a scalar, then take the element within all the embedded arrays\n",
    "            # I don't know why it does this, someone feel free to fix it\n",
    "            if not np.isscalar(action):\n",
    "                print(action)\n",
    "                # action = action[0][0][0]\n",
    "\n",
    "            if t == len(data) - 1:\n",
    "                # When the episode is done, we don't have a next state, so we set it to the last state\n",
    "                next_state = state\n",
    "            else:            \n",
    "                next_state = state_creator(data, t + 1, window_size + 1)\n",
    "            reward = 0\n",
    "\n",
    "            # Buy stock\n",
    "            if action == 1:\n",
    "                model.inventory.append(data[t][0]) # Append the closing price\n",
    "                # print(\"Buy: {}\".format(format_price(data[t][0])))\n",
    "\n",
    "            # Sell stock\n",
    "            elif action == 2 and len(model.inventory) > 0:\n",
    "                bought_price = model.inventory.pop(0) # This will be a scalar\n",
    "                reward = max(data[t][0] - bought_price, 0)\n",
    "                total_profit += data[t][0] - bought_price\n",
    "                # print(\"Sell: {} | Profit: {}\".format(format_price(data[t][0]), format_price(data[t][0] - bought_price)))\n",
    "\n",
    "            # Hold stock\n",
    "            elif action == 0:\n",
    "                # print(\"Hold: {}\".format(format_price(data[t][0])))\n",
    "                pass\n",
    "            \n",
    "            # If the episode is done, we fit the model to the target\n",
    "            done = True if t == len(data) - 1 else False    \n",
    "            model.memory.append((state, action, reward, next_state, done))\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                print(\"--------------------------------\")\n",
    "                print(\"Total Profit: {}\".format(format_price(total_profit)))\n",
    "                print(\"--------------------------------\")\n",
    "            \n",
    "            if len(model.memory) > batch_size:\n",
    "                model.batch_train(batch_size)\n",
    "        \n",
    "        print(\"Total Profit: {}\".format(format_price(total_profit)))\n",
    "        print(\"Saving model...\")\n",
    "        model.model.save(f\"models/{name}.h5\")\n",
    "\n",
    "\n",
    "def train_multistock(stocks, start_date, end_date, window_size, episodes, batch_size=32, name=\"model_multifeature\"):\n",
    "    '''\n",
    "    Given a list of stocks, fit the model to all the stocks.  \n",
    "    '''\n",
    "    trader = None\n",
    "    for stock in stocks:\n",
    "        print(f\"Loading data for {stock}...\")\n",
    "        data = dataloader(stock, 'data/', start_date, end_date)\n",
    "\n",
    "        # Get closing price, MACD, RSI, CCI, ADX\n",
    "        data = data[[\"close\", \"f01\", \"f02\", \"f03\", \"f04\"]].values\n",
    "        # data = data[[\"Close\"]].values\n",
    "\n",
    "        # Generate and append the buy/sell/hold signal to the data\n",
    "        labels = np.array(label_buy_sell_hold(data))\n",
    "\n",
    "        # Convert labels to 2D array of size (len(labels), 1)\n",
    "        labels = labels.reshape(len(labels), 1)\n",
    "        data = np.append(data, labels, axis=1)\n",
    "\n",
    "        # Get the epsCurrentYear, epsForward, forwardPE, fiftyDayAverage, marketCap\n",
    "        # df = web.get_quote_yahoo(stock)\n",
    "        # df = df[[\"epsCurrentYear\", \"epsForward\", \"forwardPE\", \"fiftyDayAverage\", \"marketCap\"]]\n",
    "\n",
    "        # Extend df to match the length of data\n",
    "        # df = pd.concat([df] * len(data), ignore_index=True)\n",
    "        \n",
    "        # Append the epsCurrentYear, epsForward, forwardPE, fiftyDayAverage, marketCap to data\n",
    "        # data = np.append(data, df, axis=1)\n",
    "\n",
    "        # Create the model only once during the first iteration of the loop\n",
    "        if not trader:\n",
    "            print(\"Model created.\")\n",
    "            trader = Model(window_size, num_features=data.shape[1])\n",
    "            trader.model = trader.model_builder()\n",
    "            # trader.model.summary()\n",
    "        \n",
    "        print(f\"Training model for {stock}...\")\n",
    "        train_model(data, trader, window_size, episodes, batch_size, name)\n",
    "\n",
    "\n",
    "def test_model(data, model, window_size, stock, start_date, end_date):\n",
    "    '''\n",
    "    Test the trained model by having it trade for a set test period.    \n",
    "    For this, we don't use the memory, and we don't need the reward.\n",
    "    '''\n",
    "    state = state_creator(data, 0, window_size + 1)\n",
    "    total_profit = 0\n",
    "    model.inventory = []\n",
    "    profits = []\n",
    "\n",
    "    for t in range(len(data)):\n",
    "        print(\"Timestep: {}/{}\".format(t, len(data)))\n",
    "        action = model.trade(state, is_eval=True)\n",
    "        print(\"Action: {}\".format(action))\n",
    "        if t == len(data) - 1:\n",
    "            # When the episode is done, we don't have a next state, so we set it to the last state\n",
    "            next_state = state\n",
    "        else:            \n",
    "            next_state = state_creator(data, t + 1, window_size + 1)\n",
    "\n",
    "        # Buy stock\n",
    "        if action == 1:\n",
    "            model.inventory.append(data[t])\n",
    "            print(\"Buy: {}\".format(format_price(data[t])))\n",
    "\n",
    "        # Sell stock\n",
    "        elif action == 2 and len(model.inventory) > 0:\n",
    "            bought_price = model.inventory.pop(0) \n",
    "            total_profit += data[t] - bought_price\n",
    "            print(\"Sell: {} | Profit: {}\".format(format_price(data[t]), format_price(data[t] - bought_price)))\n",
    "\n",
    "        # Hold stock\n",
    "        elif action == 0:\n",
    "            print(\"Hold: {}\".format(format_price(data[t])))\n",
    "            pass\n",
    "        state = next_state\n",
    "\n",
    "        # Save the profit for each timestep\n",
    "        profits.append(total_profit)\n",
    "    print(profits)\n",
    "    print(\"Overall Profit Over Testing Period: {}\".format(format_price(total_profit)))\n",
    "\n",
    "    # Use matplotlib to plot the profit over time\n",
    "    plt.plot(profits)\n",
    "    plt.xlabel('Time (Days)')\n",
    "    plt.ylabel('Profit (USD)')\n",
    "    plt.title(f'Profit Over Time for {stock} From {start_date} to {end_date}')\n",
    "    plt.legend([f'{stock}'])\n",
    "    if not os.path.exists('plots'):\n",
    "        os.makedirs('plots')\n",
    "    plt.savefig(f'plots/{stock.lower()}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters  \n",
    "    window_size = 10\n",
    "    episodes = 2\n",
    "    batch_size = 32\n",
    "    stock = 'V'\n",
    "    stocks = [selected_stocks]\n",
    "    start_date = '2022-01-01'\n",
    "    end_date = '2023-01-01'\n",
    "    name = \"S&P500\"\n",
    "    \n",
    "    train_multistock(stocks, start_date, end_date, window_size, episodes, batch_size, name)\n",
    "\n",
    "    ### Testing the model ###\n",
    "    test_start = '2023-01-02'\n",
    "    test_end = '2023-03-02'\n",
    "\n",
    "    # Get the stock closing price and technical indicators for the past week\n",
    "    test_data = prices_full_test_df\n",
    "    test_data = test_data[[\"close\", \"f01\", \"f02\", \"f03\", \"f04\"]].values\n",
    "    # test_data = test_data[[\"Close\"]].values\n",
    "    \n",
    "    # test_df = web.get_quote_yahoo(stock)\n",
    "    # test_df = test_df[[\"epsCurrentYear\", \"epsForward\", \"forwardPE\", \"fiftyDayAverage\", \"marketCap\"]]\n",
    "    # test_df = pd.concat([test_df] * len(test_data), ignore_index=True)\n",
    "    # test_data = np.append(test_data, test_df, axis=1)\n",
    "\n",
    "    # This is a placeholder signal, it will be replaced by the output of the sentiment analysis model\n",
    "    signal = \"buy\" # Change this to get output from sentiment analysis model\n",
    "    if signal == \"buy\":\n",
    "        # Create an array of 1s the same length as test_data\n",
    "        signal = np.ones((len(test_data), 1))\n",
    "    elif signal == \"sell\":\n",
    "        # Create an array of 2s the same length as test_data\n",
    "        signal = 2 * np.ones((len(test_data), 1))\n",
    "    elif signal == \"hold\":\n",
    "        # Create an array of 0s the same length as test_data\n",
    "        signal = np.zeros((len(test_data), 1))\n",
    "    test_data = np.append(test_data, signal, axis=1)\n",
    "\n",
    "    # Load the model\n",
    "    trader = Model(window_size, num_features=test_data.shape[1])\n",
    "    trader.model = trader.model_builder()\n",
    "    trader.model.load_weights(f\"models/{name}.h5\")\n",
    "\n",
    "    # Test the model\n",
    "    test_model(test_data, trader, window_size, stock, test_start, test_end)\n",
    "    quit()\n",
    "\n",
    "    # Use the model to predict the stock price for tomorrow\n",
    "    state = state_creator(test_data, 0, window_size + 1)\n",
    "    action = trader.trade(state)\n",
    "\n",
    "    actions = {\n",
    "        0: \"Hold\",\n",
    "        1: \"Buy\",\n",
    "        2: \"Sell\"\n",
    "    }\n",
    "    print(\"Action for {} on {}: {}\".format(stock, today, actions[action]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9161c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe31e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48095c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2C Train Model\n",
    "e_trade_gym = StockPortfolioEnv(df = train_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "a2c_train_daily_return, a2c_train_weights = DRLAgent.DRL_prediction(model=trained_a2c,\n",
    "                        test_data = train_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391a092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO Train Model\n",
    "e_trade_gym = StockPortfolioEnv(df = train_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "ppo_train_daily_return, ppo_train_weights = DRLAgent.DRL_prediction(model=trained_ppo,\n",
    "                        test_data = train_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDPG Train Model\n",
    "e_trade_gym = StockPortfolioEnv(df = train_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "ddpg_train_daily_return, ddpg_train_weights = DRLAgent.DRL_prediction(model=trained_ddpg,\n",
    "                        test_data = train_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ef61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the Training Models\n",
    "%store a2c_train_daily_return\n",
    "%store ppo_train_daily_return\n",
    "%store ddpg_train_daily_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7f0c0cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>260.00000</td>\n",
       "      <td>268.109985</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>266.369995</td>\n",
       "      <td>2972000</td>\n",
       "      <td>ACN</td>\n",
       "      <td>[[0.0006146582747316243, 0.0005151199896327714...</td>\n",
       "      <td>2.709271</td>\n",
       "      <td>0.510346</td>\n",
       "      <td>4.35304</td>\n",
       "      <td>1.816536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>732.47998</td>\n",
       "      <td>733.690002</td>\n",
       "      <td>719.330017</td>\n",
       "      <td>722.119995</td>\n",
       "      <td>751600</td>\n",
       "      <td>BLK</td>\n",
       "      <td>[[0.0006146582747316243, 0.0005151199896327714...</td>\n",
       "      <td>2.709271</td>\n",
       "      <td>0.510346</td>\n",
       "      <td>4.35304</td>\n",
       "      <td>1.816536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>75.57000</td>\n",
       "      <td>75.860001</td>\n",
       "      <td>75.110001</td>\n",
       "      <td>75.269997</td>\n",
       "      <td>4842600</td>\n",
       "      <td>CL</td>\n",
       "      <td>[[0.0006146582747316243, 0.0005151199896327714...</td>\n",
       "      <td>2.709271</td>\n",
       "      <td>0.510346</td>\n",
       "      <td>4.35304</td>\n",
       "      <td>1.816536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       Open        High         Low       Close   Volume  tic  \\\n",
       "0  2021-03-11  260.00000  268.109985  260.000000  266.369995  2972000  ACN   \n",
       "0  2021-03-11  732.47998  733.690002  719.330017  722.119995   751600  BLK   \n",
       "0  2021-03-11   75.57000   75.860001   75.110001   75.269997  4842600   CL   \n",
       "\n",
       "                                            cov_list       f01       f02  \\\n",
       "0  [[0.0006146582747316243, 0.0005151199896327714...  2.709271  0.510346   \n",
       "0  [[0.0006146582747316243, 0.0005151199896327714...  2.709271  0.510346   \n",
       "0  [[0.0006146582747316243, 0.0005151199896327714...  2.709271  0.510346   \n",
       "\n",
       "       f03       f04  \n",
       "0  4.35304  1.816536  \n",
       "0  4.35304  1.816536  \n",
       "0  4.35304  1.816536  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d3f299a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.rename(columns={'Close': 'close'})\n",
    "test_df = test_df.rename(columns={'Open': 'open'})\n",
    "test_df = test_df.rename(columns={'High': 'high'})\n",
    "tes_df = test_df.rename(columns={'Low': 'low'})\n",
    "test_df = test_df.rename(columns={'Volume': 'volume'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "48b71660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SANJANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1105387.3921986395\n",
      "Sharpe:  0.4421526974013133\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "# A2C Test Model\n",
    "e_trade_gym = StockPortfolioEnv(df = test_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "a2c_test_daily_return, a2c_test_weights = DRLAgent.DRL_prediction(model=trained_a2c,\n",
    "                        test_data = test_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "837e780c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-12</td>\n",
       "      <td>0.005388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>0.008031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>-0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>0.002721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  daily_return\n",
       "0  2021-03-11      0.000000\n",
       "1  2021-03-12      0.005388\n",
       "2  2021-03-15      0.008031\n",
       "3  2021-03-16     -0.000479\n",
       "4  2021-03-17      0.002721"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_test_daily_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "21908816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SANJANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1105429.375909273\n",
      "Sharpe:  0.4379122662760246\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "# PPO Test Model\n",
    "e_trade_gym = StockPortfolioEnv(df = test_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "ppo_test_daily_return, ppo_test_weights = DRLAgent.DRL_prediction(model=trained_ppo,\n",
    "                        test_data = test_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bd1be582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SANJANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1042931.4850153038\n",
      "Sharpe:  0.22512915148709947\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "# DDPG Test Model\n",
    "e_trade_gym = StockPortfolioEnv(df = test_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "ddpg_test_daily_return, ddpg_test_weights = DRLAgent.DRL_prediction(model=trained_ddpg,\n",
    "                        test_data = test_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6f2c42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_test_portfolio = a2c_test_daily_return.copy()\n",
    "a2c_test_returns = a2c_test_daily_return.copy()\n",
    "\n",
    "ppo_test_portfolio = ppo_test_daily_return.copy()\n",
    "ppo_test_returns = ppo_test_daily_return.copy()\n",
    "\n",
    "ddpg_test_portfolio = ddpg_test_daily_return.copy()\n",
    "ddpg_test_returns = ddpg_test_daily_return.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3e6ae375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'a2c_test_portfolio' (DataFrame)\n",
      "Stored 'a2c_test_returns' (DataFrame)\n",
      "Stored 'ppo_test_portfolio' (DataFrame)\n",
      "Stored 'ppo_test_returns' (DataFrame)\n",
      "Stored 'ddpg_test_portfolio' (DataFrame)\n",
      "Stored 'ddpg_test_returns' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store a2c_test_portfolio\n",
    "%store a2c_test_returns \n",
    "\n",
    "%store ppo_test_portfolio\n",
    "%store ppo_test_returns \n",
    "\n",
    "%store ddpg_test_portfolio\n",
    "%store ddpg_test_returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8ba5e217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias max_sharpe_portfolio\n",
      "no stored variable or alias uniform_weights_port\n",
      "no stored variable or alias prices_train_df\n",
      "no stored variable or alias prices_test_df\n"
     ]
    }
   ],
   "source": [
    "%store -r max_sharpe_portfolio\n",
    "%store -r uniform_weights_port\n",
    "\n",
    "%store -r prices_train_df\n",
    "%store -r prices_test_df\n",
    "\n",
    "\n",
    "%store -r a2c_train_daily_return\n",
    "%store -r ppo_train_daily_return\n",
    "%store -r ddpg_train_daily_return\n",
    "\n",
    "%store -r a2c_test_returns \n",
    "%store -r ppo_test_returns \n",
    "%store -r ddpg_test_returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5456ae56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PEP</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>KO</th>\n",
       "      <th>HON</th>\n",
       "      <th>CL</th>\n",
       "      <th>LIN</th>\n",
       "      <th>MCD</th>\n",
       "      <th>VZ</th>\n",
       "      <th>BLK</th>\n",
       "      <th>MDLZ</th>\n",
       "      <th>PG</th>\n",
       "      <th>JPM</th>\n",
       "      <th>ACN</th>\n",
       "      <th>MMM</th>\n",
       "      <th>MDT</th>\n",
       "      <th>T</th>\n",
       "      <th>LMT</th>\n",
       "      <th>GD</th>\n",
       "      <th>COST</th>\n",
       "      <th>HD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-11</th>\n",
       "      <td>133.220001</td>\n",
       "      <td>159.139999</td>\n",
       "      <td>50.880001</td>\n",
       "      <td>212.500000</td>\n",
       "      <td>75.269997</td>\n",
       "      <td>267.369995</td>\n",
       "      <td>211.570007</td>\n",
       "      <td>55.509998</td>\n",
       "      <td>722.119995</td>\n",
       "      <td>56.270000</td>\n",
       "      <td>126.910004</td>\n",
       "      <td>154.320007</td>\n",
       "      <td>266.369995</td>\n",
       "      <td>184.570007</td>\n",
       "      <td>118.099998</td>\n",
       "      <td>22.311178</td>\n",
       "      <td>339.730011</td>\n",
       "      <td>172.669998</td>\n",
       "      <td>328.649994</td>\n",
       "      <td>268.850006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-12</th>\n",
       "      <td>133.039993</td>\n",
       "      <td>159.600006</td>\n",
       "      <td>50.360001</td>\n",
       "      <td>214.380005</td>\n",
       "      <td>75.510002</td>\n",
       "      <td>268.500000</td>\n",
       "      <td>212.339996</td>\n",
       "      <td>55.630001</td>\n",
       "      <td>716.190002</td>\n",
       "      <td>56.869999</td>\n",
       "      <td>128.139999</td>\n",
       "      <td>156.149994</td>\n",
       "      <td>264.950012</td>\n",
       "      <td>184.919998</td>\n",
       "      <td>118.809998</td>\n",
       "      <td>22.515106</td>\n",
       "      <td>340.190002</td>\n",
       "      <td>176.289993</td>\n",
       "      <td>331.140015</td>\n",
       "      <td>273.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-15</th>\n",
       "      <td>133.029999</td>\n",
       "      <td>160.419998</td>\n",
       "      <td>51.029999</td>\n",
       "      <td>216.199997</td>\n",
       "      <td>75.680000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>220.460007</td>\n",
       "      <td>55.639999</td>\n",
       "      <td>719.010010</td>\n",
       "      <td>57.230000</td>\n",
       "      <td>128.559998</td>\n",
       "      <td>155.369995</td>\n",
       "      <td>266.260010</td>\n",
       "      <td>189.479996</td>\n",
       "      <td>119.150002</td>\n",
       "      <td>22.605740</td>\n",
       "      <td>346.410004</td>\n",
       "      <td>176.710007</td>\n",
       "      <td>330.510010</td>\n",
       "      <td>278.540009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-16</th>\n",
       "      <td>134.009995</td>\n",
       "      <td>161.369995</td>\n",
       "      <td>51.220001</td>\n",
       "      <td>211.809998</td>\n",
       "      <td>75.860001</td>\n",
       "      <td>270.790009</td>\n",
       "      <td>219.860001</td>\n",
       "      <td>55.639999</td>\n",
       "      <td>723.070007</td>\n",
       "      <td>57.779999</td>\n",
       "      <td>128.940002</td>\n",
       "      <td>153.509995</td>\n",
       "      <td>263.519989</td>\n",
       "      <td>186.850006</td>\n",
       "      <td>118.940002</td>\n",
       "      <td>22.651056</td>\n",
       "      <td>347.130005</td>\n",
       "      <td>175.320007</td>\n",
       "      <td>327.250000</td>\n",
       "      <td>282.079987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-17</th>\n",
       "      <td>133.619995</td>\n",
       "      <td>160.770004</td>\n",
       "      <td>51.240002</td>\n",
       "      <td>213.029999</td>\n",
       "      <td>75.800003</td>\n",
       "      <td>269.549988</td>\n",
       "      <td>224.110001</td>\n",
       "      <td>55.750000</td>\n",
       "      <td>728.219971</td>\n",
       "      <td>57.919998</td>\n",
       "      <td>128.419998</td>\n",
       "      <td>155.089996</td>\n",
       "      <td>264.269989</td>\n",
       "      <td>188.300003</td>\n",
       "      <td>118.559998</td>\n",
       "      <td>22.771902</td>\n",
       "      <td>351.019989</td>\n",
       "      <td>177.520004</td>\n",
       "      <td>329.190002</td>\n",
       "      <td>280.029999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   PEP         JNJ         KO         HON         CL  \\\n",
       "date                                                                   \n",
       "2021-03-11  133.220001  159.139999  50.880001  212.500000  75.269997   \n",
       "2021-03-12  133.039993  159.600006  50.360001  214.380005  75.510002   \n",
       "2021-03-15  133.029999  160.419998  51.029999  216.199997  75.680000   \n",
       "2021-03-16  134.009995  161.369995  51.220001  211.809998  75.860001   \n",
       "2021-03-17  133.619995  160.770004  51.240002  213.029999  75.800003   \n",
       "\n",
       "                   LIN         MCD         VZ         BLK       MDLZ  \\\n",
       "date                                                                   \n",
       "2021-03-11  267.369995  211.570007  55.509998  722.119995  56.270000   \n",
       "2021-03-12  268.500000  212.339996  55.630001  716.190002  56.869999   \n",
       "2021-03-15  269.000000  220.460007  55.639999  719.010010  57.230000   \n",
       "2021-03-16  270.790009  219.860001  55.639999  723.070007  57.779999   \n",
       "2021-03-17  269.549988  224.110001  55.750000  728.219971  57.919998   \n",
       "\n",
       "                    PG         JPM         ACN         MMM         MDT  \\\n",
       "date                                                                     \n",
       "2021-03-11  126.910004  154.320007  266.369995  184.570007  118.099998   \n",
       "2021-03-12  128.139999  156.149994  264.950012  184.919998  118.809998   \n",
       "2021-03-15  128.559998  155.369995  266.260010  189.479996  119.150002   \n",
       "2021-03-16  128.940002  153.509995  263.519989  186.850006  118.940002   \n",
       "2021-03-17  128.419998  155.089996  264.269989  188.300003  118.559998   \n",
       "\n",
       "                    T         LMT          GD        COST          HD  \n",
       "date                                                                   \n",
       "2021-03-11  22.311178  339.730011  172.669998  328.649994  268.850006  \n",
       "2021-03-12  22.515106  340.190002  176.289993  331.140015  273.100006  \n",
       "2021-03-15  22.605740  346.410004  176.710007  330.510010  278.540009  \n",
       "2021-03-16  22.651056  347.130005  175.320007  327.250000  282.079987  \n",
       "2021-03-17  22.771902  351.019989  177.520004  329.190002  280.029999  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_full_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d8dab468",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_full_test_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "34ad5e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_train = df.pct_change() # get the assets daily returns\n",
    "returns_test = prices_full_test_df.pct_change()\n",
    "\n",
    "# get the culmulative returns for each portfolio\n",
    "uw_weights = uniform_weights_port.values.flatten()\n",
    "uw_returns = returns_train.dot(uw_weights)\n",
    "uw_cum_returns = (1 + uw_returns).cumprod()\n",
    "uw_cum_returns.name = \"portfolio 1: uniform weights\"\n",
    "\n",
    "max_sharpe_weights = max_sharpe_portfolio.values.flatten()\n",
    "max_sharpe_returns = returns_train.dot(max_sharpe_weights)\n",
    "max_sharpe_cum_returns = (1 + max_sharpe_returns).cumprod()\n",
    "max_sharpe_cum_returns.name = \"portfolio 2: max sharpe\"\n",
    "\n",
    "a2c_train_cum_returns = (1 + a2c_train_daily_return.reset_index(drop=True).set_index(['date'])).cumprod()\n",
    "a2c_train_cum_returns = a2c_train_cum_returns['daily_return']\n",
    "a2c_train_cum_returns.name = 'Portfolio 3: a2c Model'\n",
    "\n",
    "ppo_train_cum_returns = (1 + ppo_train_daily_return.reset_index(drop=True).set_index(['date'])).cumprod()\n",
    "ppo_train_cum_returns = ppo_train_cum_returns['daily_return']\n",
    "ppo_train_cum_returns.name = 'Portfolio 4: ppo Model'\n",
    "\n",
    "ddpg_train_cum_returns = (1 + ddpg_train_daily_return.reset_index(drop=True).set_index(['date'])).cumprod()\n",
    "ddpg_train_cum_returns = ddpg_train_cum_returns['daily_return']\n",
    "ddpg_train_cum_returns.name = 'Portfolio 5: ddpg Model'\n",
    "\n",
    "date_list = list(ddpg_train_cum_returns.index)\n",
    "\n",
    "max_sharpe_cum_returns = max_sharpe_cum_returns[(max_sharpe_cum_returns.index).isin (date_list)]\n",
    "uw_cum_returns = uw_cum_returns[(uw_cum_returns.index).isin (date_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5843fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the culmulative returns of the portfolios\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "uw_cum_returns.plot(ax=ax, color=\"black\", alpha=0.4);\n",
    "max_sharpe_cum_returns.plot(ax=ax, color=\"darkorange\", alpha=0.4);\n",
    "\n",
    "a2c_train_cum_returns.plot(ax=ax, color='blue', alpha=0.4)\n",
    "ppo_train_cum_returns.plot(ax=ax, color='green', alpha=0.4)\n",
    "ddpg_train_cum_returns.plot(ax=ax, color='purple', alpha=0.4)\n",
    "\n",
    "plt.legend(loc=\"best\");\n",
    "plt.grid(True);\n",
    "ax.set_ylabel(\"cummulative return\");\n",
    "ax.set_title(\"Backtest based on the train data\", fontsize=14);\n",
    "fig.savefig('results/back_test_on_train_data.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "10175123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the culmulative returns for each portfolio\n",
    "uw_weights = uniform_weights_port.values.flatten()\n",
    "uw_test_returns = returns_test.dot(uw_weights)\n",
    "uw_test_cum_returns = (1 + uw_test_returns).cumprod()\n",
    "uw_test_cum_returns.name = \"portfolio 1: uniform weights\"\n",
    "\n",
    "max_sharpe_weights = max_sharpe_portfolio.values.flatten()\n",
    "max_sharpe_test_returns = returns_test.dot(max_sharpe_weights)\n",
    "max_sharpe_test_cum_returns = (1 + max_sharpe_test_returns).cumprod()\n",
    "max_sharpe_test_cum_returns.name = \"portfolio 2: max sharpe\"\n",
    "\n",
    "a2c_test_cum_returns = (1 + a2c_test_returns['daily_return']).cumprod()\n",
    "a2c_test_cum_returns.name = 'Portfolio 3: a2c Model'\n",
    "\n",
    "ppo_test_cum_returns = (1 + ppo_test_returns['daily_return']).cumprod()\n",
    "ppo_test_cum_returns.name = 'Portfolio 4: ppo Model'\n",
    "\n",
    "ddpg_test_cum_returns = (1 + ddpg_test_returns['daily_return']).cumprod()\n",
    "ddpg_test_cum_returns.name = 'Portfolio 5: ddpg Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f21e26a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the culmulative returns of the portfolios\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "uw_test_cum_returns.plot(ax=ax, color=\"black\", alpha=.4);\n",
    "max_sharpe_test_cum_returns.plot(ax=ax, color=\"darkorange\");\n",
    "a2c_test_cum_returns.plot(ax=ax, color='blue', alpha=.4)\n",
    "ppo_test_cum_returns.plot(ax=ax, color='green', alpha=.4)\n",
    "ddpg_test_cum_returns.plot(ax=ax, color='purple', alpha=.4)\n",
    "plt.legend(loc=\"best\");\n",
    "plt.grid(True);\n",
    "ax.set_ylabel(\"cummulative return\");\n",
    "ax.set_title(\"Backtest based on the test data\", fontsize=14);\n",
    "fig.savefig('results/back_test_on_test_data.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df761090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "59e6e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Function for Getting the Portfolio Statistics\n",
    "\n",
    "def portfolio_stats(portfolio_returns):\n",
    "    # Pass the returns into a dataframe\n",
    "    port_rets_df = pd.DataFrame(portfolio_returns)\n",
    "    port_rets_df = port_rets_df.reset_index()\n",
    "    port_rets_df.columns = ['date','daily_return']\n",
    "    \n",
    "    #Use the FinRL Library to get the Portfolio Returns\n",
    "    #This makes use of the Pyfolio Library\n",
    "    \n",
    "    DRL_strat = backtest_strat(port_rets_df)\n",
    "    perf_func = timeseries.perf_stats \n",
    "    perf_stats_all = perf_func( returns=DRL_strat, \n",
    "                                  factor_returns=DRL_strat, \n",
    "                                    positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "    perf_stats_all = pd.DataFrame( perf_stats_all)\n",
    "    perf_stats_all.columns = ['Statistic']\n",
    "    return perf_stats_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d7a3d14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uw_test_returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4cf3417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfolio.timeseries as timeseries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "661a5138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Portfolio Statistics for all the portfolios\n",
    "portfolios_returns_dict = {'uniform_weights':uw_test_returns, 'maximum_sharpe':max_sharpe_test_returns,\n",
    "                          'a2c Model': a2c_test_returns['daily_return'],\n",
    "                          'ppo Model': ppo_test_returns['daily_return'],\n",
    "                          'ddpg Model': ddpg_test_returns['daily_return']}\n",
    "\n",
    "portfolios_stats = pd.DataFrame()\n",
    "for i,j in portfolios_returns_dict.items():\n",
    "    port_stats = portfolio_stats(j)\n",
    "    portfolios_stats[i] = port_stats['Statistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "24ff5dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniform_weights</th>\n",
       "      <th>maximum_sharpe</th>\n",
       "      <th>a2c Model</th>\n",
       "      <th>ppo Model</th>\n",
       "      <th>ddpg Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>0.045677</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.056933</td>\n",
       "      <td>0.056955</td>\n",
       "      <td>0.023502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>0.084370</td>\n",
       "      <td>0.140912</td>\n",
       "      <td>0.105387</td>\n",
       "      <td>0.105429</td>\n",
       "      <td>0.042931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>0.151151</td>\n",
       "      <td>0.174430</td>\n",
       "      <td>0.150980</td>\n",
       "      <td>0.153287</td>\n",
       "      <td>0.159810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>0.371629</td>\n",
       "      <td>0.504774</td>\n",
       "      <td>0.442153</td>\n",
       "      <td>0.437912</td>\n",
       "      <td>0.225129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>0.227410</td>\n",
       "      <td>0.333959</td>\n",
       "      <td>0.298044</td>\n",
       "      <td>0.286929</td>\n",
       "      <td>0.104644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.105855</td>\n",
       "      <td>0.011224</td>\n",
       "      <td>0.077677</td>\n",
       "      <td>0.072713</td>\n",
       "      <td>0.313110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-0.200859</td>\n",
       "      <td>-0.225777</td>\n",
       "      <td>-0.191022</td>\n",
       "      <td>-0.198499</td>\n",
       "      <td>-0.224591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.065225</td>\n",
       "      <td>1.088724</td>\n",
       "      <td>1.077565</td>\n",
       "      <td>1.077621</td>\n",
       "      <td>1.039168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>0.528910</td>\n",
       "      <td>0.727045</td>\n",
       "      <td>0.631005</td>\n",
       "      <td>0.626504</td>\n",
       "      <td>0.319246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.099735</td>\n",
       "      <td>-0.076031</td>\n",
       "      <td>-0.047889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.801319</td>\n",
       "      <td>2.157376</td>\n",
       "      <td>1.805006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>0.929052</td>\n",
       "      <td>1.040514</td>\n",
       "      <td>0.970390</td>\n",
       "      <td>0.946697</td>\n",
       "      <td>0.953489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-0.018820</td>\n",
       "      <td>-0.021627</td>\n",
       "      <td>-0.018757</td>\n",
       "      <td>-0.019046</td>\n",
       "      <td>-0.019991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     uniform_weights  maximum_sharpe  a2c Model  ppo Model  \\\n",
       "Annual return               0.045677        0.075400   0.056933   0.056955   \n",
       "Cumulative returns          0.084370        0.140912   0.105387   0.105429   \n",
       "Annual volatility           0.151151        0.174430   0.150980   0.153287   \n",
       "Sharpe ratio                0.371629        0.504774   0.442153   0.437912   \n",
       "Calmar ratio                0.227410        0.333959   0.298044   0.286929   \n",
       "Stability                   0.105855        0.011224   0.077677   0.072713   \n",
       "Max drawdown               -0.200859       -0.225777  -0.191022  -0.198499   \n",
       "Omega ratio                 1.065225        1.088724   1.077565   1.077621   \n",
       "Sortino ratio               0.528910        0.727045   0.631005   0.626504   \n",
       "Skew                             NaN             NaN  -0.099735  -0.076031   \n",
       "Kurtosis                         NaN             NaN   1.801319   2.157376   \n",
       "Tail ratio                  0.929052        1.040514   0.970390   0.946697   \n",
       "Daily value at risk        -0.018820       -0.021627  -0.018757  -0.019046   \n",
       "Alpha                       0.000000        0.000000   0.000000   0.000000   \n",
       "Beta                        1.000000        1.000000   1.000000   1.000000   \n",
       "\n",
       "                     ddpg Model  \n",
       "Annual return          0.023502  \n",
       "Cumulative returns     0.042931  \n",
       "Annual volatility      0.159810  \n",
       "Sharpe ratio           0.225129  \n",
       "Calmar ratio           0.104644  \n",
       "Stability              0.313110  \n",
       "Max drawdown          -0.224591  \n",
       "Omega ratio            1.039168  \n",
       "Sortino ratio          0.319246  \n",
       "Skew                  -0.047889  \n",
       "Kurtosis               1.805006  \n",
       "Tail ratio             0.953489  \n",
       "Daily value at risk   -0.019991  \n",
       "Alpha                  0.000000  \n",
       "Beta                   1.000000  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolios_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20678aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_rl_for_portfolio_optimization",
   "language": "python",
   "name": "deep_rl_for_portfolio_optimization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
